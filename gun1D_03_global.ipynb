{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GAN\n",
   "id": "f862837625771c44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 83,
   "source": [
    "# basic\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# other\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean"
   ],
   "id": "c9a3fa379bf825d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DATASET + MODELY\n",
    "\n",
    "* **`Signal1DDataset`**\n",
    "\n",
    "  * Loads signal data from CSV files, grouped by experiment IDs.\n",
    "  * Each sample contains:\n",
    "\n",
    "    * A **1D signal** (from column `\"intensity\"` or last column).\n",
    "    * A **condition vector** (from parameter CSV, excluding `experiment` column).\n",
    "  * Supports:\n",
    "\n",
    "    * Global **signal normalization** to `[-1, 1]`.\n",
    "    * **Condition normalization** to zero mean, unit variance.\n",
    "\n",
    "* **`Generator1D`**\n",
    "\n",
    "  * Takes a random noise vector and a condition vector.\n",
    "  * Produces a **synthetic 1D signal** of length `signal_len` in range `[-1, 1]`.\n",
    "\n",
    "* **`Discriminator1D`**\n",
    "\n",
    "  * Takes a signal (real or generated) and a condition vector.\n",
    "  * Uses 1D convolutions to extract features.\n",
    "  * Outputs a single scalar (real vs fake score).\n",
    "\n"
   ],
   "id": "dc2ae524c4397d57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T02:42:42.238050Z",
     "start_time": "2025-09-26T02:42:42.229438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Signal1DDataset(Dataset):\n",
    "    def __init__(self, root_dir, params_csv, allowed_experiments=None,\n",
    "                 normalize_signals=True, normalize_conditions=True):\n",
    "        \"\"\"\n",
    "        Custom PyTorch dataset for loading 1D signal CSV files along with\n",
    "        associated experimental conditions.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): Root directory containing subfolders for experiments.\n",
    "            params_csv (str): Path to CSV with experiment parameters.\n",
    "                              Must contain a column 'experiment' linking to folders.\n",
    "            allowed_experiments (list[int], optional): Subset of experiments to use.\n",
    "            normalize_signals (bool): Whether to apply global min-max normalization\n",
    "                                      of signals into [-1, 1].\n",
    "            normalize_conditions (bool): Whether to standardize conditions\n",
    "                                         (zero mean, unit variance).\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.params_df = pd.read_csv(params_csv)\n",
    "\n",
    "        if allowed_experiments is not None:\n",
    "            self.params_df = self.params_df[self.params_df[\"experiment\"].isin(allowed_experiments)]\n",
    "\n",
    "        self.samples = []\n",
    "        for _, row in self.params_df.iterrows():\n",
    "            folder_id = str(int(row[\"experiment\"]))\n",
    "            folder_path = os.path.join(root_dir, folder_id)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "            for fname in os.listdir(folder_path):\n",
    "                if fname.lower().endswith(\".csv\"):\n",
    "                    fpath = os.path.join(folder_path, fname)\n",
    "                    conditions = row.drop(\"experiment\").values\n",
    "                    self.samples.append((fpath, conditions))\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} files (experiments={allowed_experiments})\")\n",
    "\n",
    "        # === global signal normalization ===\n",
    "        self.normalize_signals = normalize_signals\n",
    "        if normalize_signals and len(self.samples) > 0:\n",
    "            all_signals = []\n",
    "            for fpath, _ in self.samples:\n",
    "                df = pd.read_csv(fpath)\n",
    "                if \"intensity\" in df.columns:\n",
    "                    sig = df[\"intensity\"].values.astype(np.float32)\n",
    "                else:\n",
    "                    sig = df.iloc[:, -1].values.astype(np.float32)\n",
    "                all_signals.append(sig)\n",
    "\n",
    "            all_signals = np.concatenate(all_signals)\n",
    "            self.global_min = all_signals.min()\n",
    "            self.global_max = all_signals.max()\n",
    "            print(f\"Global normalization: min={self.global_min:.4f}, max={self.global_max:.4f}\")\n",
    "\n",
    "        # === condition normalization ===\n",
    "        self.normalize_conditions = normalize_conditions\n",
    "        if normalize_conditions and len(self.samples) > 0:\n",
    "            all_conditions = np.stack([s[1] for s in self.samples])\n",
    "            self.cond_mean = all_conditions.mean(axis=0)\n",
    "            self.cond_std = all_conditions.std(axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal_path, cond = self.samples[idx]\n",
    "        df = pd.read_csv(signal_path)\n",
    "\n",
    "        if \"intensity\" in df.columns:\n",
    "            signal = df[\"intensity\"].values.astype(np.float32)\n",
    "        else:\n",
    "            signal = df.iloc[:, -1].values.astype(np.float32)\n",
    "\n",
    "        # global normalization\n",
    "        if self.normalize_signals:\n",
    "            signal = (signal - self.global_min) / (self.global_max - self.global_min + 1e-8)\n",
    "            signal = signal * 2.0 - 1.0  # range [-1, 1]\n",
    "\n",
    "        # condition normalization\n",
    "        cond = cond.astype(np.float32)\n",
    "        if self.normalize_conditions:\n",
    "            cond = (cond - self.cond_mean) / (self.cond_std + 1e-8)\n",
    "\n",
    "        return torch.from_numpy(signal), torch.from_numpy(cond)\n",
    "\n",
    "\n",
    "class Generator1D(nn.Module):\n",
    "    def __init__(self, noise_dim=64, cond_dim=5, signal_len=450):\n",
    "        \"\"\"\n",
    "        1D Generator network for conditional GAN.\n",
    "\n",
    "        Args:\n",
    "            noise_dim (int): Dimension of input noise vector.\n",
    "            cond_dim (int): Dimension of condition vector.\n",
    "            signal_len (int): Length of the generated signal.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        input_dim = noise_dim + cond_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, signal_len),\n",
    "            nn.Tanh()   # output range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, cond):\n",
    "        x = torch.cat([noise, cond], dim=1)   # (B, noise_dim+cond_dim)\n",
    "        return self.net(x)                    # (B, signal_len)\n",
    "\n",
    "\n",
    "class Discriminator1D(nn.Module):\n",
    "    def __init__(self, cond_dim=5, signal_len=450):\n",
    "        \"\"\"\n",
    "        1D Discriminator network for conditional GAN.\n",
    "\n",
    "        Args:\n",
    "            cond_dim (int): Dimension of condition vector.\n",
    "            signal_len (int): Length of input signal.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(16, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(32, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        # compute feature dimension after convolutions\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, signal_len)\n",
    "            out = self.feature_extractor(dummy)\n",
    "            flat_dim = out.view(1, -1).size(1)\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(flat_dim + cond_dim, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, signal, cond):\n",
    "        x = signal.unsqueeze(1)       # (B, 1, L)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)     # flatten\n",
    "        x = torch.cat([x, cond], dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.dropout(x)\n",
    "        return self.out(x)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TRAIN\n",
    "\n",
    "* **`train_wgan_gp_l1`**\n",
    "\n",
    "  * Training loop for WGAN-GP with extra **L1 loss** (encourages signals to match real ones).\n",
    "  * Updates the **discriminator multiple times per generator update** (`n_critic`).\n",
    "  * Supports **λL1 decay** and optional **validation with saving outputs**.\n",
    "\n",
    "* **`gradient_penalty`**\n",
    "\n",
    "  * Implements the **gradient penalty** term from WGAN-GP.\n",
    "  * Enforces Lipschitz constraint by penalizing deviation of gradient norm from 1.\n",
    "\n",
    "* **`validate_gan`**\n",
    "\n",
    "  * Samples random real signals + conditions.\n",
    "  * Generates fake signals under same conditions.\n",
    "  * Plots **real vs generated** side by side for visual sanity check.\n"
   ],
   "id": "595b89800a269fb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T02:42:42.247830Z",
     "start_time": "2025-09-26T02:42:42.240837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_wgan_gp_l1(G, D, train_loader, noise_dim, num_epochs=50,\n",
    "                     lr_G=1e-4, lr_D=5e-5, device=\"cpu\",\n",
    "                     n_critic=2, lambda_gp=1.0, lambda_l1=10.0,\n",
    "                     l1_decay_every=None,\n",
    "                     val_dataset=None, run_dir=None, validate_every=10):\n",
    "    \"\"\"\n",
    "    Hybrid training loop for conditional WGAN-GP with additional L1 reconstruction loss.\n",
    "\n",
    "    Args:\n",
    "        G (nn.Module): Generator model.\n",
    "        D (nn.Module): Discriminator (critic) model.\n",
    "        train_loader (DataLoader): Training data loader.\n",
    "        noise_dim (int): Dimension of input noise vector.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        lr_G (float): Learning rate for generator.\n",
    "        lr_D (float): Learning rate for discriminator.\n",
    "        device (str): \"cpu\" or \"cuda\".\n",
    "        n_critic (int): Number of discriminator updates per generator update.\n",
    "        lambda_gp (float): Gradient penalty coefficient.\n",
    "        lambda_l1 (float): Weight for L1 reconstruction loss.\n",
    "        l1_decay_every (int or None): Halve lambda_l1 every given epochs.\n",
    "        val_dataset (Dataset or None): Validation dataset.\n",
    "        run_dir (str or None): Directory for saving validation outputs.\n",
    "        validate_every (int): Run validation every N epochs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Training history with loss_D, loss_G, lambda_l1.\n",
    "    \"\"\"\n",
    "    optimizer_G = optim.Adam(G.parameters(), lr=lr_G, betas=(0.0, 0.9))\n",
    "    optimizer_D = optim.Adam(D.parameters(), lr=lr_D, betas=(0.0, 0.9))\n",
    "\n",
    "    history = {\"loss_D\": [], \"loss_G\": [], \"lambda_l1\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_D_epoch, loss_G_epoch = 0.0, 0.0\n",
    "\n",
    "        # decay λL1\n",
    "        if l1_decay_every is not None and (epoch > 0) and (epoch % l1_decay_every == 0):\n",
    "            lambda_l1 = lambda_l1 / 2.0\n",
    "            print(f\"[Epoch {epoch}] Decaying lambda_l1 → {lambda_l1}\")\n",
    "\n",
    "        for signals, conds in train_loader:\n",
    "            signals = signals.to(device).float()\n",
    "            conds = conds.to(device).float()\n",
    "            b_size = signals.size(0)\n",
    "\n",
    "            # --- Critic update ---\n",
    "            for _ in range(n_critic):\n",
    "                noise = torch.randn(b_size, noise_dim, device=device)\n",
    "                fake_signals = G(noise, conds)\n",
    "\n",
    "                D.zero_grad()\n",
    "                real_validity = D(signals, conds)\n",
    "                fake_validity = D(fake_signals.detach(), conds)\n",
    "\n",
    "                gp = gradient_penalty(D, signals, fake_signals, conds, device, lambda_gp)\n",
    "                loss_D = fake_validity.mean() - real_validity.mean() + gp\n",
    "\n",
    "                loss_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # --- Generator update ---\n",
    "            noise = torch.randn(b_size, noise_dim, device=device)\n",
    "            fake_signals = G(noise, conds)\n",
    "\n",
    "            G.zero_grad()\n",
    "            fake_validity = D(fake_signals, conds)\n",
    "\n",
    "            adv_loss = -fake_validity.mean()\n",
    "            l1_loss = F.l1_loss(fake_signals, signals)\n",
    "            loss_G = adv_loss + lambda_l1 * l1_loss\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            loss_D_epoch += loss_D.item()\n",
    "            loss_G_epoch += loss_G.item()\n",
    "\n",
    "        # epoch averages\n",
    "        loss_D_epoch /= len(train_loader)\n",
    "        loss_G_epoch /= len(train_loader)\n",
    "        history[\"loss_D\"].append(loss_D_epoch)\n",
    "        history[\"loss_G\"].append(loss_G_epoch)\n",
    "        history[\"lambda_l1\"].append(lambda_l1)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Loss_D: {loss_D_epoch:.4f} Loss_G: {loss_G_epoch:.4f} (λL1={lambda_l1:.2f})\")\n",
    "\n",
    "        # --- Validation ---\n",
    "        if val_dataset is not None and run_dir is not None:\n",
    "            if (epoch+1) % validate_every == 0 or (epoch+1) == num_epochs:\n",
    "                val_df = validate_and_save_all(G, val_dataset, noise_dim=noise_dim,\n",
    "                                               device=device, save_dir=run_dir, epoch=epoch+1)\n",
    "                print(f\"[Epoch {epoch+1}] Val mean MSE={val_df['MSE'].mean():.4f}, \"\n",
    "                      f\"Corr={val_df['Corr'].mean():.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def gradient_penalty(D, real_data, fake_data, cond, device=\"cpu\", lambda_gp=10):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty for WGAN-GP.\n",
    "\n",
    "    Args:\n",
    "        D (nn.Module): Discriminator (critic).\n",
    "        real_data (Tensor): Batch of real signals.\n",
    "        fake_data (Tensor): Batch of generated signals.\n",
    "        cond (Tensor): Condition vectors.\n",
    "        device (str): Device.\n",
    "        lambda_gp (float): Penalty weight.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Gradient penalty term.\n",
    "    \"\"\"\n",
    "    b_size = real_data.size(0)\n",
    "    alpha = torch.rand(b_size, 1, device=device).expand_as(real_data)\n",
    "\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates, cond)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates, device=device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(b_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    gp = ((gradient_norm - 1) ** 2).mean() * lambda_gp\n",
    "    return gp\n",
    "\n",
    "\n",
    "def validate_gan(G, val_dataset, noise_dim=64, num_samples=5, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Visual validation of GAN outputs.\n",
    "\n",
    "    Args:\n",
    "        G (nn.Module): Generator model.\n",
    "        val_dataset (Dataset): Validation dataset.\n",
    "        noise_dim (int): Noise dimension.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "        device (str): Device.\n",
    "\n",
    "    Side effects:\n",
    "        Displays matplotlib plots comparing real vs. generated signals.\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    indices = np.random.choice(len(val_dataset), num_samples, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(10, 8), sharex=True)\n",
    "    for i, idx in enumerate(indices):\n",
    "        real_signal, cond = val_dataset[idx]\n",
    "        cond = cond.unsqueeze(0).to(device).float()\n",
    "        noise = torch.randn(1, noise_dim, device=device)\n",
    "        with torch.no_grad():\n",
    "            fake_signal = G(noise, cond).cpu().numpy().flatten()\n",
    "\n",
    "        axes[i].plot(real_signal.numpy(), label=\"Real\", color=\"black\")\n",
    "        axes[i].plot(fake_signal, label=\"Generated\", color=\"red\", alpha=0.7)\n",
    "        axes[i].legend()\n",
    "    plt.suptitle(\"Validation: Real vs Generated Signals\")\n",
    "    plt.show()\n"
   ],
   "id": "9c2ca24a74856c43",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# VALIDATE\n",
    "\n",
    "* **`validate_gan_with_metrics`**\n",
    "\n",
    "  * Picks a few random samples from the dataset.\n",
    "  * Generates fake signals under the same conditions.\n",
    "  * Computes **MSE** and **Pearson correlation** between real and fake signals.\n",
    "  * Visualizes and optionally saves the plots.\n",
    "\n",
    "* **`validate_and_save_all`**\n",
    "\n",
    "  * Runs generator across the **entire validation dataset**.\n",
    "  * Computes and saves per-sample metrics (**MSE, Corr**) into a CSV.\n",
    "  * Saves arrays of real and generated signals (`.npy`).\n",
    "  * Produces histograms of metric distributions for quick diagnostics.\n",
    "\n"
   ],
   "id": "1134f1c2a7662a9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T02:42:42.254799Z",
     "start_time": "2025-09-26T02:42:42.249333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_gan_with_metrics(G, dataset, noise_dim=64, num_samples=3, device=\"cpu\", save_dir=None):\n",
    "    \"\"\"\n",
    "    Validate generator on a random subset of the dataset and compute metrics.\n",
    "\n",
    "    Args:\n",
    "        G (nn.Module): Generator model.\n",
    "        dataset (Dataset): Dataset with real signals and conditions.\n",
    "        noise_dim (int): Dimension of the noise vector.\n",
    "        num_samples (int): Number of random samples to visualize.\n",
    "        device (str): Device (\"cpu\" or \"cuda\").\n",
    "        save_dir (str or None): If provided, save the plots to this directory.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: List of dictionaries with indices, MSE and correlation.\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    results = []\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        real_signal, cond = dataset[idx]\n",
    "        real_signal = real_signal.numpy()\n",
    "\n",
    "        cond = cond.unsqueeze(0).to(device).float()\n",
    "        noise = torch.randn(1, noise_dim, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_signal = G(noise, cond).cpu().numpy().flatten()\n",
    "\n",
    "        mse = mean_squared_error(real_signal, fake_signal)\n",
    "        corr, _ = pearsonr(real_signal, fake_signal)\n",
    "        results.append({\"idx\": idx, \"MSE\": mse, \"Corr\": corr})\n",
    "\n",
    "        axes[i].plot(real_signal, label=\"Real\", color=\"black\")\n",
    "        axes[i].plot(fake_signal, label=\"Generated\", color=\"red\", alpha=0.7)\n",
    "        axes[i].legend()\n",
    "        axes[i].set_title(f\"Sample {idx} | MSE={mse:.4f}, Corr={corr:.3f}\")\n",
    "\n",
    "    plt.suptitle(\"Validation: Real vs Generated signals (with metrics)\")\n",
    "    if save_dir is not None:\n",
    "        plt.savefig(os.path.join(save_dir, \"validation_examples.png\"), dpi=200)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def validate_and_save_all(G, dataset, noise_dim=64, device=\"cpu\", save_dir=\"results\", epoch=None):\n",
    "    \"\"\"\n",
    "    Evaluate generator on the entire validation dataset and save results.\n",
    "\n",
    "    For each sample:\n",
    "      - Generates a fake signal given the real condition.\n",
    "      - Computes MSE and Pearson correlation with the real signal.\n",
    "      - Saves signals and metrics to disk.\n",
    "\n",
    "    Args:\n",
    "        G (nn.Module): Generator model.\n",
    "        dataset (Dataset): Validation dataset.\n",
    "        noise_dim (int): Dimension of noise vector.\n",
    "        device (str): Device (\"cpu\" or \"cuda\").\n",
    "        save_dir (str): Directory for saving outputs.\n",
    "        epoch (int or None): If provided, appended to filenames.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with per-sample metrics (MSE, Corr).\n",
    "    \"\"\"\n",
    "    G.eval()\n",
    "    all_results = []\n",
    "    real_signals, fake_signals = [], []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        real_signal, cond = dataset[idx]\n",
    "        real_signal_np = real_signal.numpy()\n",
    "\n",
    "        cond = cond.unsqueeze(0).to(device).float()\n",
    "        noise = torch.randn(1, noise_dim, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_signal = G(noise, cond).cpu().numpy().flatten()\n",
    "\n",
    "        mse = mean_squared_error(real_signal_np, fake_signal)\n",
    "        corr, _ = pearsonr(real_signal_np, fake_signal)\n",
    "\n",
    "        all_results.append({\"idx\": idx, \"MSE\": mse, \"Corr\": corr})\n",
    "        real_signals.append(real_signal_np)\n",
    "        fake_signals.append(fake_signal)\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # --- dynamic filenames depending on epoch ---\n",
    "    suffix = f\"_epoch{epoch}\" if epoch is not None else \"\"\n",
    "    df.to_csv(os.path.join(save_dir, f\"validation_metrics{suffix}.csv\"), index=False)\n",
    "\n",
    "    np.save(os.path.join(save_dir, f\"real_signals{suffix}.npy\"), np.array(real_signals))\n",
    "    np.save(os.path.join(save_dir, f\"fake_signals{suffix}.npy\"), np.array(fake_signals))\n",
    "\n",
    "    # histograms of metrics\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df[\"MSE\"], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(\"MSE distribution\")\n",
    "    plt.xlabel(\"MSE\"); plt.ylabel(\"Count\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df[\"Corr\"], bins=30, color=\"salmon\", edgecolor=\"black\")\n",
    "    plt.title(\"Correlation distribution\")\n",
    "    plt.xlabel(\"Pearson corr\"); plt.ylabel(\"Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"validation_metrics_hist{suffix}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    return df\n"
   ],
   "id": "4852b0266a2e3aa5",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MAIN\n",
    "\n",
    "1. **Dataset split**\n",
    "\n",
    "   * Splits experiments into train/val sets (80/20).\n",
    "   * Saves or reloads the split from `dataset_split.csv`.\n",
    "\n",
    "2. **Dataset + DataLoader**\n",
    "\n",
    "   * Initializes `Signal1DDataset` for train and validation.\n",
    "   * Builds PyTorch `DataLoader`.\n",
    "\n",
    "3. **Model initialization**\n",
    "\n",
    "   * Derives signal length and condition dimension from dataset.\n",
    "   * Creates `Generator1D` and `Discriminator1D`.\n",
    "\n",
    "4. **Grid search**\n",
    "\n",
    "   * Iterates over combinations of `λL1` weights and number of epochs.\n",
    "   * Each run has its own timestamped results directory.\n",
    "\n",
    "5. **Training**\n",
    "\n",
    "   * Calls `train_wgan_gp_l1` with given parameters.\n",
    "   * Tracks losses and saves them in CSV/JSON.\n",
    "\n",
    "6. **Saving**\n",
    "\n",
    "   * Stores trained models (`.pth`).\n",
    "   * Exports training curves.\n",
    "\n",
    "7. **Validation**\n",
    "\n",
    "   * Runs `validate_gan_with_metrics` for sample plots with metrics.\n",
    "   * Runs `validate_and_save_all` for full validation evaluation.\n",
    "   * Saves metrics, signals, and histogram plots.\n",
    "\n"
   ],
   "id": "8bd0f79c69888881"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T06:28:56.899610Z",
     "start_time": "2025-09-26T02:42:42.259718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ==========================\n",
    "    # Setup\n",
    "    # ==========================\n",
    "    root_dir = \"1D_spec\"\n",
    "    params_csv = os.path.join(root_dir, \"params.csv\")\n",
    "    base_results_dir = \"results\"\n",
    "    os.makedirs(base_results_dir, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # ==========================\n",
    "    # Dataset split\n",
    "    # ==========================\n",
    "    split_file = os.path.join(base_results_dir, \"dataset_split.csv\")\n",
    "    if os.path.exists(split_file):\n",
    "        split_df = pd.read_csv(split_file)\n",
    "        train_exps = split_df.query(\"set == 'train'\")[\"experiment\"].tolist()\n",
    "        val_exps   = split_df.query(\"set == 'val'\")[\"experiment\"].tolist()\n",
    "    else:\n",
    "        params_df = pd.read_csv(params_csv)\n",
    "        all_experiments = params_df[\"experiment\"].unique()\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(all_experiments)\n",
    "\n",
    "        split_ratio = 0.8\n",
    "        split_idx = int(len(all_experiments) * split_ratio)\n",
    "        train_exps = all_experiments[:split_idx]\n",
    "        val_exps   = all_experiments[split_idx:]\n",
    "\n",
    "        split_df = pd.DataFrame({\n",
    "            \"experiment\": list(train_exps) + list(val_exps),\n",
    "            \"set\": [\"train\"] * len(train_exps) + [\"val\"] * len(val_exps)\n",
    "        })\n",
    "        split_df.to_csv(split_file, index=False)\n",
    "\n",
    "    # dataset and dataloader\n",
    "    train_dataset = Signal1DDataset(root_dir, params_csv, allowed_experiments=train_exps)\n",
    "    val_dataset   = Signal1DDataset(root_dir, params_csv, allowed_experiments=val_exps)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # ==========================\n",
    "    # Signal dimensions\n",
    "    # ==========================\n",
    "    signal, cond = train_dataset[0]\n",
    "    noise_dim = 64\n",
    "    cond_dim = cond.numel()\n",
    "    signal_len = signal.numel()\n",
    "\n",
    "    print(f\"Init: noise_dim={noise_dim}, cond_dim={cond_dim}, signal_len={signal_len}\")\n",
    "\n",
    "    # ==========================\n",
    "    # Grid search parameters\n",
    "    # ==========================\n",
    "    lambda_list = [5, 10, 15, 20, 25]\n",
    "    epoch_list = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "\n",
    "    # ==========================\n",
    "    # Run all combinations\n",
    "    # ==========================\n",
    "    for lambda_l1, num_epochs in itertools.product(lambda_list, epoch_list):\n",
    "        run_name = f\"lambda{lambda_l1}_epochs{num_epochs}_\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        run_dir = os.path.join(base_results_dir, run_name)\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "        print(f\"\\n=== Running: λ={lambda_l1}, epochs={num_epochs}, output: {run_dir} ===\")\n",
    "\n",
    "        # models\n",
    "        G = Generator1D(noise_dim=noise_dim, cond_dim=cond_dim, signal_len=signal_len).to(device)\n",
    "        D = Discriminator1D(cond_dim=cond_dim, signal_len=signal_len).to(device)\n",
    "\n",
    "        # config\n",
    "        config = {\n",
    "            \"lambda_l1\": lambda_l1,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"lr_G\": 1e-4,\n",
    "            \"lr_D\": 5e-5,\n",
    "            \"n_critic\": 2,\n",
    "            \"lambda_gp\": 1.0,\n",
    "            \"noise_dim\": noise_dim,\n",
    "            \"cond_dim\": cond_dim,\n",
    "            \"signal_len\": signal_len,\n",
    "            \"device\": str(device)\n",
    "        }\n",
    "        with open(os.path.join(run_dir, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "\n",
    "        # training\n",
    "        history = train_wgan_gp_l1(\n",
    "            G, D, train_loader, noise_dim,\n",
    "            num_epochs=num_epochs,\n",
    "            device=device,\n",
    "            lr_G=config[\"lr_G\"], lr_D=config[\"lr_D\"],\n",
    "            n_critic=config[\"n_critic\"],\n",
    "            lambda_gp=config[\"lambda_gp\"], lambda_l1=lambda_l1,\n",
    "            val_dataset=val_dataset, run_dir=run_dir, validate_every=10\n",
    "        )\n",
    "\n",
    "        # save training history\n",
    "        pd.DataFrame(history).to_csv(os.path.join(run_dir, \"training_history.csv\"), index=False)\n",
    "        with open(os.path.join(run_dir, \"training_history.json\"), \"w\") as f:\n",
    "            json.dump(history, f)\n",
    "\n",
    "        # save models\n",
    "        torch.save(G.state_dict(), os.path.join(run_dir, \"generator.pth\"))\n",
    "        torch.save(D.state_dict(), os.path.join(run_dir, \"discriminator.pth\"))\n",
    "\n",
    "        # loss curves\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(history[\"loss_D\"], label=\"Discriminator\")\n",
    "        plt.plot(history[\"loss_G\"], label=\"Generator\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training progress (WGAN-GP + L1)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(os.path.join(run_dir, \"loss_curve.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        # validation\n",
    "        val_results = validate_gan_with_metrics(G, val_dataset, noise_dim=noise_dim,\n",
    "                                                num_samples=5, device=device, save_dir=run_dir)\n",
    "        pd.DataFrame(val_results).to_csv(os.path.join(run_dir, \"validation_metrics.csv\"), index=False)\n",
    "\n",
    "        val_df = validate_and_save_all(G, val_dataset, noise_dim=noise_dim,\n",
    "                                       device=device, save_dir=run_dir)\n",
    "        print(val_df.describe())\n",
    "\n",
    "        print(\"Run completed. Results in folder:\", run_dir)\n"
   ],
   "id": "f4049e2a35220b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Použité zařízení: cpu\n",
      "Načteno 991 souborů (experiments=[ 1 14  9  2 16  6 21 12  4  5 18 13 19 17  3 10 22])\n",
      "Globální normalizace: min=0.0015, max=6.9025\n",
      "Načteno 288 souborů (experiments=[ 8 11 15 20  7])\n",
      "Globální normalizace: min=0.0039, max=3.2035\n",
      "Init: noise_dim=64, cond_dim=5, signal_len=450\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=10, výstup: results/lambda5_epochs10_20250926_044242 ===\n",
      "Epoch [1/10] Loss_D: -1.8329 Loss_G: 3.5305 (λL1=5.00)\n",
      "Epoch [2/10] Loss_D: -2.5101 Loss_G: -5.5305 (λL1=5.00)\n",
      "Epoch [3/10] Loss_D: 0.1727 Loss_G: -4.6210 (λL1=5.00)\n",
      "Epoch [4/10] Loss_D: 0.3351 Loss_G: 2.7134 (λL1=5.00)\n",
      "Epoch [5/10] Loss_D: -0.0079 Loss_G: -0.9835 (λL1=5.00)\n",
      "Epoch [6/10] Loss_D: -0.1014 Loss_G: 1.9514 (λL1=5.00)\n",
      "Epoch [7/10] Loss_D: -0.4894 Loss_G: 2.3617 (λL1=5.00)\n",
      "Epoch [8/10] Loss_D: -1.3326 Loss_G: 0.9576 (λL1=5.00)\n",
      "Epoch [9/10] Loss_D: -1.1614 Loss_G: 0.7955 (λL1=5.00)\n",
      "Epoch [10/10] Loss_D: -1.1623 Loss_G: 0.5747 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.1507, Corr=0.3332\n",
      "Nejlepší epocha podle MSE: epoch       10.000000\n",
      "mean_MSE     0.150732\n",
      "Name: 0, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.152610    0.332539\n",
      "std     83.282651    0.082488    0.043407\n",
      "min      0.000000    0.070719    0.260801\n",
      "25%     71.750000    0.081200    0.298685\n",
      "50%    143.500000    0.146895    0.313110\n",
      "75%    215.250000    0.201019    0.376438\n",
      "max    287.000000    0.527972    0.425853\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs10_20250926_044242\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=20, výstup: results/lambda5_epochs20_20250926_044302 ===\n",
      "Epoch [1/20] Loss_D: -2.0399 Loss_G: 3.5802 (λL1=5.00)\n",
      "Epoch [2/20] Loss_D: -2.4944 Loss_G: -7.2371 (λL1=5.00)\n",
      "Epoch [3/20] Loss_D: 0.0964 Loss_G: -6.3629 (λL1=5.00)\n",
      "Epoch [4/20] Loss_D: 0.2510 Loss_G: 0.7561 (λL1=5.00)\n",
      "Epoch [5/20] Loss_D: -0.2397 Loss_G: -3.4327 (λL1=5.00)\n",
      "Epoch [6/20] Loss_D: 0.1482 Loss_G: -1.5306 (λL1=5.00)\n",
      "Epoch [7/20] Loss_D: -1.0913 Loss_G: -2.9971 (λL1=5.00)\n",
      "Epoch [8/20] Loss_D: -1.9124 Loss_G: -3.5333 (λL1=5.00)\n",
      "Epoch [9/20] Loss_D: -0.4844 Loss_G: 0.1168 (λL1=5.00)\n",
      "Epoch [10/20] Loss_D: -1.6793 Loss_G: -0.2849 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.2006, Corr=0.6323\n",
      "Epoch [11/20] Loss_D: -8.2828 Loss_G: 2.5388 (λL1=5.00)\n",
      "Epoch [12/20] Loss_D: -2.1344 Loss_G: -0.9880 (λL1=5.00)\n",
      "Epoch [13/20] Loss_D: -0.7017 Loss_G: 1.4342 (λL1=5.00)\n",
      "Epoch [14/20] Loss_D: -1.5380 Loss_G: 5.5465 (λL1=5.00)\n",
      "Epoch [15/20] Loss_D: -1.2968 Loss_G: 0.5659 (λL1=5.00)\n",
      "Epoch [16/20] Loss_D: -7.2011 Loss_G: 4.2940 (λL1=5.00)\n",
      "Epoch [17/20] Loss_D: -1.3993 Loss_G: -0.7233 (λL1=5.00)\n",
      "Epoch [18/20] Loss_D: -1.5720 Loss_G: 0.3308 (λL1=5.00)\n",
      "Epoch [19/20] Loss_D: -1.7018 Loss_G: 3.0099 (λL1=5.00)\n",
      "Epoch [20/20] Loss_D: -1.5903 Loss_G: 7.7966 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.0853, Corr=0.4384\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.085338\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.085033    0.438592\n",
      "std     83.282651    0.076941    0.174763\n",
      "min      0.000000    0.007964    0.230418\n",
      "25%     71.750000    0.011508    0.300466\n",
      "50%    143.500000    0.075321    0.327129\n",
      "75%    215.250000    0.151768    0.653622\n",
      "max    287.000000    0.290731    0.705791\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs20_20250926_044302\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=30, výstup: results/lambda5_epochs30_20250926_044340 ===\n",
      "Epoch [1/30] Loss_D: -1.5535 Loss_G: 3.9415 (λL1=5.00)\n",
      "Epoch [2/30] Loss_D: -2.1575 Loss_G: -3.6537 (λL1=5.00)\n",
      "Epoch [3/30] Loss_D: 0.1052 Loss_G: -2.0167 (λL1=5.00)\n",
      "Epoch [4/30] Loss_D: 0.3692 Loss_G: 3.5947 (λL1=5.00)\n",
      "Epoch [5/30] Loss_D: -0.1134 Loss_G: -1.0563 (λL1=5.00)\n",
      "Epoch [6/30] Loss_D: -0.3325 Loss_G: 3.7621 (λL1=5.00)\n",
      "Epoch [7/30] Loss_D: -0.9633 Loss_G: 3.1855 (λL1=5.00)\n",
      "Epoch [8/30] Loss_D: -2.2029 Loss_G: 2.9750 (λL1=5.00)\n",
      "Epoch [9/30] Loss_D: -0.6760 Loss_G: 5.4103 (λL1=5.00)\n",
      "Epoch [10/30] Loss_D: -3.4574 Loss_G: 7.0739 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.1224, Corr=0.5199\n",
      "Epoch [11/30] Loss_D: -2.7669 Loss_G: 7.2674 (λL1=5.00)\n",
      "Epoch [12/30] Loss_D: -1.0493 Loss_G: 6.1012 (λL1=5.00)\n",
      "Epoch [13/30] Loss_D: -2.6018 Loss_G: -0.3368 (λL1=5.00)\n",
      "Epoch [14/30] Loss_D: -4.4621 Loss_G: 0.4798 (λL1=5.00)\n",
      "Epoch [15/30] Loss_D: -0.8801 Loss_G: 6.5421 (λL1=5.00)\n",
      "Epoch [16/30] Loss_D: -0.8772 Loss_G: 6.2232 (λL1=5.00)\n",
      "Epoch [17/30] Loss_D: -2.4843 Loss_G: 6.3678 (λL1=5.00)\n",
      "Epoch [18/30] Loss_D: -0.1035 Loss_G: 5.9322 (λL1=5.00)\n",
      "Epoch [19/30] Loss_D: 0.3190 Loss_G: 5.8151 (λL1=5.00)\n",
      "Epoch [20/30] Loss_D: 0.4809 Loss_G: 8.1467 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.0627, Corr=0.4391\n",
      "Epoch [21/30] Loss_D: 0.4067 Loss_G: 10.4959 (λL1=5.00)\n",
      "Epoch [22/30] Loss_D: 0.4551 Loss_G: 9.8019 (λL1=5.00)\n",
      "Epoch [23/30] Loss_D: 0.2794 Loss_G: 7.4695 (λL1=5.00)\n",
      "Epoch [24/30] Loss_D: 0.5384 Loss_G: 7.2423 (λL1=5.00)\n",
      "Epoch [25/30] Loss_D: 0.3499 Loss_G: 6.5110 (λL1=5.00)\n",
      "Epoch [26/30] Loss_D: 0.1164 Loss_G: 7.3814 (λL1=5.00)\n",
      "Epoch [27/30] Loss_D: -0.0253 Loss_G: 7.0901 (λL1=5.00)\n",
      "Epoch [28/30] Loss_D: 0.1476 Loss_G: 6.7801 (λL1=5.00)\n",
      "Epoch [29/30] Loss_D: 0.3277 Loss_G: 7.0642 (λL1=5.00)\n",
      "Epoch [30/30] Loss_D: 0.3032 Loss_G: 7.6420 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0449, Corr=0.9017\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.044945\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045208    0.901503\n",
      "std     83.282651    0.070523    0.068689\n",
      "min      0.000000    0.000523    0.768272\n",
      "25%     71.750000    0.004368    0.847383\n",
      "50%    143.500000    0.010087    0.881745\n",
      "75%    215.250000    0.034053    0.982561\n",
      "max    287.000000    0.248581    0.988816\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs30_20250926_044340\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=40, výstup: results/lambda5_epochs40_20250926_044437 ===\n",
      "Epoch [1/40] Loss_D: -1.2422 Loss_G: 3.4068 (λL1=5.00)\n",
      "Epoch [2/40] Loss_D: -2.5117 Loss_G: -6.2087 (λL1=5.00)\n",
      "Epoch [3/40] Loss_D: 0.2322 Loss_G: -7.1621 (λL1=5.00)\n",
      "Epoch [4/40] Loss_D: 0.2989 Loss_G: -0.3136 (λL1=5.00)\n",
      "Epoch [5/40] Loss_D: 0.1729 Loss_G: -2.2677 (λL1=5.00)\n",
      "Epoch [6/40] Loss_D: 0.0806 Loss_G: -0.2113 (λL1=5.00)\n",
      "Epoch [7/40] Loss_D: -0.4205 Loss_G: 1.2513 (λL1=5.00)\n",
      "Epoch [8/40] Loss_D: -0.7112 Loss_G: 1.0767 (λL1=5.00)\n",
      "Epoch [9/40] Loss_D: -2.1548 Loss_G: 0.2851 (λL1=5.00)\n",
      "Epoch [10/40] Loss_D: -0.5389 Loss_G: -0.8368 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.0786, Corr=0.6323\n",
      "Epoch [11/40] Loss_D: -0.1909 Loss_G: -0.0512 (λL1=5.00)\n",
      "Epoch [12/40] Loss_D: 0.0698 Loss_G: 0.5333 (λL1=5.00)\n",
      "Epoch [13/40] Loss_D: 0.1826 Loss_G: 2.1511 (λL1=5.00)\n",
      "Epoch [14/40] Loss_D: 0.3910 Loss_G: 3.5208 (λL1=5.00)\n",
      "Epoch [15/40] Loss_D: 0.3401 Loss_G: 4.5900 (λL1=5.00)\n",
      "Epoch [16/40] Loss_D: 0.1518 Loss_G: 5.0705 (λL1=5.00)\n",
      "Epoch [17/40] Loss_D: -0.0747 Loss_G: 5.3271 (λL1=5.00)\n",
      "Epoch [18/40] Loss_D: -0.0327 Loss_G: 5.2275 (λL1=5.00)\n",
      "Epoch [19/40] Loss_D: 0.1717 Loss_G: 4.9228 (λL1=5.00)\n",
      "Epoch [20/40] Loss_D: 0.0821 Loss_G: 4.5525 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.0454, Corr=0.9327\n",
      "Epoch [21/40] Loss_D: 0.1272 Loss_G: 4.1974 (λL1=5.00)\n",
      "Epoch [22/40] Loss_D: 0.0931 Loss_G: 4.2847 (λL1=5.00)\n",
      "Epoch [23/40] Loss_D: 0.0451 Loss_G: 4.2971 (λL1=5.00)\n",
      "Epoch [24/40] Loss_D: 0.2105 Loss_G: 3.8022 (λL1=5.00)\n",
      "Epoch [25/40] Loss_D: 0.0384 Loss_G: 3.3625 (λL1=5.00)\n",
      "Epoch [26/40] Loss_D: -0.0883 Loss_G: 3.7301 (λL1=5.00)\n",
      "Epoch [27/40] Loss_D: 0.0007 Loss_G: 5.0120 (λL1=5.00)\n",
      "Epoch [28/40] Loss_D: 0.0832 Loss_G: 5.0835 (λL1=5.00)\n",
      "Epoch [29/40] Loss_D: -0.0444 Loss_G: 5.0504 (λL1=5.00)\n",
      "Epoch [30/40] Loss_D: 0.2200 Loss_G: 4.9368 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0443, Corr=0.9452\n",
      "Epoch [31/40] Loss_D: 0.1362 Loss_G: 4.4565 (λL1=5.00)\n",
      "Epoch [32/40] Loss_D: 0.0378 Loss_G: 4.6606 (λL1=5.00)\n",
      "Epoch [33/40] Loss_D: -0.0656 Loss_G: 5.1901 (λL1=5.00)\n",
      "Epoch [34/40] Loss_D: -0.0355 Loss_G: 5.0369 (λL1=5.00)\n",
      "Epoch [35/40] Loss_D: 0.0558 Loss_G: 5.3215 (λL1=5.00)\n",
      "Epoch [36/40] Loss_D: 0.1557 Loss_G: 5.1058 (λL1=5.00)\n",
      "Epoch [37/40] Loss_D: 0.0402 Loss_G: 4.8526 (λL1=5.00)\n",
      "Epoch [38/40] Loss_D: 0.0450 Loss_G: 4.7872 (λL1=5.00)\n",
      "Epoch [39/40] Loss_D: -0.0713 Loss_G: 5.0458 (λL1=5.00)\n",
      "Epoch [40/40] Loss_D: 0.0505 Loss_G: 4.4617 (λL1=5.00)\n",
      "[Epoch 40] Val mean MSE=0.0440, Corr=0.9543\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.044003\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043877    0.955695\n",
      "std     83.282651    0.075422    0.041162\n",
      "min      0.000000    0.000576    0.775821\n",
      "25%     71.750000    0.003484    0.945217\n",
      "50%    143.500000    0.008271    0.957720\n",
      "75%    215.250000    0.023775    0.991623\n",
      "max    287.000000    0.265181    0.995031\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs40_20250926_044437\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=50, výstup: results/lambda5_epochs50_20250926_044554 ===\n",
      "Epoch [1/50] Loss_D: -0.7058 Loss_G: 3.9021 (λL1=5.00)\n",
      "Epoch [2/50] Loss_D: -1.6071 Loss_G: -2.3371 (λL1=5.00)\n",
      "Epoch [3/50] Loss_D: 0.0361 Loss_G: -4.0618 (λL1=5.00)\n",
      "Epoch [4/50] Loss_D: 0.3787 Loss_G: 1.0282 (λL1=5.00)\n",
      "Epoch [5/50] Loss_D: -0.6520 Loss_G: -1.4804 (λL1=5.00)\n",
      "Epoch [6/50] Loss_D: -0.2598 Loss_G: -3.9856 (λL1=5.00)\n",
      "Epoch [7/50] Loss_D: 0.1244 Loss_G: -1.2201 (λL1=5.00)\n",
      "Epoch [8/50] Loss_D: -1.0311 Loss_G: -3.0094 (λL1=5.00)\n",
      "Epoch [9/50] Loss_D: -3.0798 Loss_G: -5.0512 (λL1=5.00)\n",
      "Epoch [10/50] Loss_D: 0.6501 Loss_G: -5.0723 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.1897, Corr=0.5888\n",
      "Epoch [11/50] Loss_D: -2.5380 Loss_G: -1.5373 (λL1=5.00)\n",
      "Epoch [12/50] Loss_D: -1.0466 Loss_G: -0.4284 (λL1=5.00)\n",
      "Epoch [13/50] Loss_D: -0.3052 Loss_G: 2.6179 (λL1=5.00)\n",
      "Epoch [14/50] Loss_D: -1.8984 Loss_G: 1.0544 (λL1=5.00)\n",
      "Epoch [15/50] Loss_D: -5.3681 Loss_G: -0.6762 (λL1=5.00)\n",
      "Epoch [16/50] Loss_D: -0.5594 Loss_G: -1.5700 (λL1=5.00)\n",
      "Epoch [17/50] Loss_D: -0.0667 Loss_G: 2.0290 (λL1=5.00)\n",
      "Epoch [18/50] Loss_D: -3.6904 Loss_G: 3.8600 (λL1=5.00)\n",
      "Epoch [19/50] Loss_D: -1.6392 Loss_G: 2.4020 (λL1=5.00)\n",
      "Epoch [20/50] Loss_D: -5.0024 Loss_G: 1.4959 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.1257, Corr=0.4064\n",
      "Epoch [21/50] Loss_D: -2.2813 Loss_G: 1.0729 (λL1=5.00)\n",
      "Epoch [22/50] Loss_D: -1.0269 Loss_G: 2.1153 (λL1=5.00)\n",
      "Epoch [23/50] Loss_D: -6.9150 Loss_G: 3.0423 (λL1=5.00)\n",
      "Epoch [24/50] Loss_D: -0.5984 Loss_G: -0.8688 (λL1=5.00)\n",
      "Epoch [25/50] Loss_D: -1.3595 Loss_G: 3.0271 (λL1=5.00)\n",
      "Epoch [26/50] Loss_D: -0.8169 Loss_G: 1.7771 (λL1=5.00)\n",
      "Epoch [27/50] Loss_D: -0.1524 Loss_G: 3.4256 (λL1=5.00)\n",
      "Epoch [28/50] Loss_D: 0.1385 Loss_G: 5.1256 (λL1=5.00)\n",
      "Epoch [29/50] Loss_D: 0.2820 Loss_G: 8.5262 (λL1=5.00)\n",
      "Epoch [30/50] Loss_D: 0.1893 Loss_G: 9.2511 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0601, Corr=0.5772\n",
      "Epoch [31/50] Loss_D: 0.5591 Loss_G: 8.0300 (λL1=5.00)\n",
      "Epoch [32/50] Loss_D: 0.0706 Loss_G: 5.0634 (λL1=5.00)\n",
      "Epoch [33/50] Loss_D: 0.2653 Loss_G: 6.0395 (λL1=5.00)\n",
      "Epoch [34/50] Loss_D: 0.4361 Loss_G: 6.7911 (λL1=5.00)\n",
      "Epoch [35/50] Loss_D: 0.4285 Loss_G: 5.3052 (λL1=5.00)\n",
      "Epoch [36/50] Loss_D: 0.1801 Loss_G: 4.7532 (λL1=5.00)\n",
      "Epoch [37/50] Loss_D: -0.1902 Loss_G: 3.7247 (λL1=5.00)\n",
      "Epoch [38/50] Loss_D: 0.2155 Loss_G: 4.0584 (λL1=5.00)\n",
      "Epoch [39/50] Loss_D: -0.4236 Loss_G: 4.3306 (λL1=5.00)\n",
      "Epoch [40/50] Loss_D: 0.2544 Loss_G: 3.7676 (λL1=5.00)\n",
      "[Epoch 40] Val mean MSE=0.0469, Corr=0.8966\n",
      "Epoch [41/50] Loss_D: 0.1990 Loss_G: 4.2381 (λL1=5.00)\n",
      "Epoch [42/50] Loss_D: 0.4221 Loss_G: 3.7364 (λL1=5.00)\n",
      "Epoch [43/50] Loss_D: -0.0099 Loss_G: 3.7392 (λL1=5.00)\n",
      "Epoch [44/50] Loss_D: 0.0702 Loss_G: 4.7449 (λL1=5.00)\n",
      "Epoch [45/50] Loss_D: 0.1213 Loss_G: 3.9797 (λL1=5.00)\n",
      "Epoch [46/50] Loss_D: 0.1045 Loss_G: 5.1523 (λL1=5.00)\n",
      "Epoch [47/50] Loss_D: -0.0934 Loss_G: 3.2889 (λL1=5.00)\n",
      "Epoch [48/50] Loss_D: -0.0644 Loss_G: 4.8845 (λL1=5.00)\n",
      "Epoch [49/50] Loss_D: -0.1625 Loss_G: 4.6861 (λL1=5.00)\n",
      "Epoch [50/50] Loss_D: -0.0606 Loss_G: 5.4915 (λL1=5.00)\n",
      "[Epoch 50] Val mean MSE=0.0529, Corr=0.8475\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.046894\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.054195    0.852976\n",
      "std     83.282651    0.074294    0.097501\n",
      "min      0.000000    0.001023    0.591905\n",
      "25%     71.750000    0.005986    0.783260\n",
      "50%    143.500000    0.015857    0.823389\n",
      "75%    215.250000    0.060886    0.964457\n",
      "max    287.000000    0.260939    0.981989\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs50_20250926_044554\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=60, výstup: results/lambda5_epochs60_20250926_044729 ===\n",
      "Epoch [1/60] Loss_D: -1.5647 Loss_G: 3.1170 (λL1=5.00)\n",
      "Epoch [2/60] Loss_D: -1.7674 Loss_G: -7.6467 (λL1=5.00)\n",
      "Epoch [3/60] Loss_D: 0.4086 Loss_G: -9.3579 (λL1=5.00)\n",
      "Epoch [4/60] Loss_D: 0.4558 Loss_G: -1.3768 (λL1=5.00)\n",
      "Epoch [5/60] Loss_D: -0.2333 Loss_G: -3.9031 (λL1=5.00)\n",
      "Epoch [6/60] Loss_D: 0.2210 Loss_G: -4.6559 (λL1=5.00)\n",
      "Epoch [7/60] Loss_D: -0.0516 Loss_G: -3.1315 (λL1=5.00)\n",
      "Epoch [8/60] Loss_D: -0.7764 Loss_G: -2.4493 (λL1=5.00)\n",
      "Epoch [9/60] Loss_D: -1.3126 Loss_G: -1.5407 (λL1=5.00)\n",
      "Epoch [10/60] Loss_D: -1.6030 Loss_G: -2.6615 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.0693, Corr=0.7838\n",
      "Epoch [11/60] Loss_D: -0.7507 Loss_G: -4.9264 (λL1=5.00)\n",
      "Epoch [12/60] Loss_D: 0.4451 Loss_G: -4.7908 (λL1=5.00)\n",
      "Epoch [13/60] Loss_D: 0.8206 Loss_G: -2.2974 (λL1=5.00)\n",
      "Epoch [14/60] Loss_D: 0.5897 Loss_G: -1.3333 (λL1=5.00)\n",
      "Epoch [15/60] Loss_D: 0.2274 Loss_G: 0.0456 (λL1=5.00)\n",
      "Epoch [16/60] Loss_D: -0.0800 Loss_G: 0.5618 (λL1=5.00)\n",
      "Epoch [17/60] Loss_D: 0.0100 Loss_G: 0.4763 (λL1=5.00)\n",
      "Epoch [18/60] Loss_D: 0.1256 Loss_G: 0.0748 (λL1=5.00)\n",
      "Epoch [19/60] Loss_D: 0.1297 Loss_G: -0.6941 (λL1=5.00)\n",
      "Epoch [20/60] Loss_D: 0.0619 Loss_G: -1.2305 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.0479, Corr=0.8882\n",
      "Epoch [21/60] Loss_D: 0.0109 Loss_G: -1.4815 (λL1=5.00)\n",
      "Epoch [22/60] Loss_D: 0.0196 Loss_G: -1.3586 (λL1=5.00)\n",
      "Epoch [23/60] Loss_D: -0.0004 Loss_G: -0.9708 (λL1=5.00)\n",
      "Epoch [24/60] Loss_D: 0.1765 Loss_G: -0.7158 (λL1=5.00)\n",
      "Epoch [25/60] Loss_D: 0.1024 Loss_G: -0.9784 (λL1=5.00)\n",
      "Epoch [26/60] Loss_D: 0.1218 Loss_G: -0.7733 (λL1=5.00)\n",
      "Epoch [27/60] Loss_D: -0.0037 Loss_G: -0.0790 (λL1=5.00)\n",
      "Epoch [28/60] Loss_D: 0.0739 Loss_G: 0.3090 (λL1=5.00)\n",
      "Epoch [29/60] Loss_D: -0.0793 Loss_G: -0.5352 (λL1=5.00)\n",
      "Epoch [30/60] Loss_D: 0.0560 Loss_G: -0.3786 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0472, Corr=0.9290\n",
      "Epoch [31/60] Loss_D: -0.0846 Loss_G: -0.0748 (λL1=5.00)\n",
      "Epoch [32/60] Loss_D: -0.0493 Loss_G: -0.6183 (λL1=5.00)\n",
      "Epoch [33/60] Loss_D: -0.1508 Loss_G: -0.3398 (λL1=5.00)\n",
      "Epoch [34/60] Loss_D: -0.0665 Loss_G: 0.1060 (λL1=5.00)\n",
      "Epoch [35/60] Loss_D: 0.0539 Loss_G: 0.5017 (λL1=5.00)\n",
      "Epoch [36/60] Loss_D: 0.0275 Loss_G: 0.0295 (λL1=5.00)\n",
      "Epoch [37/60] Loss_D: -0.2692 Loss_G: -0.5936 (λL1=5.00)\n",
      "Epoch [38/60] Loss_D: 0.1768 Loss_G: -0.1844 (λL1=5.00)\n",
      "Epoch [39/60] Loss_D: -0.0469 Loss_G: -0.2475 (λL1=5.00)\n",
      "Epoch [40/60] Loss_D: -0.2012 Loss_G: -0.9571 (λL1=5.00)\n",
      "[Epoch 40] Val mean MSE=0.0511, Corr=0.9122\n",
      "Epoch [41/60] Loss_D: -0.1532 Loss_G: -0.7962 (λL1=5.00)\n",
      "Epoch [42/60] Loss_D: -0.0303 Loss_G: -1.7966 (λL1=5.00)\n",
      "Epoch [43/60] Loss_D: 0.0508 Loss_G: -0.9286 (λL1=5.00)\n",
      "Epoch [44/60] Loss_D: 0.0468 Loss_G: -1.0454 (λL1=5.00)\n",
      "Epoch [45/60] Loss_D: -0.2371 Loss_G: -0.8579 (λL1=5.00)\n",
      "Epoch [46/60] Loss_D: -0.0928 Loss_G: -0.3853 (λL1=5.00)\n",
      "Epoch [47/60] Loss_D: 0.0066 Loss_G: -0.7336 (λL1=5.00)\n",
      "Epoch [48/60] Loss_D: 0.1089 Loss_G: -0.9608 (λL1=5.00)\n",
      "Epoch [49/60] Loss_D: -0.0240 Loss_G: -1.0353 (λL1=5.00)\n",
      "Epoch [50/60] Loss_D: -0.0231 Loss_G: 0.0906 (λL1=5.00)\n",
      "[Epoch 50] Val mean MSE=0.0542, Corr=0.8836\n",
      "Epoch [51/60] Loss_D: -0.1040 Loss_G: -0.5848 (λL1=5.00)\n",
      "Epoch [52/60] Loss_D: -0.3711 Loss_G: -1.4577 (λL1=5.00)\n",
      "Epoch [53/60] Loss_D: -0.1808 Loss_G: 0.4189 (λL1=5.00)\n",
      "Epoch [54/60] Loss_D: -0.4416 Loss_G: -0.2135 (λL1=5.00)\n",
      "Epoch [55/60] Loss_D: -0.4351 Loss_G: -0.2566 (λL1=5.00)\n",
      "Epoch [56/60] Loss_D: 0.0092 Loss_G: 0.0020 (λL1=5.00)\n",
      "Epoch [57/60] Loss_D: 0.3917 Loss_G: 0.9701 (λL1=5.00)\n",
      "Epoch [58/60] Loss_D: 0.2042 Loss_G: -0.1071 (λL1=5.00)\n",
      "Epoch [59/60] Loss_D: 0.0143 Loss_G: 0.6647 (λL1=5.00)\n",
      "Epoch [60/60] Loss_D: 0.2997 Loss_G: -0.5238 (λL1=5.00)\n",
      "[Epoch 60] Val mean MSE=0.0534, Corr=0.9276\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.047237\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.055598    0.927885\n",
      "std     83.282651    0.078698    0.054107\n",
      "min      0.000000    0.000301    0.699565\n",
      "25%     71.750000    0.005473    0.904985\n",
      "50%    143.500000    0.012703    0.938265\n",
      "75%    215.250000    0.075310    0.968687\n",
      "max    287.000000    0.414174    0.991846\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs60_20250926_044729\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=70, výstup: results/lambda5_epochs70_20250926_044924 ===\n",
      "Epoch [1/70] Loss_D: -0.8993 Loss_G: 3.0430 (λL1=5.00)\n",
      "Epoch [2/70] Loss_D: -1.5831 Loss_G: -7.4422 (λL1=5.00)\n",
      "Epoch [3/70] Loss_D: 0.5148 Loss_G: -9.3428 (λL1=5.00)\n",
      "Epoch [4/70] Loss_D: 0.3624 Loss_G: -3.6651 (λL1=5.00)\n",
      "Epoch [5/70] Loss_D: 0.3696 Loss_G: -2.9974 (λL1=5.00)\n",
      "Epoch [6/70] Loss_D: -0.1896 Loss_G: -6.6401 (λL1=5.00)\n",
      "Epoch [7/70] Loss_D: 0.3226 Loss_G: -3.9961 (λL1=5.00)\n",
      "Epoch [8/70] Loss_D: -0.1998 Loss_G: -3.2145 (λL1=5.00)\n",
      "Epoch [9/70] Loss_D: -0.5392 Loss_G: -4.7709 (λL1=5.00)\n",
      "Epoch [10/70] Loss_D: -4.2295 Loss_G: -7.1655 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.1672, Corr=0.7398\n",
      "Epoch [11/70] Loss_D: -4.0830 Loss_G: -9.2106 (λL1=5.00)\n",
      "Epoch [12/70] Loss_D: 0.7527 Loss_G: -6.4983 (λL1=5.00)\n",
      "Epoch [13/70] Loss_D: 0.1117 Loss_G: -2.1490 (λL1=5.00)\n",
      "Epoch [14/70] Loss_D: -0.8508 Loss_G: -2.4953 (λL1=5.00)\n",
      "Epoch [15/70] Loss_D: -0.8514 Loss_G: -2.3577 (λL1=5.00)\n",
      "Epoch [16/70] Loss_D: 2.1503 Loss_G: -8.0661 (λL1=5.00)\n",
      "Epoch [17/70] Loss_D: -4.4050 Loss_G: -5.7672 (λL1=5.00)\n",
      "Epoch [18/70] Loss_D: -4.3403 Loss_G: -3.6381 (λL1=5.00)\n",
      "Epoch [19/70] Loss_D: 0.0149 Loss_G: 0.5445 (λL1=5.00)\n",
      "Epoch [20/70] Loss_D: 0.9266 Loss_G: 3.3172 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.1438, Corr=0.4014\n",
      "Epoch [21/70] Loss_D: -0.3659 Loss_G: 0.1503 (λL1=5.00)\n",
      "Epoch [22/70] Loss_D: -2.0758 Loss_G: -1.6607 (λL1=5.00)\n",
      "Epoch [23/70] Loss_D: 0.4678 Loss_G: 1.4454 (λL1=5.00)\n",
      "Epoch [24/70] Loss_D: -1.7292 Loss_G: 2.6230 (λL1=5.00)\n",
      "Epoch [25/70] Loss_D: -1.0801 Loss_G: 2.5961 (λL1=5.00)\n",
      "Epoch [26/70] Loss_D: -0.6068 Loss_G: 6.6846 (λL1=5.00)\n",
      "Epoch [27/70] Loss_D: -0.4552 Loss_G: 4.2125 (λL1=5.00)\n",
      "Epoch [28/70] Loss_D: 0.3484 Loss_G: 3.8597 (λL1=5.00)\n",
      "Epoch [29/70] Loss_D: -0.0687 Loss_G: 7.4737 (λL1=5.00)\n",
      "Epoch [30/70] Loss_D: 0.0569 Loss_G: 12.0593 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0603, Corr=0.4840\n",
      "Epoch [31/70] Loss_D: -0.1461 Loss_G: 12.6780 (λL1=5.00)\n",
      "Epoch [32/70] Loss_D: -0.1278 Loss_G: 13.7532 (λL1=5.00)\n",
      "Epoch [33/70] Loss_D: -0.0186 Loss_G: 14.2033 (λL1=5.00)\n",
      "Epoch [34/70] Loss_D: 0.1406 Loss_G: 14.0781 (λL1=5.00)\n",
      "Epoch [35/70] Loss_D: 0.0184 Loss_G: 14.4564 (λL1=5.00)\n",
      "Epoch [36/70] Loss_D: -0.0058 Loss_G: 14.3499 (λL1=5.00)\n",
      "Epoch [37/70] Loss_D: 0.0312 Loss_G: 14.4197 (λL1=5.00)\n",
      "Epoch [38/70] Loss_D: 0.2457 Loss_G: 13.1418 (λL1=5.00)\n",
      "Epoch [39/70] Loss_D: -0.1790 Loss_G: 13.2102 (λL1=5.00)\n",
      "Epoch [40/70] Loss_D: -0.0139 Loss_G: 13.1731 (λL1=5.00)\n",
      "[Epoch 40] Val mean MSE=0.0529, Corr=0.7895\n",
      "Epoch [41/70] Loss_D: 0.0181 Loss_G: 13.6384 (λL1=5.00)\n",
      "Epoch [42/70] Loss_D: -0.1823 Loss_G: 13.7267 (λL1=5.00)\n",
      "Epoch [43/70] Loss_D: 0.0254 Loss_G: 14.2547 (λL1=5.00)\n",
      "Epoch [44/70] Loss_D: 0.0434 Loss_G: 14.7273 (λL1=5.00)\n",
      "Epoch [45/70] Loss_D: -0.1018 Loss_G: 14.6081 (λL1=5.00)\n",
      "Epoch [46/70] Loss_D: -0.1784 Loss_G: 15.8565 (λL1=5.00)\n",
      "Epoch [47/70] Loss_D: 0.2401 Loss_G: 15.6428 (λL1=5.00)\n",
      "Epoch [48/70] Loss_D: -0.0894 Loss_G: 15.0888 (λL1=5.00)\n",
      "Epoch [49/70] Loss_D: 0.0891 Loss_G: 15.0351 (λL1=5.00)\n",
      "Epoch [50/70] Loss_D: 0.3055 Loss_G: 15.3624 (λL1=5.00)\n",
      "[Epoch 50] Val mean MSE=0.0449, Corr=0.9501\n",
      "Epoch [51/70] Loss_D: -0.1272 Loss_G: 14.5912 (λL1=5.00)\n",
      "Epoch [52/70] Loss_D: 0.0650 Loss_G: 15.9481 (λL1=5.00)\n",
      "Epoch [53/70] Loss_D: 0.1077 Loss_G: 14.3249 (λL1=5.00)\n",
      "Epoch [54/70] Loss_D: 0.2219 Loss_G: 14.7490 (λL1=5.00)\n",
      "Epoch [55/70] Loss_D: -0.0607 Loss_G: 13.6577 (λL1=5.00)\n",
      "Epoch [56/70] Loss_D: -0.0801 Loss_G: 14.6712 (λL1=5.00)\n",
      "Epoch [57/70] Loss_D: 0.0676 Loss_G: 12.7281 (λL1=5.00)\n",
      "Epoch [58/70] Loss_D: 0.3445 Loss_G: 14.6558 (λL1=5.00)\n",
      "Epoch [59/70] Loss_D: -0.2085 Loss_G: 15.7168 (λL1=5.00)\n",
      "Epoch [60/70] Loss_D: 0.3044 Loss_G: 13.5599 (λL1=5.00)\n",
      "[Epoch 60] Val mean MSE=0.0511, Corr=0.8905\n",
      "Epoch [61/70] Loss_D: -0.0994 Loss_G: 14.9464 (λL1=5.00)\n",
      "Epoch [62/70] Loss_D: -0.1604 Loss_G: 13.3317 (λL1=5.00)\n",
      "Epoch [63/70] Loss_D: -0.0056 Loss_G: 13.9787 (λL1=5.00)\n",
      "Epoch [64/70] Loss_D: -0.0102 Loss_G: 15.1614 (λL1=5.00)\n",
      "Epoch [65/70] Loss_D: 0.0172 Loss_G: 11.9919 (λL1=5.00)\n",
      "Epoch [66/70] Loss_D: 0.0196 Loss_G: 16.2811 (λL1=5.00)\n",
      "Epoch [67/70] Loss_D: 0.0456 Loss_G: 15.1092 (λL1=5.00)\n",
      "Epoch [68/70] Loss_D: -0.2982 Loss_G: 15.4904 (λL1=5.00)\n",
      "Epoch [69/70] Loss_D: -0.1039 Loss_G: 16.5144 (λL1=5.00)\n",
      "Epoch [70/70] Loss_D: 0.0759 Loss_G: 11.0063 (λL1=5.00)\n",
      "[Epoch 70] Val mean MSE=0.0568, Corr=0.7225\n",
      "Nejlepší epocha podle MSE: epoch       50.000000\n",
      "mean_MSE     0.044944\n",
      "Name: 4, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.055643    0.722955\n",
      "std     83.282651    0.075654    0.224312\n",
      "min      0.000000    0.001082    0.240987\n",
      "25%     71.750000    0.005810    0.594222\n",
      "50%    143.500000    0.015076    0.658827\n",
      "75%    215.250000    0.071848    0.980857\n",
      "max    287.000000    0.261263    0.988910\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs70_20250926_044924\n",
      "\n",
      "=== Spouštím běh: λ=5, epochs=80, výstup: results/lambda5_epochs80_20250926_045139 ===\n",
      "Epoch [1/80] Loss_D: -0.8237 Loss_G: 3.8563 (λL1=5.00)\n",
      "Epoch [2/80] Loss_D: -1.6165 Loss_G: -2.3793 (λL1=5.00)\n",
      "Epoch [3/80] Loss_D: 0.2127 Loss_G: -4.3266 (λL1=5.00)\n",
      "Epoch [4/80] Loss_D: 0.3495 Loss_G: -0.1384 (λL1=5.00)\n",
      "Epoch [5/80] Loss_D: 0.0147 Loss_G: -2.6519 (λL1=5.00)\n",
      "Epoch [6/80] Loss_D: 0.0775 Loss_G: -2.0359 (λL1=5.00)\n",
      "Epoch [7/80] Loss_D: -0.3736 Loss_G: -0.3292 (λL1=5.00)\n",
      "Epoch [8/80] Loss_D: -1.1484 Loss_G: -2.4673 (λL1=5.00)\n",
      "Epoch [9/80] Loss_D: -0.2951 Loss_G: -1.9665 (λL1=5.00)\n",
      "Epoch [10/80] Loss_D: -3.5943 Loss_G: -2.0668 (λL1=5.00)\n",
      "[Epoch 10] Val mean MSE=0.1353, Corr=0.6696\n",
      "Epoch [11/80] Loss_D: -1.5015 Loss_G: -1.7575 (λL1=5.00)\n",
      "Epoch [12/80] Loss_D: 0.2864 Loss_G: -1.3812 (λL1=5.00)\n",
      "Epoch [13/80] Loss_D: -1.9498 Loss_G: -2.2457 (λL1=5.00)\n",
      "Epoch [14/80] Loss_D: -1.7396 Loss_G: -0.3858 (λL1=5.00)\n",
      "Epoch [15/80] Loss_D: 0.8785 Loss_G: 0.2979 (λL1=5.00)\n",
      "Epoch [16/80] Loss_D: -1.6513 Loss_G: -0.0929 (λL1=5.00)\n",
      "Epoch [17/80] Loss_D: -2.1455 Loss_G: 0.0947 (λL1=5.00)\n",
      "Epoch [18/80] Loss_D: -0.4848 Loss_G: -0.4264 (λL1=5.00)\n",
      "Epoch [19/80] Loss_D: -1.3473 Loss_G: -1.6639 (λL1=5.00)\n",
      "Epoch [20/80] Loss_D: -0.3491 Loss_G: -1.2360 (λL1=5.00)\n",
      "[Epoch 20] Val mean MSE=0.0749, Corr=0.6615\n",
      "Epoch [21/80] Loss_D: -1.0730 Loss_G: -2.8779 (λL1=5.00)\n",
      "Epoch [22/80] Loss_D: 0.1633 Loss_G: -0.0946 (λL1=5.00)\n",
      "Epoch [23/80] Loss_D: 0.5338 Loss_G: 3.9826 (λL1=5.00)\n",
      "Epoch [24/80] Loss_D: 0.3057 Loss_G: 4.6100 (λL1=5.00)\n",
      "Epoch [25/80] Loss_D: 0.4476 Loss_G: 2.1955 (λL1=5.00)\n",
      "Epoch [26/80] Loss_D: 0.6663 Loss_G: 1.2952 (λL1=5.00)\n",
      "Epoch [27/80] Loss_D: 0.5031 Loss_G: 0.3518 (λL1=5.00)\n",
      "Epoch [28/80] Loss_D: 0.4527 Loss_G: -1.1978 (λL1=5.00)\n",
      "Epoch [29/80] Loss_D: 0.3998 Loss_G: -1.4200 (λL1=5.00)\n",
      "Epoch [30/80] Loss_D: 0.2073 Loss_G: -0.7485 (λL1=5.00)\n",
      "[Epoch 30] Val mean MSE=0.0488, Corr=0.6940\n",
      "Epoch [31/80] Loss_D: 0.0811 Loss_G: -0.4743 (λL1=5.00)\n",
      "Epoch [32/80] Loss_D: 0.1094 Loss_G: -0.8682 (λL1=5.00)\n",
      "Epoch [33/80] Loss_D: 0.2550 Loss_G: -1.0163 (λL1=5.00)\n",
      "Epoch [34/80] Loss_D: 0.0140 Loss_G: -0.9116 (λL1=5.00)\n",
      "Epoch [35/80] Loss_D: 0.2076 Loss_G: -1.2695 (λL1=5.00)\n",
      "Epoch [36/80] Loss_D: 0.1527 Loss_G: -1.9852 (λL1=5.00)\n",
      "Epoch [37/80] Loss_D: 0.0643 Loss_G: -1.7412 (λL1=5.00)\n",
      "Epoch [38/80] Loss_D: 0.0363 Loss_G: -1.8235 (λL1=5.00)\n",
      "Epoch [39/80] Loss_D: 0.0967 Loss_G: -2.2900 (λL1=5.00)\n",
      "Epoch [40/80] Loss_D: 0.1608 Loss_G: -1.6196 (λL1=5.00)\n",
      "[Epoch 40] Val mean MSE=0.0457, Corr=0.9330\n",
      "Epoch [41/80] Loss_D: 0.0824 Loss_G: -1.4857 (λL1=5.00)\n",
      "Epoch [42/80] Loss_D: 0.1374 Loss_G: -1.2833 (λL1=5.00)\n",
      "Epoch [43/80] Loss_D: 0.0508 Loss_G: -1.6008 (λL1=5.00)\n",
      "Epoch [44/80] Loss_D: 0.0751 Loss_G: -1.5365 (λL1=5.00)\n",
      "Epoch [45/80] Loss_D: 0.0524 Loss_G: -1.3611 (λL1=5.00)\n",
      "Epoch [46/80] Loss_D: -0.0318 Loss_G: -1.6775 (λL1=5.00)\n",
      "Epoch [47/80] Loss_D: 0.0715 Loss_G: -1.7109 (λL1=5.00)\n",
      "Epoch [48/80] Loss_D: 0.1129 Loss_G: -0.5200 (λL1=5.00)\n",
      "Epoch [49/80] Loss_D: 0.0473 Loss_G: -1.8394 (λL1=5.00)\n",
      "Epoch [50/80] Loss_D: 0.0548 Loss_G: -1.5179 (λL1=5.00)\n",
      "[Epoch 50] Val mean MSE=0.0467, Corr=0.8924\n",
      "Epoch [51/80] Loss_D: -0.1005 Loss_G: -2.4305 (λL1=5.00)\n",
      "Epoch [52/80] Loss_D: -0.2585 Loss_G: -2.4345 (λL1=5.00)\n",
      "Epoch [53/80] Loss_D: -0.0405 Loss_G: -2.4207 (λL1=5.00)\n",
      "Epoch [54/80] Loss_D: -0.1859 Loss_G: -2.2130 (λL1=5.00)\n",
      "Epoch [55/80] Loss_D: 0.0930 Loss_G: -2.1493 (λL1=5.00)\n",
      "Epoch [56/80] Loss_D: -0.0253 Loss_G: -1.8703 (λL1=5.00)\n",
      "Epoch [57/80] Loss_D: -0.0334 Loss_G: -2.8688 (λL1=5.00)\n",
      "Epoch [58/80] Loss_D: -0.0253 Loss_G: -2.1996 (λL1=5.00)\n",
      "Epoch [59/80] Loss_D: -0.0587 Loss_G: -2.5338 (λL1=5.00)\n",
      "Epoch [60/80] Loss_D: -0.1957 Loss_G: -2.9893 (λL1=5.00)\n",
      "[Epoch 60] Val mean MSE=0.0481, Corr=0.6257\n",
      "Epoch [61/80] Loss_D: 0.0544 Loss_G: -2.2462 (λL1=5.00)\n",
      "Epoch [62/80] Loss_D: 0.0011 Loss_G: -3.5250 (λL1=5.00)\n",
      "Epoch [63/80] Loss_D: 0.0834 Loss_G: -3.3519 (λL1=5.00)\n",
      "Epoch [64/80] Loss_D: 0.0006 Loss_G: -3.1317 (λL1=5.00)\n",
      "Epoch [65/80] Loss_D: -0.0876 Loss_G: -2.5282 (λL1=5.00)\n",
      "Epoch [66/80] Loss_D: -0.0935 Loss_G: -2.9363 (λL1=5.00)\n",
      "Epoch [67/80] Loss_D: -0.1508 Loss_G: -2.5949 (λL1=5.00)\n",
      "Epoch [68/80] Loss_D: -0.3086 Loss_G: -2.9742 (λL1=5.00)\n",
      "Epoch [69/80] Loss_D: -0.0926 Loss_G: -3.3198 (λL1=5.00)\n",
      "Epoch [70/80] Loss_D: 0.0324 Loss_G: -2.8792 (λL1=5.00)\n",
      "[Epoch 70] Val mean MSE=0.0504, Corr=0.7859\n",
      "Epoch [71/80] Loss_D: 0.0099 Loss_G: -4.1094 (λL1=5.00)\n",
      "Epoch [72/80] Loss_D: -0.3433 Loss_G: -3.6949 (λL1=5.00)\n",
      "Epoch [73/80] Loss_D: -0.0515 Loss_G: -3.6962 (λL1=5.00)\n",
      "Epoch [74/80] Loss_D: -0.3920 Loss_G: -4.0398 (λL1=5.00)\n",
      "Epoch [75/80] Loss_D: -0.0773 Loss_G: -3.9604 (λL1=5.00)\n",
      "Epoch [76/80] Loss_D: 0.0055 Loss_G: -5.3710 (λL1=5.00)\n",
      "Epoch [77/80] Loss_D: 0.0995 Loss_G: -4.4049 (λL1=5.00)\n",
      "Epoch [78/80] Loss_D: 0.0938 Loss_G: -4.7159 (λL1=5.00)\n",
      "Epoch [79/80] Loss_D: -0.2541 Loss_G: -3.0558 (λL1=5.00)\n",
      "Epoch [80/80] Loss_D: -0.0130 Loss_G: -4.9054 (λL1=5.00)\n",
      "[Epoch 80] Val mean MSE=0.0440, Corr=0.9473\n",
      "Nejlepší epocha podle MSE: epoch       80.000000\n",
      "mean_MSE     0.043977\n",
      "Name: 7, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.044059    0.947306\n",
      "std     83.282651    0.073342    0.035833\n",
      "min      0.000000    0.000365    0.845347\n",
      "25%     71.750000    0.004440    0.919572\n",
      "50%    143.500000    0.008818    0.944296\n",
      "75%    215.250000    0.026147    0.986271\n",
      "max    287.000000    0.258330    0.992241\n",
      "Běh dokončen. Výsledky ve složce: results/lambda5_epochs80_20250926_045139\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=10, výstup: results/lambda10_epochs10_20250926_045413 ===\n",
      "Epoch [1/10] Loss_D: -0.6137 Loss_G: 7.0634 (λL1=10.00)\n",
      "Epoch [2/10] Loss_D: -1.7553 Loss_G: -3.1377 (λL1=10.00)\n",
      "Epoch [3/10] Loss_D: 0.3787 Loss_G: -6.9790 (λL1=10.00)\n",
      "Epoch [4/10] Loss_D: 0.2046 Loss_G: -0.3510 (λL1=10.00)\n",
      "Epoch [5/10] Loss_D: 0.3665 Loss_G: 0.0811 (λL1=10.00)\n",
      "Epoch [6/10] Loss_D: -0.0333 Loss_G: 1.9421 (λL1=10.00)\n",
      "Epoch [7/10] Loss_D: -0.3320 Loss_G: 3.0737 (λL1=10.00)\n",
      "Epoch [8/10] Loss_D: -0.4110 Loss_G: 2.2153 (λL1=10.00)\n",
      "Epoch [9/10] Loss_D: 0.0753 Loss_G: -0.0620 (λL1=10.00)\n",
      "Epoch [10/10] Loss_D: 0.3936 Loss_G: -0.1172 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0520, Corr=0.6832\n",
      "Nejlepší epocha podle MSE: epoch       10.000000\n",
      "mean_MSE     0.052012\n",
      "Name: 0, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.053568    0.686419\n",
      "std     83.282651    0.077684    0.241931\n",
      "min      0.000000    0.001592    0.234575\n",
      "25%     71.750000    0.007348    0.490519\n",
      "50%    143.500000    0.014913    0.612897\n",
      "75%    215.250000    0.044452    0.969095\n",
      "max    287.000000    0.279202    0.982264\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs10_20250926_045413\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=20, výstup: results/lambda10_epochs20_20250926_045433 ===\n",
      "Epoch [1/20] Loss_D: -0.9119 Loss_G: 7.4746 (λL1=10.00)\n",
      "Epoch [2/20] Loss_D: -1.9433 Loss_G: -1.1144 (λL1=10.00)\n",
      "Epoch [3/20] Loss_D: 0.2474 Loss_G: -3.4843 (λL1=10.00)\n",
      "Epoch [4/20] Loss_D: 0.3489 Loss_G: 0.9867 (λL1=10.00)\n",
      "Epoch [5/20] Loss_D: 0.0551 Loss_G: -0.2548 (λL1=10.00)\n",
      "Epoch [6/20] Loss_D: -0.4966 Loss_G: 2.9708 (λL1=10.00)\n",
      "Epoch [7/20] Loss_D: -0.5700 Loss_G: 0.8307 (λL1=10.00)\n",
      "Epoch [8/20] Loss_D: -2.1274 Loss_G: -0.2583 (λL1=10.00)\n",
      "Epoch [9/20] Loss_D: -3.2107 Loss_G: 0.1591 (λL1=10.00)\n",
      "Epoch [10/20] Loss_D: -0.0939 Loss_G: 1.8305 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0803, Corr=0.5825\n",
      "Epoch [11/20] Loss_D: 0.0930 Loss_G: 4.5888 (λL1=10.00)\n",
      "Epoch [12/20] Loss_D: 0.2063 Loss_G: 6.7367 (λL1=10.00)\n",
      "Epoch [13/20] Loss_D: 0.3035 Loss_G: 5.8736 (λL1=10.00)\n",
      "Epoch [14/20] Loss_D: 0.6440 Loss_G: 5.1791 (λL1=10.00)\n",
      "Epoch [15/20] Loss_D: 0.6139 Loss_G: 5.1893 (λL1=10.00)\n",
      "Epoch [16/20] Loss_D: 0.3649 Loss_G: 5.0045 (λL1=10.00)\n",
      "Epoch [17/20] Loss_D: 0.1875 Loss_G: 5.2911 (λL1=10.00)\n",
      "Epoch [18/20] Loss_D: 0.3008 Loss_G: 4.9620 (λL1=10.00)\n",
      "Epoch [19/20] Loss_D: 0.1010 Loss_G: 4.5587 (λL1=10.00)\n",
      "Epoch [20/20] Loss_D: 0.0233 Loss_G: 4.4477 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0449, Corr=0.9210\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.044895\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.044798    0.919588\n",
      "std     83.282651    0.073967    0.057775\n",
      "min      0.000000    0.000330    0.775346\n",
      "25%     71.750000    0.004841    0.875660\n",
      "50%    143.500000    0.009642    0.909404\n",
      "75%    215.250000    0.024146    0.984114\n",
      "max    287.000000    0.263550    0.990375\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs20_20250926_045433\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=30, výstup: results/lambda10_epochs30_20250926_045513 ===\n",
      "Epoch [1/30] Loss_D: -1.0029 Loss_G: 7.7733 (λL1=10.00)\n",
      "Epoch [2/30] Loss_D: -2.2041 Loss_G: -0.3102 (λL1=10.00)\n",
      "Epoch [3/30] Loss_D: 0.1729 Loss_G: -3.7462 (λL1=10.00)\n",
      "Epoch [4/30] Loss_D: 0.2422 Loss_G: 5.5133 (λL1=10.00)\n",
      "Epoch [5/30] Loss_D: 0.4244 Loss_G: 4.5659 (λL1=10.00)\n",
      "Epoch [6/30] Loss_D: -0.2032 Loss_G: 4.6539 (λL1=10.00)\n",
      "Epoch [7/30] Loss_D: -0.6321 Loss_G: 5.8719 (λL1=10.00)\n",
      "Epoch [8/30] Loss_D: -0.7457 Loss_G: 4.9581 (λL1=10.00)\n",
      "Epoch [9/30] Loss_D: 0.0823 Loss_G: 3.0720 (λL1=10.00)\n",
      "Epoch [10/30] Loss_D: 0.5996 Loss_G: 1.8734 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0568, Corr=0.4913\n",
      "Epoch [11/30] Loss_D: 0.5038 Loss_G: 4.5216 (λL1=10.00)\n",
      "Epoch [12/30] Loss_D: 0.3180 Loss_G: 5.9926 (λL1=10.00)\n",
      "Epoch [13/30] Loss_D: 0.1369 Loss_G: 5.8674 (λL1=10.00)\n",
      "Epoch [14/30] Loss_D: 0.0431 Loss_G: 6.0308 (λL1=10.00)\n",
      "Epoch [15/30] Loss_D: 0.0664 Loss_G: 6.3425 (λL1=10.00)\n",
      "Epoch [16/30] Loss_D: 0.0682 Loss_G: 6.3395 (λL1=10.00)\n",
      "Epoch [17/30] Loss_D: 0.0720 Loss_G: 5.8369 (λL1=10.00)\n",
      "Epoch [18/30] Loss_D: -0.0153 Loss_G: 5.9591 (λL1=10.00)\n",
      "Epoch [19/30] Loss_D: 0.0715 Loss_G: 6.4660 (λL1=10.00)\n",
      "Epoch [20/30] Loss_D: 0.0785 Loss_G: 5.7244 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0448, Corr=0.9500\n",
      "Epoch [21/30] Loss_D: 0.0063 Loss_G: 5.7091 (λL1=10.00)\n",
      "Epoch [22/30] Loss_D: 0.0099 Loss_G: 5.2082 (λL1=10.00)\n",
      "Epoch [23/30] Loss_D: -0.0234 Loss_G: 5.2866 (λL1=10.00)\n",
      "Epoch [24/30] Loss_D: 0.0380 Loss_G: 5.0664 (λL1=10.00)\n",
      "Epoch [25/30] Loss_D: 0.1102 Loss_G: 4.9557 (λL1=10.00)\n",
      "Epoch [26/30] Loss_D: 0.0000 Loss_G: 5.1263 (λL1=10.00)\n",
      "Epoch [27/30] Loss_D: -0.0016 Loss_G: 4.7920 (λL1=10.00)\n",
      "Epoch [28/30] Loss_D: 0.0185 Loss_G: 4.5700 (λL1=10.00)\n",
      "Epoch [29/30] Loss_D: -0.0148 Loss_G: 4.0794 (λL1=10.00)\n",
      "Epoch [30/30] Loss_D: -0.0106 Loss_G: 4.4828 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0455, Corr=0.9403\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.044781\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.046699    0.942138\n",
      "std     83.282651    0.074016    0.049483\n",
      "min      0.000000    0.000424    0.753148\n",
      "25%     71.750000    0.003893    0.922372\n",
      "50%    143.500000    0.010215    0.944912\n",
      "75%    215.250000    0.033921    0.989391\n",
      "max    287.000000    0.260264    0.993291\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs30_20250926_045513\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=40, výstup: results/lambda10_epochs40_20250926_045611 ===\n",
      "Epoch [1/40] Loss_D: -0.7385 Loss_G: 7.0644 (λL1=10.00)\n",
      "Epoch [2/40] Loss_D: -2.1936 Loss_G: -2.0666 (λL1=10.00)\n",
      "Epoch [3/40] Loss_D: 0.2790 Loss_G: -4.9732 (λL1=10.00)\n",
      "Epoch [4/40] Loss_D: 0.1823 Loss_G: 0.1938 (λL1=10.00)\n",
      "Epoch [5/40] Loss_D: 0.1750 Loss_G: 1.3874 (λL1=10.00)\n",
      "Epoch [6/40] Loss_D: -0.1494 Loss_G: 1.7331 (λL1=10.00)\n",
      "Epoch [7/40] Loss_D: -0.1289 Loss_G: 0.7213 (λL1=10.00)\n",
      "Epoch [8/40] Loss_D: -1.0768 Loss_G: -1.1656 (λL1=10.00)\n",
      "Epoch [9/40] Loss_D: 0.0819 Loss_G: -2.0199 (λL1=10.00)\n",
      "Epoch [10/40] Loss_D: 0.3139 Loss_G: -1.5681 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0720, Corr=0.4853\n",
      "Epoch [11/40] Loss_D: 0.0516 Loss_G: -1.4787 (λL1=10.00)\n",
      "Epoch [12/40] Loss_D: 0.2193 Loss_G: -0.9838 (λL1=10.00)\n",
      "Epoch [13/40] Loss_D: 0.2067 Loss_G: 0.3124 (λL1=10.00)\n",
      "Epoch [14/40] Loss_D: 0.1425 Loss_G: 1.0631 (λL1=10.00)\n",
      "Epoch [15/40] Loss_D: 0.0961 Loss_G: 0.8706 (λL1=10.00)\n",
      "Epoch [16/40] Loss_D: 0.0331 Loss_G: 0.6544 (λL1=10.00)\n",
      "Epoch [17/40] Loss_D: 0.0360 Loss_G: 0.5713 (λL1=10.00)\n",
      "Epoch [18/40] Loss_D: 0.0499 Loss_G: 0.6639 (λL1=10.00)\n",
      "Epoch [19/40] Loss_D: 0.0709 Loss_G: 0.8799 (λL1=10.00)\n",
      "Epoch [20/40] Loss_D: 0.0298 Loss_G: 1.1486 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0489, Corr=0.9357\n",
      "Epoch [21/40] Loss_D: 0.0721 Loss_G: 1.0670 (λL1=10.00)\n",
      "Epoch [22/40] Loss_D: 0.0778 Loss_G: 1.3795 (λL1=10.00)\n",
      "Epoch [23/40] Loss_D: -0.0050 Loss_G: 1.5648 (λL1=10.00)\n",
      "Epoch [24/40] Loss_D: 0.0055 Loss_G: 1.6385 (λL1=10.00)\n",
      "Epoch [25/40] Loss_D: -0.0322 Loss_G: 1.8582 (λL1=10.00)\n",
      "Epoch [26/40] Loss_D: 0.0287 Loss_G: 1.5495 (λL1=10.00)\n",
      "Epoch [27/40] Loss_D: 0.0517 Loss_G: 1.3734 (λL1=10.00)\n",
      "Epoch [28/40] Loss_D: -0.0084 Loss_G: 1.3490 (λL1=10.00)\n",
      "Epoch [29/40] Loss_D: 0.0201 Loss_G: 1.1362 (λL1=10.00)\n",
      "Epoch [30/40] Loss_D: 0.0322 Loss_G: 1.6859 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0483, Corr=0.9230\n",
      "Epoch [31/40] Loss_D: -0.0311 Loss_G: 2.7085 (λL1=10.00)\n",
      "Epoch [32/40] Loss_D: 0.0431 Loss_G: 1.5515 (λL1=10.00)\n",
      "Epoch [33/40] Loss_D: -0.0179 Loss_G: 1.1912 (λL1=10.00)\n",
      "Epoch [34/40] Loss_D: -0.0483 Loss_G: 2.0200 (λL1=10.00)\n",
      "Epoch [35/40] Loss_D: -0.0836 Loss_G: 2.5633 (λL1=10.00)\n",
      "Epoch [36/40] Loss_D: -0.0507 Loss_G: 2.1368 (λL1=10.00)\n",
      "Epoch [37/40] Loss_D: 0.0890 Loss_G: 2.8787 (λL1=10.00)\n",
      "Epoch [38/40] Loss_D: -0.0304 Loss_G: 3.9274 (λL1=10.00)\n",
      "Epoch [39/40] Loss_D: -0.0172 Loss_G: 3.2366 (λL1=10.00)\n",
      "Epoch [40/40] Loss_D: 0.0152 Loss_G: 2.3105 (λL1=10.00)\n",
      "[Epoch 40] Val mean MSE=0.0478, Corr=0.9326\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.047838\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.046865    0.931099\n",
      "std     83.282651    0.075083    0.052670\n",
      "min      0.000000    0.000499    0.748633\n",
      "25%     71.750000    0.004910    0.903575\n",
      "50%    143.500000    0.010313    0.928639\n",
      "75%    215.250000    0.032098    0.984005\n",
      "max    287.000000    0.256952    0.989747\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs40_20250926_045611\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=50, výstup: results/lambda10_epochs50_20250926_045730 ===\n",
      "Epoch [1/50] Loss_D: -0.9864 Loss_G: 7.3942 (λL1=10.00)\n",
      "Epoch [2/50] Loss_D: -2.1258 Loss_G: -1.6751 (λL1=10.00)\n",
      "Epoch [3/50] Loss_D: 0.0953 Loss_G: -4.7453 (λL1=10.00)\n",
      "Epoch [4/50] Loss_D: 0.3964 Loss_G: 0.9873 (λL1=10.00)\n",
      "Epoch [5/50] Loss_D: 0.2194 Loss_G: 0.1866 (λL1=10.00)\n",
      "Epoch [6/50] Loss_D: -0.2179 Loss_G: 1.4315 (λL1=10.00)\n",
      "Epoch [7/50] Loss_D: -0.6313 Loss_G: 1.6739 (λL1=10.00)\n",
      "Epoch [8/50] Loss_D: -0.5585 Loss_G: 0.6677 (λL1=10.00)\n",
      "Epoch [9/50] Loss_D: 0.0861 Loss_G: -1.2286 (λL1=10.00)\n",
      "Epoch [10/50] Loss_D: 0.5987 Loss_G: -0.9424 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0588, Corr=0.5029\n",
      "Epoch [11/50] Loss_D: 0.4930 Loss_G: 0.3508 (λL1=10.00)\n",
      "Epoch [12/50] Loss_D: 0.2737 Loss_G: 1.7289 (λL1=10.00)\n",
      "Epoch [13/50] Loss_D: 0.1036 Loss_G: 2.4034 (λL1=10.00)\n",
      "Epoch [14/50] Loss_D: 0.1658 Loss_G: 2.7549 (λL1=10.00)\n",
      "Epoch [15/50] Loss_D: 0.0881 Loss_G: 2.1038 (λL1=10.00)\n",
      "Epoch [16/50] Loss_D: 0.0857 Loss_G: 2.1642 (λL1=10.00)\n",
      "Epoch [17/50] Loss_D: -0.0069 Loss_G: 2.5635 (λL1=10.00)\n",
      "Epoch [18/50] Loss_D: 0.0275 Loss_G: 2.5494 (λL1=10.00)\n",
      "Epoch [19/50] Loss_D: 0.0401 Loss_G: 2.7999 (λL1=10.00)\n",
      "Epoch [20/50] Loss_D: 0.1976 Loss_G: 2.4442 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0500, Corr=0.9420\n",
      "Epoch [21/50] Loss_D: 0.0801 Loss_G: 1.7645 (λL1=10.00)\n",
      "Epoch [22/50] Loss_D: 0.0533 Loss_G: 2.4313 (λL1=10.00)\n",
      "Epoch [23/50] Loss_D: 0.0282 Loss_G: 2.5625 (λL1=10.00)\n",
      "Epoch [24/50] Loss_D: 0.0480 Loss_G: 2.4117 (λL1=10.00)\n",
      "Epoch [25/50] Loss_D: -0.0486 Loss_G: 2.6577 (λL1=10.00)\n",
      "Epoch [26/50] Loss_D: -0.0025 Loss_G: 2.5688 (λL1=10.00)\n",
      "Epoch [27/50] Loss_D: 0.0082 Loss_G: 2.3046 (λL1=10.00)\n",
      "Epoch [28/50] Loss_D: 0.0705 Loss_G: 2.1150 (λL1=10.00)\n",
      "Epoch [29/50] Loss_D: -0.0017 Loss_G: 2.1613 (λL1=10.00)\n",
      "Epoch [30/50] Loss_D: 0.0578 Loss_G: 2.0070 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0446, Corr=0.9623\n",
      "Epoch [31/50] Loss_D: 0.0921 Loss_G: 2.1501 (λL1=10.00)\n",
      "Epoch [32/50] Loss_D: -0.0019 Loss_G: 1.9961 (λL1=10.00)\n",
      "Epoch [33/50] Loss_D: -0.0043 Loss_G: 2.3118 (λL1=10.00)\n",
      "Epoch [34/50] Loss_D: 0.0118 Loss_G: 2.3644 (λL1=10.00)\n",
      "Epoch [35/50] Loss_D: 0.0753 Loss_G: 2.7898 (λL1=10.00)\n",
      "Epoch [36/50] Loss_D: 0.0054 Loss_G: 2.4633 (λL1=10.00)\n",
      "Epoch [37/50] Loss_D: 0.0408 Loss_G: 2.5696 (λL1=10.00)\n",
      "Epoch [38/50] Loss_D: -0.0341 Loss_G: 2.3560 (λL1=10.00)\n",
      "Epoch [39/50] Loss_D: 0.0079 Loss_G: 2.0822 (λL1=10.00)\n",
      "Epoch [40/50] Loss_D: -0.0131 Loss_G: 2.2176 (λL1=10.00)\n",
      "[Epoch 40] Val mean MSE=0.0453, Corr=0.9460\n",
      "Epoch [41/50] Loss_D: 0.0094 Loss_G: 1.8568 (λL1=10.00)\n",
      "Epoch [42/50] Loss_D: -0.0320 Loss_G: 2.4069 (λL1=10.00)\n",
      "Epoch [43/50] Loss_D: 0.0489 Loss_G: 2.8561 (λL1=10.00)\n",
      "Epoch [44/50] Loss_D: -0.0307 Loss_G: 2.5935 (λL1=10.00)\n",
      "Epoch [45/50] Loss_D: -0.0836 Loss_G: 2.4933 (λL1=10.00)\n",
      "Epoch [46/50] Loss_D: 0.0519 Loss_G: 2.5954 (λL1=10.00)\n",
      "Epoch [47/50] Loss_D: -0.0066 Loss_G: 2.2782 (λL1=10.00)\n",
      "Epoch [48/50] Loss_D: -0.0534 Loss_G: 2.9936 (λL1=10.00)\n",
      "Epoch [49/50] Loss_D: 0.0210 Loss_G: 3.0308 (λL1=10.00)\n",
      "Epoch [50/50] Loss_D: -0.1069 Loss_G: 3.4091 (λL1=10.00)\n",
      "[Epoch 50] Val mean MSE=0.0444, Corr=0.9111\n",
      "Nejlepší epocha podle MSE: epoch       50.000000\n",
      "mean_MSE     0.044404\n",
      "Name: 4, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.044021    0.910060\n",
      "std     83.282651    0.074594    0.090882\n",
      "min      0.000000    0.000447    0.608462\n",
      "25%     71.750000    0.005351    0.881217\n",
      "50%    143.500000    0.009121    0.928491\n",
      "75%    215.250000    0.021862    0.984919\n",
      "max    287.000000    0.255866    0.991922\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs50_20250926_045730\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=60, výstup: results/lambda10_epochs60_20250926_045909 ===\n",
      "Epoch [1/60] Loss_D: -0.6719 Loss_G: 7.7409 (λL1=10.00)\n",
      "Epoch [2/60] Loss_D: -2.0105 Loss_G: 0.5617 (λL1=10.00)\n",
      "Epoch [3/60] Loss_D: 0.0648 Loss_G: -2.0340 (λL1=10.00)\n",
      "Epoch [4/60] Loss_D: 0.3218 Loss_G: 3.2287 (λL1=10.00)\n",
      "Epoch [5/60] Loss_D: 0.1376 Loss_G: 1.8621 (λL1=10.00)\n",
      "Epoch [6/60] Loss_D: -0.1034 Loss_G: 4.4238 (λL1=10.00)\n",
      "Epoch [7/60] Loss_D: -0.4839 Loss_G: 5.3389 (λL1=10.00)\n",
      "Epoch [8/60] Loss_D: -0.3945 Loss_G: 5.2183 (λL1=10.00)\n",
      "Epoch [9/60] Loss_D: 0.0588 Loss_G: 4.4395 (λL1=10.00)\n",
      "Epoch [10/60] Loss_D: 0.3463 Loss_G: 5.4627 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0508, Corr=0.7409\n",
      "Epoch [11/60] Loss_D: 0.2431 Loss_G: 7.1090 (λL1=10.00)\n",
      "Epoch [12/60] Loss_D: 0.1419 Loss_G: 6.7142 (λL1=10.00)\n",
      "Epoch [13/60] Loss_D: 0.0832 Loss_G: 6.9239 (λL1=10.00)\n",
      "Epoch [14/60] Loss_D: 0.1127 Loss_G: 7.3263 (λL1=10.00)\n",
      "Epoch [15/60] Loss_D: 0.0295 Loss_G: 6.4347 (λL1=10.00)\n",
      "Epoch [16/60] Loss_D: 0.0572 Loss_G: 6.8352 (λL1=10.00)\n",
      "Epoch [17/60] Loss_D: 0.0850 Loss_G: 6.9166 (λL1=10.00)\n",
      "Epoch [18/60] Loss_D: 0.0498 Loss_G: 6.5623 (λL1=10.00)\n",
      "Epoch [19/60] Loss_D: 0.0071 Loss_G: 6.6369 (λL1=10.00)\n",
      "Epoch [20/60] Loss_D: -0.0125 Loss_G: 6.6984 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0471, Corr=0.9509\n",
      "Epoch [21/60] Loss_D: 0.0361 Loss_G: 6.7499 (λL1=10.00)\n",
      "Epoch [22/60] Loss_D: 0.0846 Loss_G: 6.7087 (λL1=10.00)\n",
      "Epoch [23/60] Loss_D: 0.0630 Loss_G: 7.0111 (λL1=10.00)\n",
      "Epoch [24/60] Loss_D: -0.0270 Loss_G: 7.4201 (λL1=10.00)\n",
      "Epoch [25/60] Loss_D: -0.0501 Loss_G: 7.1389 (λL1=10.00)\n",
      "Epoch [26/60] Loss_D: 0.0219 Loss_G: 7.0164 (λL1=10.00)\n",
      "Epoch [27/60] Loss_D: -0.0184 Loss_G: 7.0584 (λL1=10.00)\n",
      "Epoch [28/60] Loss_D: 0.0501 Loss_G: 6.9427 (λL1=10.00)\n",
      "Epoch [29/60] Loss_D: 0.0692 Loss_G: 6.5016 (λL1=10.00)\n",
      "Epoch [30/60] Loss_D: -0.0639 Loss_G: 6.4884 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0457, Corr=0.9642\n",
      "Epoch [31/60] Loss_D: 0.0205 Loss_G: 6.4937 (λL1=10.00)\n",
      "Epoch [32/60] Loss_D: 0.0770 Loss_G: 6.3685 (λL1=10.00)\n",
      "Epoch [33/60] Loss_D: -0.0899 Loss_G: 6.5064 (λL1=10.00)\n",
      "Epoch [34/60] Loss_D: -0.0070 Loss_G: 7.1770 (λL1=10.00)\n",
      "Epoch [35/60] Loss_D: 0.0120 Loss_G: 7.1228 (λL1=10.00)\n",
      "Epoch [36/60] Loss_D: -0.1266 Loss_G: 7.1900 (λL1=10.00)\n",
      "Epoch [37/60] Loss_D: -0.0817 Loss_G: 7.6310 (λL1=10.00)\n",
      "Epoch [38/60] Loss_D: -0.0041 Loss_G: 7.4252 (λL1=10.00)\n",
      "Epoch [39/60] Loss_D: -0.0034 Loss_G: 6.7095 (λL1=10.00)\n",
      "Epoch [40/60] Loss_D: -0.1042 Loss_G: 6.7899 (λL1=10.00)\n",
      "[Epoch 40] Val mean MSE=0.0442, Corr=0.9651\n",
      "Epoch [41/60] Loss_D: -0.0356 Loss_G: 6.8995 (λL1=10.00)\n",
      "Epoch [42/60] Loss_D: -0.0289 Loss_G: 6.8535 (λL1=10.00)\n",
      "Epoch [43/60] Loss_D: -0.0990 Loss_G: 6.9399 (λL1=10.00)\n",
      "Epoch [44/60] Loss_D: -0.0596 Loss_G: 6.9757 (λL1=10.00)\n",
      "Epoch [45/60] Loss_D: -0.0824 Loss_G: 7.0449 (λL1=10.00)\n",
      "Epoch [46/60] Loss_D: -0.0858 Loss_G: 6.8478 (λL1=10.00)\n",
      "Epoch [47/60] Loss_D: -0.1465 Loss_G: 6.9428 (λL1=10.00)\n",
      "Epoch [48/60] Loss_D: -0.0716 Loss_G: 6.6499 (λL1=10.00)\n",
      "Epoch [49/60] Loss_D: -0.0864 Loss_G: 6.2800 (λL1=10.00)\n",
      "Epoch [50/60] Loss_D: -0.0684 Loss_G: 6.5443 (λL1=10.00)\n",
      "[Epoch 50] Val mean MSE=0.0429, Corr=0.9685\n",
      "Epoch [51/60] Loss_D: -0.0374 Loss_G: 5.4792 (λL1=10.00)\n",
      "Epoch [52/60] Loss_D: -0.0937 Loss_G: 6.1905 (λL1=10.00)\n",
      "Epoch [53/60] Loss_D: -0.1622 Loss_G: 6.1124 (λL1=10.00)\n",
      "Epoch [54/60] Loss_D: -0.1484 Loss_G: 5.7514 (λL1=10.00)\n",
      "Epoch [55/60] Loss_D: -0.0150 Loss_G: 6.3308 (λL1=10.00)\n",
      "Epoch [56/60] Loss_D: -0.1591 Loss_G: 6.1527 (λL1=10.00)\n",
      "Epoch [57/60] Loss_D: -0.1933 Loss_G: 6.4700 (λL1=10.00)\n",
      "Epoch [58/60] Loss_D: -0.0802 Loss_G: 6.0854 (λL1=10.00)\n",
      "Epoch [59/60] Loss_D: -0.0771 Loss_G: 6.0945 (λL1=10.00)\n",
      "Epoch [60/60] Loss_D: -0.0469 Loss_G: 4.9416 (λL1=10.00)\n",
      "[Epoch 60] Val mean MSE=0.0453, Corr=0.9598\n",
      "Nejlepší epocha podle MSE: epoch       50.000000\n",
      "mean_MSE     0.042933\n",
      "Name: 4, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045451    0.960351\n",
      "std     83.282651    0.074708    0.039588\n",
      "min      0.000000    0.000800    0.803359\n",
      "25%     71.750000    0.004592    0.952118\n",
      "50%    143.500000    0.008966    0.971819\n",
      "75%    215.250000    0.025846    0.989022\n",
      "max    287.000000    0.257025    0.993574\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs60_20250926_045909\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=70, výstup: results/lambda10_epochs70_20250926_050105 ===\n",
      "Epoch [1/70] Loss_D: -1.0256 Loss_G: 7.5162 (λL1=10.00)\n",
      "Epoch [2/70] Loss_D: -2.0169 Loss_G: -2.1090 (λL1=10.00)\n",
      "Epoch [3/70] Loss_D: 0.0464 Loss_G: -4.5666 (λL1=10.00)\n",
      "Epoch [4/70] Loss_D: 0.3056 Loss_G: 2.0045 (λL1=10.00)\n",
      "Epoch [5/70] Loss_D: -0.6516 Loss_G: -0.6790 (λL1=10.00)\n",
      "Epoch [6/70] Loss_D: -0.0906 Loss_G: -0.7602 (λL1=10.00)\n",
      "Epoch [7/70] Loss_D: -0.1106 Loss_G: 2.9376 (λL1=10.00)\n",
      "Epoch [8/70] Loss_D: -0.9977 Loss_G: 2.4551 (λL1=10.00)\n",
      "Epoch [9/70] Loss_D: -3.4082 Loss_G: 0.5491 (λL1=10.00)\n",
      "Epoch [10/70] Loss_D: -0.5228 Loss_G: 1.2765 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.1246, Corr=0.5921\n",
      "Epoch [11/70] Loss_D: -1.1621 Loss_G: 1.6254 (λL1=10.00)\n",
      "Epoch [12/70] Loss_D: -4.1499 Loss_G: 3.6028 (λL1=10.00)\n",
      "Epoch [13/70] Loss_D: -0.3303 Loss_G: 4.7522 (λL1=10.00)\n",
      "Epoch [14/70] Loss_D: -0.6243 Loss_G: 2.8579 (λL1=10.00)\n",
      "Epoch [15/70] Loss_D: -0.6309 Loss_G: 3.8969 (λL1=10.00)\n",
      "Epoch [16/70] Loss_D: 0.1463 Loss_G: 2.3914 (λL1=10.00)\n",
      "Epoch [17/70] Loss_D: 0.5658 Loss_G: 5.1244 (λL1=10.00)\n",
      "Epoch [18/70] Loss_D: 0.6905 Loss_G: 9.4122 (λL1=10.00)\n",
      "Epoch [19/70] Loss_D: 0.7680 Loss_G: 11.8457 (λL1=10.00)\n",
      "Epoch [20/70] Loss_D: 0.5583 Loss_G: 11.9871 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0531, Corr=0.6112\n",
      "Epoch [21/70] Loss_D: 0.4250 Loss_G: 11.5243 (λL1=10.00)\n",
      "Epoch [22/70] Loss_D: 0.2432 Loss_G: 9.7909 (λL1=10.00)\n",
      "Epoch [23/70] Loss_D: 0.2607 Loss_G: 8.6250 (λL1=10.00)\n",
      "Epoch [24/70] Loss_D: 0.0328 Loss_G: 6.6677 (λL1=10.00)\n",
      "Epoch [25/70] Loss_D: 0.0094 Loss_G: 6.3696 (λL1=10.00)\n",
      "Epoch [26/70] Loss_D: 0.1269 Loss_G: 7.0411 (λL1=10.00)\n",
      "Epoch [27/70] Loss_D: 0.1072 Loss_G: 7.4455 (λL1=10.00)\n",
      "Epoch [28/70] Loss_D: 0.1988 Loss_G: 7.2837 (λL1=10.00)\n",
      "Epoch [29/70] Loss_D: 0.1346 Loss_G: 6.4288 (λL1=10.00)\n",
      "Epoch [30/70] Loss_D: 0.0535 Loss_G: 6.0658 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0442, Corr=0.9399\n",
      "Epoch [31/70] Loss_D: 0.0169 Loss_G: 6.1739 (λL1=10.00)\n",
      "Epoch [32/70] Loss_D: 0.0359 Loss_G: 5.8879 (λL1=10.00)\n",
      "Epoch [33/70] Loss_D: -0.0635 Loss_G: 5.7684 (λL1=10.00)\n",
      "Epoch [34/70] Loss_D: -0.0097 Loss_G: 6.0966 (λL1=10.00)\n",
      "Epoch [35/70] Loss_D: -0.0258 Loss_G: 5.9820 (λL1=10.00)\n",
      "Epoch [36/70] Loss_D: 0.1619 Loss_G: 5.5944 (λL1=10.00)\n",
      "Epoch [37/70] Loss_D: -0.1100 Loss_G: 7.0096 (λL1=10.00)\n",
      "Epoch [38/70] Loss_D: -0.0984 Loss_G: 6.8845 (λL1=10.00)\n",
      "Epoch [39/70] Loss_D: 0.0290 Loss_G: 6.2979 (λL1=10.00)\n",
      "Epoch [40/70] Loss_D: 0.0482 Loss_G: 5.8256 (λL1=10.00)\n",
      "[Epoch 40] Val mean MSE=0.0473, Corr=0.9387\n",
      "Epoch [41/70] Loss_D: -0.3198 Loss_G: 5.7906 (λL1=10.00)\n",
      "Epoch [42/70] Loss_D: 0.0819 Loss_G: 4.7528 (λL1=10.00)\n",
      "Epoch [43/70] Loss_D: 0.1569 Loss_G: 4.7324 (λL1=10.00)\n",
      "Epoch [44/70] Loss_D: 0.0458 Loss_G: 4.8121 (λL1=10.00)\n",
      "Epoch [45/70] Loss_D: -0.0397 Loss_G: 3.3778 (λL1=10.00)\n",
      "Epoch [46/70] Loss_D: 0.1007 Loss_G: 4.3651 (λL1=10.00)\n",
      "Epoch [47/70] Loss_D: -0.1522 Loss_G: 3.2281 (λL1=10.00)\n",
      "Epoch [48/70] Loss_D: -0.0442 Loss_G: 2.7328 (λL1=10.00)\n",
      "Epoch [49/70] Loss_D: -0.0505 Loss_G: 3.6964 (λL1=10.00)\n",
      "Epoch [50/70] Loss_D: -0.1393 Loss_G: 5.3589 (λL1=10.00)\n",
      "[Epoch 50] Val mean MSE=0.0484, Corr=0.9321\n",
      "Epoch [51/70] Loss_D: -0.0491 Loss_G: 4.6516 (λL1=10.00)\n",
      "Epoch [52/70] Loss_D: 0.0642 Loss_G: 5.0072 (λL1=10.00)\n",
      "Epoch [53/70] Loss_D: -0.0407 Loss_G: 4.7834 (λL1=10.00)\n",
      "Epoch [54/70] Loss_D: 0.0146 Loss_G: 2.8371 (λL1=10.00)\n",
      "Epoch [55/70] Loss_D: 0.0113 Loss_G: 4.4772 (λL1=10.00)\n",
      "Epoch [56/70] Loss_D: -0.0857 Loss_G: 3.6423 (λL1=10.00)\n",
      "Epoch [57/70] Loss_D: 0.0642 Loss_G: 3.6331 (λL1=10.00)\n",
      "Epoch [58/70] Loss_D: -0.2399 Loss_G: 4.1761 (λL1=10.00)\n",
      "Epoch [59/70] Loss_D: -0.0101 Loss_G: 4.3586 (λL1=10.00)\n",
      "Epoch [60/70] Loss_D: 0.0198 Loss_G: 4.8126 (λL1=10.00)\n",
      "[Epoch 60] Val mean MSE=0.0449, Corr=0.8902\n",
      "Epoch [61/70] Loss_D: 0.0182 Loss_G: 4.1961 (λL1=10.00)\n",
      "Epoch [62/70] Loss_D: -0.0919 Loss_G: 4.1444 (λL1=10.00)\n",
      "Epoch [63/70] Loss_D: -0.1148 Loss_G: 5.1305 (λL1=10.00)\n",
      "Epoch [64/70] Loss_D: 0.0296 Loss_G: 3.9952 (λL1=10.00)\n",
      "Epoch [65/70] Loss_D: -0.1061 Loss_G: 6.3761 (λL1=10.00)\n",
      "Epoch [66/70] Loss_D: 0.0099 Loss_G: 4.6134 (λL1=10.00)\n",
      "Epoch [67/70] Loss_D: 0.2052 Loss_G: 5.6029 (λL1=10.00)\n",
      "Epoch [68/70] Loss_D: -0.1130 Loss_G: 6.3339 (λL1=10.00)\n",
      "Epoch [69/70] Loss_D: -0.0128 Loss_G: 5.7053 (λL1=10.00)\n",
      "Epoch [70/70] Loss_D: -0.1589 Loss_G: 4.1374 (λL1=10.00)\n",
      "[Epoch 70] Val mean MSE=0.0528, Corr=0.8567\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.044194\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.051878    0.855637\n",
      "std     83.282651    0.076369    0.116279\n",
      "min      0.000000    0.001284    0.516519\n",
      "25%     71.750000    0.005724    0.800552\n",
      "50%    143.500000    0.012518    0.839546\n",
      "75%    215.250000    0.051440    0.976503\n",
      "max    287.000000    0.297631    0.991104\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs70_20250926_050105\n",
      "\n",
      "=== Spouštím běh: λ=10, epochs=80, výstup: results/lambda10_epochs80_20250926_050321 ===\n",
      "Epoch [1/80] Loss_D: -1.4961 Loss_G: 7.1616 (λL1=10.00)\n",
      "Epoch [2/80] Loss_D: -2.6785 Loss_G: -4.7694 (λL1=10.00)\n",
      "Epoch [3/80] Loss_D: 0.4920 Loss_G: -7.8880 (λL1=10.00)\n",
      "Epoch [4/80] Loss_D: 0.1202 Loss_G: -0.8483 (λL1=10.00)\n",
      "Epoch [5/80] Loss_D: 0.3884 Loss_G: -0.2785 (λL1=10.00)\n",
      "Epoch [6/80] Loss_D: -0.2814 Loss_G: -0.0932 (λL1=10.00)\n",
      "Epoch [7/80] Loss_D: -0.9061 Loss_G: 0.7428 (λL1=10.00)\n",
      "Epoch [8/80] Loss_D: -1.0339 Loss_G: 0.1380 (λL1=10.00)\n",
      "Epoch [9/80] Loss_D: -0.3128 Loss_G: -1.6687 (λL1=10.00)\n",
      "Epoch [10/80] Loss_D: 0.3968 Loss_G: -1.4991 (λL1=10.00)\n",
      "[Epoch 10] Val mean MSE=0.0557, Corr=0.6751\n",
      "Epoch [11/80] Loss_D: 0.5472 Loss_G: 0.0990 (λL1=10.00)\n",
      "Epoch [12/80] Loss_D: 0.4665 Loss_G: 2.1537 (λL1=10.00)\n",
      "Epoch [13/80] Loss_D: 0.1656 Loss_G: 2.2989 (λL1=10.00)\n",
      "Epoch [14/80] Loss_D: -0.0034 Loss_G: 2.6542 (λL1=10.00)\n",
      "Epoch [15/80] Loss_D: 0.0859 Loss_G: 2.8787 (λL1=10.00)\n",
      "Epoch [16/80] Loss_D: 0.0072 Loss_G: 3.6093 (λL1=10.00)\n",
      "Epoch [17/80] Loss_D: -0.0016 Loss_G: 3.9912 (λL1=10.00)\n",
      "Epoch [18/80] Loss_D: 0.1577 Loss_G: 4.0519 (λL1=10.00)\n",
      "Epoch [19/80] Loss_D: 0.1182 Loss_G: 4.5466 (λL1=10.00)\n",
      "Epoch [20/80] Loss_D: 0.1063 Loss_G: 4.5395 (λL1=10.00)\n",
      "[Epoch 20] Val mean MSE=0.0490, Corr=0.9345\n",
      "Epoch [21/80] Loss_D: 0.1419 Loss_G: 4.3644 (λL1=10.00)\n",
      "Epoch [22/80] Loss_D: 0.0362 Loss_G: 4.0569 (λL1=10.00)\n",
      "Epoch [23/80] Loss_D: 0.0148 Loss_G: 4.4431 (λL1=10.00)\n",
      "Epoch [24/80] Loss_D: 0.0108 Loss_G: 4.7839 (λL1=10.00)\n",
      "Epoch [25/80] Loss_D: 0.0775 Loss_G: 4.4162 (λL1=10.00)\n",
      "Epoch [26/80] Loss_D: -0.0041 Loss_G: 4.3902 (λL1=10.00)\n",
      "Epoch [27/80] Loss_D: 0.0764 Loss_G: 4.6729 (λL1=10.00)\n",
      "Epoch [28/80] Loss_D: 0.0757 Loss_G: 4.3842 (λL1=10.00)\n",
      "Epoch [29/80] Loss_D: 0.0286 Loss_G: 4.5869 (λL1=10.00)\n",
      "Epoch [30/80] Loss_D: -0.0291 Loss_G: 4.4800 (λL1=10.00)\n",
      "[Epoch 30] Val mean MSE=0.0463, Corr=0.9461\n",
      "Epoch [31/80] Loss_D: 0.0477 Loss_G: 4.3409 (λL1=10.00)\n",
      "Epoch [32/80] Loss_D: 0.0033 Loss_G: 3.9445 (λL1=10.00)\n",
      "Epoch [33/80] Loss_D: 0.0101 Loss_G: 4.1108 (λL1=10.00)\n",
      "Epoch [34/80] Loss_D: -0.0357 Loss_G: 4.3185 (λL1=10.00)\n",
      "Epoch [35/80] Loss_D: 0.0867 Loss_G: 4.0049 (λL1=10.00)\n",
      "Epoch [36/80] Loss_D: -0.0409 Loss_G: 4.1486 (λL1=10.00)\n",
      "Epoch [37/80] Loss_D: -0.0253 Loss_G: 3.7719 (λL1=10.00)\n",
      "Epoch [38/80] Loss_D: -0.0661 Loss_G: 4.1856 (λL1=10.00)\n",
      "Epoch [39/80] Loss_D: 0.0154 Loss_G: 4.7877 (λL1=10.00)\n",
      "Epoch [40/80] Loss_D: 0.0854 Loss_G: 4.2547 (λL1=10.00)\n",
      "[Epoch 40] Val mean MSE=0.0444, Corr=0.9195\n",
      "Epoch [41/80] Loss_D: -0.0472 Loss_G: 4.1225 (λL1=10.00)\n",
      "Epoch [42/80] Loss_D: -0.0649 Loss_G: 4.6735 (λL1=10.00)\n",
      "Epoch [43/80] Loss_D: -0.0126 Loss_G: 4.7120 (λL1=10.00)\n",
      "Epoch [44/80] Loss_D: 0.0093 Loss_G: 3.8710 (λL1=10.00)\n",
      "Epoch [45/80] Loss_D: -0.0744 Loss_G: 4.1309 (λL1=10.00)\n",
      "Epoch [46/80] Loss_D: 0.0359 Loss_G: 4.1229 (λL1=10.00)\n",
      "Epoch [47/80] Loss_D: -0.1374 Loss_G: 4.4704 (λL1=10.00)\n",
      "Epoch [48/80] Loss_D: -0.1846 Loss_G: 5.0337 (λL1=10.00)\n",
      "Epoch [49/80] Loss_D: -0.0578 Loss_G: 4.9850 (λL1=10.00)\n",
      "Epoch [50/80] Loss_D: 0.0131 Loss_G: 5.0605 (λL1=10.00)\n",
      "[Epoch 50] Val mean MSE=0.0473, Corr=0.9277\n",
      "Epoch [51/80] Loss_D: 0.0412 Loss_G: 5.4424 (λL1=10.00)\n",
      "Epoch [52/80] Loss_D: -0.0958 Loss_G: 4.5165 (λL1=10.00)\n",
      "Epoch [53/80] Loss_D: -0.1052 Loss_G: 4.8184 (λL1=10.00)\n",
      "Epoch [54/80] Loss_D: 0.0030 Loss_G: 5.2855 (λL1=10.00)\n",
      "Epoch [55/80] Loss_D: -0.0142 Loss_G: 4.7606 (λL1=10.00)\n",
      "Epoch [56/80] Loss_D: 0.0634 Loss_G: 4.1376 (λL1=10.00)\n",
      "Epoch [57/80] Loss_D: -0.0257 Loss_G: 4.5586 (λL1=10.00)\n",
      "Epoch [58/80] Loss_D: 0.0516 Loss_G: 5.4364 (λL1=10.00)\n",
      "Epoch [59/80] Loss_D: -0.0662 Loss_G: 3.5183 (λL1=10.00)\n",
      "Epoch [60/80] Loss_D: -0.0027 Loss_G: 5.3048 (λL1=10.00)\n",
      "[Epoch 60] Val mean MSE=0.0519, Corr=0.9309\n",
      "Epoch [61/80] Loss_D: 0.0719 Loss_G: 5.6558 (λL1=10.00)\n",
      "Epoch [62/80] Loss_D: -0.0995 Loss_G: 3.0446 (λL1=10.00)\n",
      "Epoch [63/80] Loss_D: 0.1507 Loss_G: 5.7006 (λL1=10.00)\n",
      "Epoch [64/80] Loss_D: -0.0058 Loss_G: 5.9738 (λL1=10.00)\n",
      "Epoch [65/80] Loss_D: 0.0600 Loss_G: 3.5712 (λL1=10.00)\n",
      "Epoch [66/80] Loss_D: -0.0031 Loss_G: 5.7174 (λL1=10.00)\n",
      "Epoch [67/80] Loss_D: -0.0267 Loss_G: 6.0428 (λL1=10.00)\n",
      "Epoch [68/80] Loss_D: 0.1026 Loss_G: 5.0988 (λL1=10.00)\n",
      "Epoch [69/80] Loss_D: -0.0721 Loss_G: 7.2797 (λL1=10.00)\n",
      "Epoch [70/80] Loss_D: -0.0948 Loss_G: 4.5476 (λL1=10.00)\n",
      "[Epoch 70] Val mean MSE=0.0470, Corr=0.9253\n",
      "Epoch [71/80] Loss_D: 0.0185 Loss_G: 5.5392 (λL1=10.00)\n",
      "Epoch [72/80] Loss_D: 0.0054 Loss_G: 6.6443 (λL1=10.00)\n",
      "Epoch [73/80] Loss_D: -0.0472 Loss_G: 5.3238 (λL1=10.00)\n",
      "Epoch [74/80] Loss_D: -0.0610 Loss_G: 6.5079 (λL1=10.00)\n",
      "Epoch [75/80] Loss_D: 0.0848 Loss_G: 4.8688 (λL1=10.00)\n",
      "Epoch [76/80] Loss_D: 0.0019 Loss_G: 6.3736 (λL1=10.00)\n",
      "Epoch [77/80] Loss_D: -0.0409 Loss_G: 5.2292 (λL1=10.00)\n",
      "Epoch [78/80] Loss_D: 0.1149 Loss_G: 6.3259 (λL1=10.00)\n",
      "Epoch [79/80] Loss_D: 0.0609 Loss_G: 5.4919 (λL1=10.00)\n",
      "Epoch [80/80] Loss_D: -0.1126 Loss_G: 5.6403 (λL1=10.00)\n",
      "[Epoch 80] Val mean MSE=0.0458, Corr=0.9642\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.044389\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045598    0.963182\n",
      "std     83.282651    0.073653    0.023078\n",
      "min      0.000000    0.000608    0.879714\n",
      "25%     71.750000    0.004541    0.948444\n",
      "50%    143.500000    0.010266    0.968671\n",
      "75%    215.250000    0.029318    0.980117\n",
      "max    287.000000    0.265467    0.994934\n",
      "Běh dokončen. Výsledky ve složce: results/lambda10_epochs80_20250926_050321\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=10, výstup: results/lambda15_epochs10_20250926_050554 ===\n",
      "Epoch [1/10] Loss_D: -1.0021 Loss_G: 10.1005 (λL1=15.00)\n",
      "Epoch [2/10] Loss_D: -2.3626 Loss_G: -5.1621 (λL1=15.00)\n",
      "Epoch [3/10] Loss_D: 0.0999 Loss_G: -9.8465 (λL1=15.00)\n",
      "Epoch [4/10] Loss_D: 0.2778 Loss_G: -2.7505 (λL1=15.00)\n",
      "Epoch [5/10] Loss_D: 0.4745 Loss_G: 0.0594 (λL1=15.00)\n",
      "Epoch [6/10] Loss_D: 0.0274 Loss_G: -1.2719 (λL1=15.00)\n",
      "Epoch [7/10] Loss_D: -0.1684 Loss_G: -1.1172 (λL1=15.00)\n",
      "Epoch [8/10] Loss_D: -0.1871 Loss_G: -1.8748 (λL1=15.00)\n",
      "Epoch [9/10] Loss_D: -0.0274 Loss_G: -4.8097 (λL1=15.00)\n",
      "Epoch [10/10] Loss_D: 0.2623 Loss_G: -5.6101 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0556, Corr=0.7599\n",
      "Nejlepší epocha podle MSE: epoch       10.000000\n",
      "mean_MSE     0.055645\n",
      "Name: 0, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.052767    0.766469\n",
      "std     83.282651    0.075335    0.177816\n",
      "min      0.000000    0.000933    0.374873\n",
      "25%     71.750000    0.006398    0.629805\n",
      "50%    143.500000    0.016580    0.719213\n",
      "75%    215.250000    0.046960    0.970928\n",
      "max    287.000000    0.274390    0.985141\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs10_20250926_050554\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=20, výstup: results/lambda15_epochs20_20250926_050613 ===\n",
      "Epoch [1/20] Loss_D: -1.2127 Loss_G: 10.7124 (λL1=15.00)\n",
      "Epoch [2/20] Loss_D: -2.7962 Loss_G: -3.1303 (λL1=15.00)\n",
      "Epoch [3/20] Loss_D: 0.3475 Loss_G: -6.2493 (λL1=15.00)\n",
      "Epoch [4/20] Loss_D: 0.2248 Loss_G: 2.5447 (λL1=15.00)\n",
      "Epoch [5/20] Loss_D: 0.4127 Loss_G: 2.9424 (λL1=15.00)\n",
      "Epoch [6/20] Loss_D: -0.1814 Loss_G: 3.8397 (λL1=15.00)\n",
      "Epoch [7/20] Loss_D: -0.4453 Loss_G: 3.8649 (λL1=15.00)\n",
      "Epoch [8/20] Loss_D: -0.4014 Loss_G: 2.9923 (λL1=15.00)\n",
      "Epoch [9/20] Loss_D: 0.2524 Loss_G: 0.5276 (λL1=15.00)\n",
      "Epoch [10/20] Loss_D: 0.5083 Loss_G: 1.9839 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0523, Corr=0.6715\n",
      "Epoch [11/20] Loss_D: 0.4014 Loss_G: 4.0674 (λL1=15.00)\n",
      "Epoch [12/20] Loss_D: 0.2115 Loss_G: 4.6913 (λL1=15.00)\n",
      "Epoch [13/20] Loss_D: 0.1177 Loss_G: 4.1460 (λL1=15.00)\n",
      "Epoch [14/20] Loss_D: 0.1013 Loss_G: 4.0497 (λL1=15.00)\n",
      "Epoch [15/20] Loss_D: 0.1102 Loss_G: 3.3783 (λL1=15.00)\n",
      "Epoch [16/20] Loss_D: 0.1030 Loss_G: 3.2433 (λL1=15.00)\n",
      "Epoch [17/20] Loss_D: 0.0625 Loss_G: 3.2632 (λL1=15.00)\n",
      "Epoch [18/20] Loss_D: 0.0664 Loss_G: 3.0088 (λL1=15.00)\n",
      "Epoch [19/20] Loss_D: 0.0684 Loss_G: 3.0630 (λL1=15.00)\n",
      "Epoch [20/20] Loss_D: 0.0557 Loss_G: 3.0896 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0465, Corr=0.9538\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.046484\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045009    0.953306\n",
      "std     83.282651    0.073244    0.033628\n",
      "min      0.000000    0.000322    0.838400\n",
      "25%     71.750000    0.004110    0.938546\n",
      "50%    143.500000    0.010484    0.951039\n",
      "75%    215.250000    0.026072    0.986811\n",
      "max    287.000000    0.257004    0.992768\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs20_20250926_050613\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=30, výstup: results/lambda15_epochs30_20250926_050652 ===\n",
      "Epoch [1/30] Loss_D: -0.8053 Loss_G: 10.8217 (λL1=15.00)\n",
      "Epoch [2/30] Loss_D: -1.9178 Loss_G: -1.4124 (λL1=15.00)\n",
      "Epoch [3/30] Loss_D: 0.2285 Loss_G: -6.1280 (λL1=15.00)\n",
      "Epoch [4/30] Loss_D: 0.2739 Loss_G: 2.5307 (λL1=15.00)\n",
      "Epoch [5/30] Loss_D: 0.1333 Loss_G: 2.1411 (λL1=15.00)\n",
      "Epoch [6/30] Loss_D: -0.5312 Loss_G: 2.5961 (λL1=15.00)\n",
      "Epoch [7/30] Loss_D: -0.9488 Loss_G: 3.4887 (λL1=15.00)\n",
      "Epoch [8/30] Loss_D: -0.5814 Loss_G: 1.1755 (λL1=15.00)\n",
      "Epoch [9/30] Loss_D: 0.0034 Loss_G: -1.2455 (λL1=15.00)\n",
      "Epoch [10/30] Loss_D: 0.4673 Loss_G: -1.4851 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0551, Corr=0.6430\n",
      "Epoch [11/30] Loss_D: 0.5112 Loss_G: 0.6272 (λL1=15.00)\n",
      "Epoch [12/30] Loss_D: 0.4259 Loss_G: 1.0282 (λL1=15.00)\n",
      "Epoch [13/30] Loss_D: 0.0461 Loss_G: 2.5438 (λL1=15.00)\n",
      "Epoch [14/30] Loss_D: 0.0742 Loss_G: 3.1019 (λL1=15.00)\n",
      "Epoch [15/30] Loss_D: 0.0602 Loss_G: 2.8509 (λL1=15.00)\n",
      "Epoch [16/30] Loss_D: 0.0603 Loss_G: 3.2806 (λL1=15.00)\n",
      "Epoch [17/30] Loss_D: 0.1341 Loss_G: 3.3296 (λL1=15.00)\n",
      "Epoch [18/30] Loss_D: -0.0292 Loss_G: 2.5935 (λL1=15.00)\n",
      "Epoch [19/30] Loss_D: 0.0881 Loss_G: 3.1625 (λL1=15.00)\n",
      "Epoch [20/30] Loss_D: -0.0468 Loss_G: 2.8795 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0461, Corr=0.9471\n",
      "Epoch [21/30] Loss_D: 0.1142 Loss_G: 2.7355 (λL1=15.00)\n",
      "Epoch [22/30] Loss_D: 0.1181 Loss_G: 2.9398 (λL1=15.00)\n",
      "Epoch [23/30] Loss_D: 0.0950 Loss_G: 4.2545 (λL1=15.00)\n",
      "Epoch [24/30] Loss_D: 0.1641 Loss_G: 4.3474 (λL1=15.00)\n",
      "Epoch [25/30] Loss_D: 0.0289 Loss_G: 3.9554 (λL1=15.00)\n",
      "Epoch [26/30] Loss_D: 0.1078 Loss_G: 2.8241 (λL1=15.00)\n",
      "Epoch [27/30] Loss_D: 0.0333 Loss_G: 2.4978 (λL1=15.00)\n",
      "Epoch [28/30] Loss_D: 0.0226 Loss_G: 2.6449 (λL1=15.00)\n",
      "Epoch [29/30] Loss_D: -0.1503 Loss_G: 2.8141 (λL1=15.00)\n",
      "Epoch [30/30] Loss_D: -0.0173 Loss_G: 3.2124 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0466, Corr=0.9406\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.046128\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.046145    0.940043\n",
      "std     83.282651    0.075707    0.046571\n",
      "min      0.000000    0.000614    0.805786\n",
      "25%     71.750000    0.004330    0.911358\n",
      "50%    143.500000    0.009384    0.937625\n",
      "75%    215.250000    0.027349    0.988956\n",
      "max    287.000000    0.263097    0.994545\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs30_20250926_050652\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=40, výstup: results/lambda15_epochs40_20250926_050749 ===\n",
      "Epoch [1/40] Loss_D: -1.7032 Loss_G: 9.8987 (λL1=15.00)\n",
      "Epoch [2/40] Loss_D: -3.1561 Loss_G: -8.9841 (λL1=15.00)\n",
      "Epoch [3/40] Loss_D: 0.5642 Loss_G: -11.6567 (λL1=15.00)\n",
      "Epoch [4/40] Loss_D: 0.2387 Loss_G: -2.3351 (λL1=15.00)\n",
      "Epoch [5/40] Loss_D: 0.5373 Loss_G: 0.3579 (λL1=15.00)\n",
      "Epoch [6/40] Loss_D: 0.2059 Loss_G: -1.1819 (λL1=15.00)\n",
      "Epoch [7/40] Loss_D: 0.1223 Loss_G: -0.7837 (λL1=15.00)\n",
      "Epoch [8/40] Loss_D: 0.0277 Loss_G: -1.7930 (λL1=15.00)\n",
      "Epoch [9/40] Loss_D: 0.1303 Loss_G: -2.3617 (λL1=15.00)\n",
      "Epoch [10/40] Loss_D: 0.3011 Loss_G: -3.8666 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0537, Corr=0.8389\n",
      "Epoch [11/40] Loss_D: 0.3178 Loss_G: -3.3207 (λL1=15.00)\n",
      "Epoch [12/40] Loss_D: 0.4311 Loss_G: -3.1696 (λL1=15.00)\n",
      "Epoch [13/40] Loss_D: 0.0736 Loss_G: -3.7802 (λL1=15.00)\n",
      "Epoch [14/40] Loss_D: 0.1132 Loss_G: -3.5126 (λL1=15.00)\n",
      "Epoch [15/40] Loss_D: 0.0519 Loss_G: -3.7836 (λL1=15.00)\n",
      "Epoch [16/40] Loss_D: 0.1000 Loss_G: -2.9418 (λL1=15.00)\n",
      "Epoch [17/40] Loss_D: 0.0998 Loss_G: -2.2328 (λL1=15.00)\n",
      "Epoch [18/40] Loss_D: 0.1250 Loss_G: -3.0739 (λL1=15.00)\n",
      "Epoch [19/40] Loss_D: 0.1388 Loss_G: -1.6429 (λL1=15.00)\n",
      "Epoch [20/40] Loss_D: 0.1047 Loss_G: -1.2793 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0484, Corr=0.9472\n",
      "Epoch [21/40] Loss_D: 0.0583 Loss_G: -2.2114 (λL1=15.00)\n",
      "Epoch [22/40] Loss_D: -0.0276 Loss_G: -1.8429 (λL1=15.00)\n",
      "Epoch [23/40] Loss_D: -0.0104 Loss_G: -1.4432 (λL1=15.00)\n",
      "Epoch [24/40] Loss_D: 0.0285 Loss_G: -1.8579 (λL1=15.00)\n",
      "Epoch [25/40] Loss_D: 0.0255 Loss_G: -1.7258 (λL1=15.00)\n",
      "Epoch [26/40] Loss_D: -0.0698 Loss_G: -1.8121 (λL1=15.00)\n",
      "Epoch [27/40] Loss_D: -0.0228 Loss_G: -2.5045 (λL1=15.00)\n",
      "Epoch [28/40] Loss_D: 0.0722 Loss_G: -3.4885 (λL1=15.00)\n",
      "Epoch [29/40] Loss_D: 0.0501 Loss_G: -2.8664 (λL1=15.00)\n",
      "Epoch [30/40] Loss_D: 0.0671 Loss_G: -2.2662 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0447, Corr=0.9522\n",
      "Epoch [31/40] Loss_D: -0.0243 Loss_G: -2.5936 (λL1=15.00)\n",
      "Epoch [32/40] Loss_D: 0.0787 Loss_G: -3.4344 (λL1=15.00)\n",
      "Epoch [33/40] Loss_D: 0.0301 Loss_G: -2.8267 (λL1=15.00)\n",
      "Epoch [34/40] Loss_D: 0.0269 Loss_G: -1.9688 (λL1=15.00)\n",
      "Epoch [35/40] Loss_D: -0.0226 Loss_G: -1.9144 (λL1=15.00)\n",
      "Epoch [36/40] Loss_D: 0.0202 Loss_G: -2.3418 (λL1=15.00)\n",
      "Epoch [37/40] Loss_D: 0.0409 Loss_G: -1.4316 (λL1=15.00)\n",
      "Epoch [38/40] Loss_D: 0.0531 Loss_G: -2.6291 (λL1=15.00)\n",
      "Epoch [39/40] Loss_D: 0.0047 Loss_G: -3.9549 (λL1=15.00)\n",
      "Epoch [40/40] Loss_D: 0.0635 Loss_G: -3.7423 (λL1=15.00)\n",
      "[Epoch 40] Val mean MSE=0.0473, Corr=0.9471\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.044706\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.047046    0.947925\n",
      "std     83.282651    0.075697    0.037030\n",
      "min      0.000000    0.001169    0.832053\n",
      "25%     71.750000    0.004607    0.929170\n",
      "50%    143.500000    0.009641    0.947060\n",
      "75%    215.250000    0.031019    0.984980\n",
      "max    287.000000    0.262655    0.989440\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs40_20250926_050749\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=50, výstup: results/lambda15_epochs50_20250926_050919 ===\n",
      "Epoch [1/50] Loss_D: -0.4505 Loss_G: 11.2469 (λL1=15.00)\n",
      "Epoch [2/50] Loss_D: -1.7203 Loss_G: 3.0256 (λL1=15.00)\n",
      "Epoch [3/50] Loss_D: -0.0563 Loss_G: 0.5575 (λL1=15.00)\n",
      "Epoch [4/50] Loss_D: -0.1253 Loss_G: 5.0521 (λL1=15.00)\n",
      "Epoch [5/50] Loss_D: 0.8915 Loss_G: 4.4056 (λL1=15.00)\n",
      "Epoch [6/50] Loss_D: -1.7645 Loss_G: 3.6434 (λL1=15.00)\n",
      "Epoch [7/50] Loss_D: -0.3266 Loss_G: 2.7420 (λL1=15.00)\n",
      "Epoch [8/50] Loss_D: -0.5857 Loss_G: 6.7065 (λL1=15.00)\n",
      "Epoch [9/50] Loss_D: -1.3704 Loss_G: 9.0537 (λL1=15.00)\n",
      "Epoch [10/50] Loss_D: -0.9561 Loss_G: 9.2453 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0618, Corr=0.8444\n",
      "Epoch [11/50] Loss_D: -0.2240 Loss_G: 8.7200 (λL1=15.00)\n",
      "Epoch [12/50] Loss_D: 0.2914 Loss_G: 9.5480 (λL1=15.00)\n",
      "Epoch [13/50] Loss_D: 0.4175 Loss_G: 11.6960 (λL1=15.00)\n",
      "Epoch [14/50] Loss_D: 0.4371 Loss_G: 13.2540 (λL1=15.00)\n",
      "Epoch [15/50] Loss_D: 0.2009 Loss_G: 14.8104 (λL1=15.00)\n",
      "Epoch [16/50] Loss_D: 0.2096 Loss_G: 13.9163 (λL1=15.00)\n",
      "Epoch [17/50] Loss_D: 0.0855 Loss_G: 13.7417 (λL1=15.00)\n",
      "Epoch [18/50] Loss_D: 0.1123 Loss_G: 12.7806 (λL1=15.00)\n",
      "Epoch [19/50] Loss_D: 0.1394 Loss_G: 12.5990 (λL1=15.00)\n",
      "Epoch [20/50] Loss_D: -0.0035 Loss_G: 12.3218 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0468, Corr=0.9172\n",
      "Epoch [21/50] Loss_D: 0.1002 Loss_G: 12.1038 (λL1=15.00)\n",
      "Epoch [22/50] Loss_D: 0.0893 Loss_G: 12.0719 (λL1=15.00)\n",
      "Epoch [23/50] Loss_D: 0.0676 Loss_G: 11.6176 (λL1=15.00)\n",
      "Epoch [24/50] Loss_D: 0.0424 Loss_G: 10.7572 (λL1=15.00)\n",
      "Epoch [25/50] Loss_D: 0.0071 Loss_G: 11.0036 (λL1=15.00)\n",
      "Epoch [26/50] Loss_D: -0.1168 Loss_G: 11.5916 (λL1=15.00)\n",
      "Epoch [27/50] Loss_D: 0.0242 Loss_G: 11.4343 (λL1=15.00)\n",
      "Epoch [28/50] Loss_D: 0.0141 Loss_G: 11.3996 (λL1=15.00)\n",
      "Epoch [29/50] Loss_D: 0.0685 Loss_G: 10.6675 (λL1=15.00)\n",
      "Epoch [30/50] Loss_D: -0.0671 Loss_G: 10.4646 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0449, Corr=0.9199\n",
      "Epoch [31/50] Loss_D: 0.0231 Loss_G: 10.5245 (λL1=15.00)\n",
      "Epoch [32/50] Loss_D: 0.1212 Loss_G: 10.2046 (λL1=15.00)\n",
      "Epoch [33/50] Loss_D: -0.0462 Loss_G: 10.4516 (λL1=15.00)\n",
      "Epoch [34/50] Loss_D: -0.1248 Loss_G: 10.5488 (λL1=15.00)\n",
      "Epoch [35/50] Loss_D: 0.0057 Loss_G: 10.2508 (λL1=15.00)\n",
      "Epoch [36/50] Loss_D: -0.0535 Loss_G: 10.1956 (λL1=15.00)\n",
      "Epoch [37/50] Loss_D: -0.1077 Loss_G: 10.5912 (λL1=15.00)\n",
      "Epoch [38/50] Loss_D: -0.1853 Loss_G: 11.4903 (λL1=15.00)\n",
      "Epoch [39/50] Loss_D: 0.1161 Loss_G: 11.4180 (λL1=15.00)\n",
      "Epoch [40/50] Loss_D: 0.0436 Loss_G: 11.8200 (λL1=15.00)\n",
      "[Epoch 40] Val mean MSE=0.0422, Corr=0.9457\n",
      "Epoch [41/50] Loss_D: -0.2275 Loss_G: 11.7726 (λL1=15.00)\n",
      "Epoch [42/50] Loss_D: -0.0898 Loss_G: 10.8360 (λL1=15.00)\n",
      "Epoch [43/50] Loss_D: -0.0951 Loss_G: 12.4221 (λL1=15.00)\n",
      "Epoch [44/50] Loss_D: -0.2098 Loss_G: 11.4378 (λL1=15.00)\n",
      "Epoch [45/50] Loss_D: 0.0734 Loss_G: 12.8425 (λL1=15.00)\n",
      "Epoch [46/50] Loss_D: 0.0350 Loss_G: 11.8084 (λL1=15.00)\n",
      "Epoch [47/50] Loss_D: 0.1104 Loss_G: 12.8443 (λL1=15.00)\n",
      "Epoch [48/50] Loss_D: -0.0591 Loss_G: 12.3679 (λL1=15.00)\n",
      "Epoch [49/50] Loss_D: 0.1131 Loss_G: 11.3587 (λL1=15.00)\n",
      "Epoch [50/50] Loss_D: 0.0075 Loss_G: 11.4987 (λL1=15.00)\n",
      "[Epoch 50] Val mean MSE=0.0428, Corr=0.9618\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.042237\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.044138    0.962434\n",
      "std     83.282651    0.072109    0.025559\n",
      "min      0.000000    0.000243    0.880936\n",
      "25%     71.750000    0.003839    0.944598\n",
      "50%    143.500000    0.009410    0.960326\n",
      "75%    215.250000    0.029207    0.989381\n",
      "max    287.000000    0.246451    0.993752\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs50_20250926_050919\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=60, výstup: results/lambda15_epochs60_20250926_051129 ===\n",
      "Epoch [1/60] Loss_D: -0.4978 Loss_G: 11.1618 (λL1=15.00)\n",
      "Epoch [2/60] Loss_D: -1.9877 Loss_G: 1.9409 (λL1=15.00)\n",
      "Epoch [3/60] Loss_D: 0.0343 Loss_G: -2.0890 (λL1=15.00)\n",
      "Epoch [4/60] Loss_D: -0.0406 Loss_G: 3.2195 (λL1=15.00)\n",
      "Epoch [5/60] Loss_D: 0.2501 Loss_G: 3.4865 (λL1=15.00)\n",
      "Epoch [6/60] Loss_D: -0.7316 Loss_G: 1.4212 (λL1=15.00)\n",
      "Epoch [7/60] Loss_D: -0.4810 Loss_G: 1.9210 (λL1=15.00)\n",
      "Epoch [8/60] Loss_D: -0.4817 Loss_G: 3.0771 (λL1=15.00)\n",
      "Epoch [9/60] Loss_D: -0.2995 Loss_G: 2.2933 (λL1=15.00)\n",
      "Epoch [10/60] Loss_D: 0.2365 Loss_G: 2.3398 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0571, Corr=0.7390\n",
      "Epoch [11/60] Loss_D: 0.4477 Loss_G: 3.5701 (λL1=15.00)\n",
      "Epoch [12/60] Loss_D: 0.3922 Loss_G: 5.7691 (λL1=15.00)\n",
      "Epoch [13/60] Loss_D: 0.3127 Loss_G: 7.6361 (λL1=15.00)\n",
      "Epoch [14/60] Loss_D: 0.1307 Loss_G: 8.4403 (λL1=15.00)\n",
      "Epoch [15/60] Loss_D: 0.1292 Loss_G: 8.3213 (λL1=15.00)\n",
      "Epoch [16/60] Loss_D: 0.2591 Loss_G: 7.9437 (λL1=15.00)\n",
      "Epoch [17/60] Loss_D: 0.0633 Loss_G: 7.7978 (λL1=15.00)\n",
      "Epoch [18/60] Loss_D: 0.0506 Loss_G: 7.5413 (λL1=15.00)\n",
      "Epoch [19/60] Loss_D: 0.0757 Loss_G: 7.0379 (λL1=15.00)\n",
      "Epoch [20/60] Loss_D: 0.0844 Loss_G: 6.8501 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0465, Corr=0.9450\n",
      "Epoch [21/60] Loss_D: 0.0348 Loss_G: 6.6046 (λL1=15.00)\n",
      "Epoch [22/60] Loss_D: 0.0359 Loss_G: 6.5738 (λL1=15.00)\n",
      "Epoch [23/60] Loss_D: 0.0686 Loss_G: 6.5121 (λL1=15.00)\n",
      "Epoch [24/60] Loss_D: 0.0298 Loss_G: 6.3603 (λL1=15.00)\n",
      "Epoch [25/60] Loss_D: 0.0536 Loss_G: 6.0087 (λL1=15.00)\n",
      "Epoch [26/60] Loss_D: 0.0348 Loss_G: 5.9294 (λL1=15.00)\n",
      "Epoch [27/60] Loss_D: -0.0649 Loss_G: 6.0626 (λL1=15.00)\n",
      "Epoch [28/60] Loss_D: -0.0279 Loss_G: 6.1199 (λL1=15.00)\n",
      "Epoch [29/60] Loss_D: 0.0183 Loss_G: 6.3972 (λL1=15.00)\n",
      "Epoch [30/60] Loss_D: -0.0305 Loss_G: 5.8813 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0450, Corr=0.9663\n",
      "Epoch [31/60] Loss_D: 0.0023 Loss_G: 5.3957 (λL1=15.00)\n",
      "Epoch [32/60] Loss_D: 0.1170 Loss_G: 5.4306 (λL1=15.00)\n",
      "Epoch [33/60] Loss_D: -0.0319 Loss_G: 4.4524 (λL1=15.00)\n",
      "Epoch [34/60] Loss_D: 0.1180 Loss_G: 5.8090 (λL1=15.00)\n",
      "Epoch [35/60] Loss_D: 0.0288 Loss_G: 3.8539 (λL1=15.00)\n",
      "Epoch [36/60] Loss_D: 0.0440 Loss_G: 4.9107 (λL1=15.00)\n",
      "Epoch [37/60] Loss_D: -0.0087 Loss_G: 3.8522 (λL1=15.00)\n",
      "Epoch [38/60] Loss_D: -0.0164 Loss_G: 4.8554 (λL1=15.00)\n",
      "Epoch [39/60] Loss_D: -0.0573 Loss_G: 3.3534 (λL1=15.00)\n",
      "Epoch [40/60] Loss_D: -0.0701 Loss_G: 5.4432 (λL1=15.00)\n",
      "[Epoch 40] Val mean MSE=0.0442, Corr=0.9629\n",
      "Epoch [41/60] Loss_D: 0.0045 Loss_G: 4.2781 (λL1=15.00)\n",
      "Epoch [42/60] Loss_D: -0.0129 Loss_G: 4.5669 (λL1=15.00)\n",
      "Epoch [43/60] Loss_D: -0.0637 Loss_G: 6.6484 (λL1=15.00)\n",
      "Epoch [44/60] Loss_D: 0.0617 Loss_G: 4.0812 (λL1=15.00)\n",
      "Epoch [45/60] Loss_D: 0.0494 Loss_G: 5.3609 (λL1=15.00)\n",
      "Epoch [46/60] Loss_D: -0.0386 Loss_G: 5.4346 (λL1=15.00)\n",
      "Epoch [47/60] Loss_D: -0.1123 Loss_G: 4.9795 (λL1=15.00)\n",
      "Epoch [48/60] Loss_D: -0.0682 Loss_G: 7.0393 (λL1=15.00)\n",
      "Epoch [49/60] Loss_D: -0.0401 Loss_G: 4.6335 (λL1=15.00)\n",
      "Epoch [50/60] Loss_D: -0.0871 Loss_G: 8.0402 (λL1=15.00)\n",
      "[Epoch 50] Val mean MSE=0.0446, Corr=0.9600\n",
      "Epoch [51/60] Loss_D: 0.0825 Loss_G: 6.9322 (λL1=15.00)\n",
      "Epoch [52/60] Loss_D: -0.0404 Loss_G: 6.1537 (λL1=15.00)\n",
      "Epoch [53/60] Loss_D: -0.0588 Loss_G: 7.8771 (λL1=15.00)\n",
      "Epoch [54/60] Loss_D: -0.1263 Loss_G: 6.4358 (λL1=15.00)\n",
      "Epoch [55/60] Loss_D: -0.0590 Loss_G: 8.7331 (λL1=15.00)\n",
      "Epoch [56/60] Loss_D: -0.0746 Loss_G: 7.3042 (λL1=15.00)\n",
      "Epoch [57/60] Loss_D: -0.1237 Loss_G: 8.2703 (λL1=15.00)\n",
      "Epoch [58/60] Loss_D: 0.0569 Loss_G: 8.7281 (λL1=15.00)\n",
      "Epoch [59/60] Loss_D: -0.0216 Loss_G: 6.0481 (λL1=15.00)\n",
      "Epoch [60/60] Loss_D: -0.0586 Loss_G: 9.0104 (λL1=15.00)\n",
      "[Epoch 60] Val mean MSE=0.0409, Corr=0.9462\n",
      "Nejlepší epocha podle MSE: epoch       60.000000\n",
      "mean_MSE     0.040948\n",
      "Name: 5, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.041290    0.945462\n",
      "std     83.282651    0.070320    0.040400\n",
      "min      0.000000    0.000190    0.857882\n",
      "25%     71.750000    0.003208    0.910163\n",
      "50%    143.500000    0.007581    0.951247\n",
      "75%    215.250000    0.021163    0.987148\n",
      "max    287.000000    0.259745    0.994613\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs60_20250926_051129\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=70, výstup: results/lambda15_epochs70_20250926_052422 ===\n",
      "Epoch [1/70] Loss_D: -1.8029 Loss_G: 11.1511 (λL1=15.00)\n",
      "Epoch [2/70] Loss_D: -3.3341 Loss_G: -2.6670 (λL1=15.00)\n",
      "Epoch [3/70] Loss_D: 0.0447 Loss_G: -5.1131 (λL1=15.00)\n",
      "Epoch [4/70] Loss_D: -0.0009 Loss_G: 4.7603 (λL1=15.00)\n",
      "Epoch [5/70] Loss_D: 0.3622 Loss_G: 3.7896 (λL1=15.00)\n",
      "Epoch [6/70] Loss_D: -0.0499 Loss_G: 4.8647 (λL1=15.00)\n",
      "Epoch [7/70] Loss_D: -0.4850 Loss_G: 4.8985 (λL1=15.00)\n",
      "Epoch [8/70] Loss_D: -0.7787 Loss_G: 4.5862 (λL1=15.00)\n",
      "Epoch [9/70] Loss_D: -0.3166 Loss_G: 4.5546 (λL1=15.00)\n",
      "Epoch [10/70] Loss_D: 0.3349 Loss_G: 4.0466 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0521, Corr=0.7942\n",
      "Epoch [11/70] Loss_D: 0.4875 Loss_G: 5.3222 (λL1=15.00)\n",
      "Epoch [12/70] Loss_D: 0.3601 Loss_G: 6.0229 (λL1=15.00)\n",
      "Epoch [13/70] Loss_D: 0.3263 Loss_G: 4.9994 (λL1=15.00)\n",
      "Epoch [14/70] Loss_D: 0.0575 Loss_G: 4.6716 (λL1=15.00)\n",
      "Epoch [15/70] Loss_D: 0.0910 Loss_G: 4.5306 (λL1=15.00)\n",
      "Epoch [16/70] Loss_D: 0.1124 Loss_G: 4.9640 (λL1=15.00)\n",
      "Epoch [17/70] Loss_D: -0.0096 Loss_G: 4.4689 (λL1=15.00)\n",
      "Epoch [18/70] Loss_D: 0.1180 Loss_G: 4.5925 (λL1=15.00)\n",
      "Epoch [19/70] Loss_D: 0.1844 Loss_G: 3.8534 (λL1=15.00)\n",
      "Epoch [20/70] Loss_D: 0.0041 Loss_G: 4.1530 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0465, Corr=0.9484\n",
      "Epoch [21/70] Loss_D: 0.0374 Loss_G: 3.7759 (λL1=15.00)\n",
      "Epoch [22/70] Loss_D: -0.0220 Loss_G: 3.2396 (λL1=15.00)\n",
      "Epoch [23/70] Loss_D: 0.0401 Loss_G: 2.9639 (λL1=15.00)\n",
      "Epoch [24/70] Loss_D: 0.0595 Loss_G: 3.6200 (λL1=15.00)\n",
      "Epoch [25/70] Loss_D: 0.0799 Loss_G: 3.1094 (λL1=15.00)\n",
      "Epoch [26/70] Loss_D: -0.0515 Loss_G: 3.3792 (λL1=15.00)\n",
      "Epoch [27/70] Loss_D: 0.1871 Loss_G: 3.3604 (λL1=15.00)\n",
      "Epoch [28/70] Loss_D: 0.0453 Loss_G: 3.1349 (λL1=15.00)\n",
      "Epoch [29/70] Loss_D: 0.0156 Loss_G: 2.6692 (λL1=15.00)\n",
      "Epoch [30/70] Loss_D: -0.0310 Loss_G: 2.0134 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0458, Corr=0.9584\n",
      "Epoch [31/70] Loss_D: 0.0901 Loss_G: 1.9541 (λL1=15.00)\n",
      "Epoch [32/70] Loss_D: 0.0267 Loss_G: 2.1541 (λL1=15.00)\n",
      "Epoch [33/70] Loss_D: 0.0362 Loss_G: 2.9921 (λL1=15.00)\n",
      "Epoch [34/70] Loss_D: -0.0836 Loss_G: 3.4550 (λL1=15.00)\n",
      "Epoch [35/70] Loss_D: -0.0770 Loss_G: 3.2754 (λL1=15.00)\n",
      "Epoch [36/70] Loss_D: -0.0600 Loss_G: 3.3648 (λL1=15.00)\n",
      "Epoch [37/70] Loss_D: -0.0523 Loss_G: 3.5704 (λL1=15.00)\n",
      "Epoch [38/70] Loss_D: -0.0453 Loss_G: 3.7456 (λL1=15.00)\n",
      "Epoch [39/70] Loss_D: 0.1340 Loss_G: 3.8718 (λL1=15.00)\n",
      "Epoch [40/70] Loss_D: -0.0067 Loss_G: 3.6723 (λL1=15.00)\n",
      "[Epoch 40] Val mean MSE=0.0447, Corr=0.9538\n",
      "Epoch [41/70] Loss_D: 0.2201 Loss_G: 3.2214 (λL1=15.00)\n",
      "Epoch [42/70] Loss_D: 0.0203 Loss_G: 2.5102 (λL1=15.00)\n",
      "Epoch [43/70] Loss_D: -0.1616 Loss_G: 3.1639 (λL1=15.00)\n",
      "Epoch [44/70] Loss_D: -0.1092 Loss_G: 3.4352 (λL1=15.00)\n",
      "Epoch [45/70] Loss_D: 0.0262 Loss_G: 4.2567 (λL1=15.00)\n",
      "Epoch [46/70] Loss_D: 0.0330 Loss_G: 4.2256 (λL1=15.00)\n",
      "Epoch [47/70] Loss_D: -0.0511 Loss_G: 4.0345 (λL1=15.00)\n",
      "Epoch [48/70] Loss_D: 0.0325 Loss_G: 4.0326 (λL1=15.00)\n",
      "Epoch [49/70] Loss_D: 0.0360 Loss_G: 3.5691 (λL1=15.00)\n",
      "Epoch [50/70] Loss_D: -0.0424 Loss_G: 2.5733 (λL1=15.00)\n",
      "[Epoch 50] Val mean MSE=0.0462, Corr=0.9502\n",
      "Epoch [51/70] Loss_D: 0.0888 Loss_G: 3.1832 (λL1=15.00)\n",
      "Epoch [52/70] Loss_D: 0.0117 Loss_G: 3.7953 (λL1=15.00)\n",
      "Epoch [53/70] Loss_D: 0.0191 Loss_G: 4.2125 (λL1=15.00)\n",
      "Epoch [54/70] Loss_D: -0.0280 Loss_G: 3.7542 (λL1=15.00)\n",
      "Epoch [55/70] Loss_D: 0.0048 Loss_G: 3.1902 (λL1=15.00)\n",
      "Epoch [56/70] Loss_D: -0.0099 Loss_G: 3.2072 (λL1=15.00)\n",
      "Epoch [57/70] Loss_D: 0.0034 Loss_G: 3.4720 (λL1=15.00)\n",
      "Epoch [58/70] Loss_D: -0.0904 Loss_G: 4.4981 (λL1=15.00)\n",
      "Epoch [59/70] Loss_D: 0.0041 Loss_G: 4.1010 (λL1=15.00)\n",
      "Epoch [60/70] Loss_D: 0.1258 Loss_G: 3.7849 (λL1=15.00)\n",
      "[Epoch 60] Val mean MSE=0.0469, Corr=0.9249\n",
      "Epoch [61/70] Loss_D: -0.0183 Loss_G: 3.6868 (λL1=15.00)\n",
      "Epoch [62/70] Loss_D: -0.0413 Loss_G: 3.3440 (λL1=15.00)\n",
      "Epoch [63/70] Loss_D: 0.0608 Loss_G: 3.8056 (λL1=15.00)\n",
      "Epoch [64/70] Loss_D: -0.0466 Loss_G: 4.5467 (λL1=15.00)\n",
      "Epoch [65/70] Loss_D: -0.0217 Loss_G: 4.7726 (λL1=15.00)\n",
      "Epoch [66/70] Loss_D: -0.0804 Loss_G: 4.1333 (λL1=15.00)\n",
      "Epoch [67/70] Loss_D: 0.0041 Loss_G: 4.7123 (λL1=15.00)\n",
      "Epoch [68/70] Loss_D: 0.0014 Loss_G: 4.2008 (λL1=15.00)\n",
      "Epoch [69/70] Loss_D: -0.1599 Loss_G: 4.8659 (λL1=15.00)\n",
      "Epoch [70/70] Loss_D: 0.0386 Loss_G: 3.6942 (λL1=15.00)\n",
      "[Epoch 70] Val mean MSE=0.0464, Corr=0.8182\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.044718\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.046620    0.819404\n",
      "std     83.282651    0.072287    0.155180\n",
      "min      0.000000    0.000592    0.417281\n",
      "25%     71.750000    0.007445    0.737248\n",
      "50%    143.500000    0.013638    0.850311\n",
      "75%    215.250000    0.030470    0.961794\n",
      "max    287.000000    0.254295    0.976787\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs70_20250926_052422\n",
      "\n",
      "=== Spouštím běh: λ=15, epochs=80, výstup: results/lambda15_epochs80_20250926_052631 ===\n",
      "Epoch [1/80] Loss_D: -2.1810 Loss_G: 9.7293 (λL1=15.00)\n",
      "Epoch [2/80] Loss_D: -3.3208 Loss_G: -10.1757 (λL1=15.00)\n",
      "Epoch [3/80] Loss_D: 0.3918 Loss_G: -11.6322 (λL1=15.00)\n",
      "Epoch [4/80] Loss_D: 0.2048 Loss_G: -0.2376 (λL1=15.00)\n",
      "Epoch [5/80] Loss_D: 0.4300 Loss_G: -0.0312 (λL1=15.00)\n",
      "Epoch [6/80] Loss_D: -0.0939 Loss_G: -0.0098 (λL1=15.00)\n",
      "Epoch [7/80] Loss_D: -0.4008 Loss_G: 0.2601 (λL1=15.00)\n",
      "Epoch [8/80] Loss_D: -0.6561 Loss_G: 0.5481 (λL1=15.00)\n",
      "Epoch [9/80] Loss_D: -0.2649 Loss_G: -2.1515 (λL1=15.00)\n",
      "Epoch [10/80] Loss_D: 0.3019 Loss_G: -3.0583 (λL1=15.00)\n",
      "[Epoch 10] Val mean MSE=0.0533, Corr=0.8141\n",
      "Epoch [11/80] Loss_D: 0.4480 Loss_G: -1.2985 (λL1=15.00)\n",
      "Epoch [12/80] Loss_D: 0.3285 Loss_G: 1.0882 (λL1=15.00)\n",
      "Epoch [13/80] Loss_D: 0.1977 Loss_G: 1.9762 (λL1=15.00)\n",
      "Epoch [14/80] Loss_D: 0.2335 Loss_G: 1.2340 (λL1=15.00)\n",
      "Epoch [15/80] Loss_D: 0.1642 Loss_G: -0.0459 (λL1=15.00)\n",
      "Epoch [16/80] Loss_D: 0.0235 Loss_G: -0.2547 (λL1=15.00)\n",
      "Epoch [17/80] Loss_D: 0.0286 Loss_G: 0.0195 (λL1=15.00)\n",
      "Epoch [18/80] Loss_D: 0.0920 Loss_G: -0.1881 (λL1=15.00)\n",
      "Epoch [19/80] Loss_D: -0.0043 Loss_G: 0.0144 (λL1=15.00)\n",
      "Epoch [20/80] Loss_D: 0.0731 Loss_G: -0.1688 (λL1=15.00)\n",
      "[Epoch 20] Val mean MSE=0.0458, Corr=0.9471\n",
      "Epoch [21/80] Loss_D: -0.0012 Loss_G: 0.0148 (λL1=15.00)\n",
      "Epoch [22/80] Loss_D: 0.0291 Loss_G: -0.7850 (λL1=15.00)\n",
      "Epoch [23/80] Loss_D: 0.1328 Loss_G: -0.0818 (λL1=15.00)\n",
      "Epoch [24/80] Loss_D: 0.0822 Loss_G: 0.1155 (λL1=15.00)\n",
      "Epoch [25/80] Loss_D: -0.0021 Loss_G: -0.9545 (λL1=15.00)\n",
      "Epoch [26/80] Loss_D: -0.0968 Loss_G: -0.6704 (λL1=15.00)\n",
      "Epoch [27/80] Loss_D: 0.0317 Loss_G: -0.1661 (λL1=15.00)\n",
      "Epoch [28/80] Loss_D: -0.0704 Loss_G: -0.0304 (λL1=15.00)\n",
      "Epoch [29/80] Loss_D: 0.0213 Loss_G: -0.6393 (λL1=15.00)\n",
      "Epoch [30/80] Loss_D: 0.0293 Loss_G: -0.9915 (λL1=15.00)\n",
      "[Epoch 30] Val mean MSE=0.0440, Corr=0.9617\n",
      "Epoch [31/80] Loss_D: -0.0715 Loss_G: -0.7481 (λL1=15.00)\n",
      "Epoch [32/80] Loss_D: -0.0721 Loss_G: -0.9744 (λL1=15.00)\n",
      "Epoch [33/80] Loss_D: -0.0963 Loss_G: -0.5434 (λL1=15.00)\n",
      "Epoch [34/80] Loss_D: 0.0369 Loss_G: -1.9976 (λL1=15.00)\n",
      "Epoch [35/80] Loss_D: -0.1131 Loss_G: -4.5199 (λL1=15.00)\n",
      "Epoch [36/80] Loss_D: -0.2128 Loss_G: -3.6673 (λL1=15.00)\n",
      "Epoch [37/80] Loss_D: -0.1865 Loss_G: -5.7116 (λL1=15.00)\n",
      "Epoch [38/80] Loss_D: -0.1699 Loss_G: -6.9435 (λL1=15.00)\n",
      "Epoch [39/80] Loss_D: 0.0296 Loss_G: -5.4483 (λL1=15.00)\n",
      "Epoch [40/80] Loss_D: -0.2510 Loss_G: -2.2620 (λL1=15.00)\n",
      "[Epoch 40] Val mean MSE=0.0446, Corr=0.9611\n",
      "Epoch [41/80] Loss_D: -0.0049 Loss_G: -3.0266 (λL1=15.00)\n",
      "Epoch [42/80] Loss_D: -0.1172 Loss_G: -5.0621 (λL1=15.00)\n",
      "Epoch [43/80] Loss_D: -0.1248 Loss_G: -7.0319 (λL1=15.00)\n",
      "Epoch [44/80] Loss_D: 0.1170 Loss_G: -5.9298 (λL1=15.00)\n",
      "Epoch [45/80] Loss_D: -0.0302 Loss_G: -5.6726 (λL1=15.00)\n",
      "Epoch [46/80] Loss_D: 0.0154 Loss_G: -4.5822 (λL1=15.00)\n",
      "Epoch [47/80] Loss_D: -0.0931 Loss_G: -3.4720 (λL1=15.00)\n",
      "Epoch [48/80] Loss_D: -0.1377 Loss_G: -5.7391 (λL1=15.00)\n",
      "Epoch [49/80] Loss_D: 0.0601 Loss_G: -5.1601 (λL1=15.00)\n",
      "Epoch [50/80] Loss_D: 0.0207 Loss_G: -6.0436 (λL1=15.00)\n",
      "[Epoch 50] Val mean MSE=0.0438, Corr=0.9430\n",
      "Epoch [51/80] Loss_D: -0.3145 Loss_G: -6.8198 (λL1=15.00)\n",
      "Epoch [52/80] Loss_D: 0.0530 Loss_G: -5.8684 (λL1=15.00)\n",
      "Epoch [53/80] Loss_D: -0.1636 Loss_G: -5.0733 (λL1=15.00)\n",
      "Epoch [54/80] Loss_D: 0.0066 Loss_G: -3.0754 (λL1=15.00)\n",
      "Epoch [55/80] Loss_D: -0.1486 Loss_G: -2.2929 (λL1=15.00)\n",
      "Epoch [56/80] Loss_D: 0.0047 Loss_G: -5.0479 (λL1=15.00)\n",
      "Epoch [57/80] Loss_D: -0.0897 Loss_G: -3.9588 (λL1=15.00)\n",
      "Epoch [58/80] Loss_D: -0.2519 Loss_G: -5.5154 (λL1=15.00)\n",
      "Epoch [59/80] Loss_D: -0.1063 Loss_G: -6.8515 (λL1=15.00)\n",
      "Epoch [60/80] Loss_D: -0.0036 Loss_G: -4.2075 (λL1=15.00)\n",
      "[Epoch 60] Val mean MSE=0.0460, Corr=0.9629\n",
      "Epoch [61/80] Loss_D: -0.1051 Loss_G: -4.7630 (λL1=15.00)\n",
      "Epoch [62/80] Loss_D: -0.1942 Loss_G: -4.7629 (λL1=15.00)\n",
      "Epoch [63/80] Loss_D: -0.0458 Loss_G: -4.4789 (λL1=15.00)\n",
      "Epoch [64/80] Loss_D: -0.2080 Loss_G: -4.9080 (λL1=15.00)\n",
      "Epoch [65/80] Loss_D: -0.1725 Loss_G: -4.7260 (λL1=15.00)\n",
      "Epoch [66/80] Loss_D: -0.0994 Loss_G: -6.6962 (λL1=15.00)\n",
      "Epoch [67/80] Loss_D: 0.1969 Loss_G: -5.1244 (λL1=15.00)\n",
      "Epoch [68/80] Loss_D: 0.0672 Loss_G: -6.5483 (λL1=15.00)\n",
      "Epoch [69/80] Loss_D: -0.0845 Loss_G: -4.9233 (λL1=15.00)\n",
      "Epoch [70/80] Loss_D: -0.2447 Loss_G: -6.3120 (λL1=15.00)\n",
      "[Epoch 70] Val mean MSE=0.0439, Corr=0.9350\n",
      "Epoch [71/80] Loss_D: 0.0719 Loss_G: -4.9900 (λL1=15.00)\n",
      "Epoch [72/80] Loss_D: -0.1563 Loss_G: -4.9548 (λL1=15.00)\n",
      "Epoch [73/80] Loss_D: -0.2129 Loss_G: -7.6462 (λL1=15.00)\n",
      "Epoch [74/80] Loss_D: -0.0493 Loss_G: -8.2201 (λL1=15.00)\n",
      "Epoch [75/80] Loss_D: -0.1119 Loss_G: -7.9050 (λL1=15.00)\n",
      "Epoch [76/80] Loss_D: 0.1476 Loss_G: -4.5838 (λL1=15.00)\n",
      "Epoch [77/80] Loss_D: -0.0621 Loss_G: -5.2586 (λL1=15.00)\n",
      "Epoch [78/80] Loss_D: -0.0091 Loss_G: -5.0678 (λL1=15.00)\n",
      "Epoch [79/80] Loss_D: -0.0025 Loss_G: -4.1886 (λL1=15.00)\n",
      "Epoch [80/80] Loss_D: -0.1925 Loss_G: -4.0593 (λL1=15.00)\n",
      "[Epoch 80] Val mean MSE=0.0432, Corr=0.9656\n",
      "Nejlepší epocha podle MSE: epoch       80.000000\n",
      "mean_MSE     0.043211\n",
      "Name: 7, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043426    0.966590\n",
      "std     83.282651    0.074302    0.027861\n",
      "min      0.000000    0.001358    0.858323\n",
      "25%     71.750000    0.004700    0.957557\n",
      "50%    143.500000    0.009281    0.973146\n",
      "75%    215.250000    0.022460    0.988984\n",
      "max    287.000000    0.262106    0.993145\n",
      "Běh dokončen. Výsledky ve složce: results/lambda15_epochs80_20250926_052631\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=10, výstup: results/lambda20_epochs10_20250926_052859 ===\n",
      "Epoch [1/10] Loss_D: -2.5783 Loss_G: 13.8488 (λL1=20.00)\n",
      "Epoch [2/10] Loss_D: -3.7453 Loss_G: -8.0746 (λL1=20.00)\n",
      "Epoch [3/10] Loss_D: 0.2356 Loss_G: -9.1849 (λL1=20.00)\n",
      "Epoch [4/10] Loss_D: 0.1315 Loss_G: 3.6052 (λL1=20.00)\n",
      "Epoch [5/10] Loss_D: 0.4540 Loss_G: 5.7314 (λL1=20.00)\n",
      "Epoch [6/10] Loss_D: -0.0459 Loss_G: 4.5002 (λL1=20.00)\n",
      "Epoch [7/10] Loss_D: -0.3528 Loss_G: 2.8059 (λL1=20.00)\n",
      "Epoch [8/10] Loss_D: -0.2757 Loss_G: 1.3752 (λL1=20.00)\n",
      "Epoch [9/10] Loss_D: 0.1289 Loss_G: -0.3020 (λL1=20.00)\n",
      "Epoch [10/10] Loss_D: 0.3185 Loss_G: -0.3682 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0561, Corr=0.7731\n",
      "Nejlepší epocha podle MSE: epoch       10.000000\n",
      "mean_MSE     0.056141\n",
      "Name: 0, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.054048    0.783118\n",
      "std     83.282651    0.076464    0.169733\n",
      "min      0.000000    0.001044    0.346081\n",
      "25%     71.750000    0.006787    0.662327\n",
      "50%    143.500000    0.015908    0.746245\n",
      "75%    215.250000    0.056910    0.974093\n",
      "max    287.000000    0.272222    0.987632\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs10_20250926_052859\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=20, výstup: results/lambda20_epochs20_20250926_052917 ===\n",
      "Epoch [1/20] Loss_D: -0.6994 Loss_G: 15.1163 (λL1=20.00)\n",
      "Epoch [2/20] Loss_D: -2.9161 Loss_G: 3.2340 (λL1=20.00)\n",
      "Epoch [3/20] Loss_D: 0.1671 Loss_G: -2.4582 (λL1=20.00)\n",
      "Epoch [4/20] Loss_D: 0.0432 Loss_G: 3.7832 (λL1=20.00)\n",
      "Epoch [5/20] Loss_D: 0.1077 Loss_G: 5.9156 (λL1=20.00)\n",
      "Epoch [6/20] Loss_D: -0.4328 Loss_G: 6.7978 (λL1=20.00)\n",
      "Epoch [7/20] Loss_D: -0.8718 Loss_G: 7.9428 (λL1=20.00)\n",
      "Epoch [8/20] Loss_D: -0.5354 Loss_G: 6.4363 (λL1=20.00)\n",
      "Epoch [9/20] Loss_D: 0.1845 Loss_G: 5.5359 (λL1=20.00)\n",
      "Epoch [10/20] Loss_D: 0.5929 Loss_G: 6.3215 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0532, Corr=0.7084\n",
      "Epoch [11/20] Loss_D: 0.4835 Loss_G: 7.0009 (λL1=20.00)\n",
      "Epoch [12/20] Loss_D: 0.3595 Loss_G: 8.6254 (λL1=20.00)\n",
      "Epoch [13/20] Loss_D: 0.2240 Loss_G: 9.6246 (λL1=20.00)\n",
      "Epoch [14/20] Loss_D: 0.1616 Loss_G: 11.2446 (λL1=20.00)\n",
      "Epoch [15/20] Loss_D: 0.1464 Loss_G: 11.6715 (λL1=20.00)\n",
      "Epoch [16/20] Loss_D: 0.0355 Loss_G: 11.6058 (λL1=20.00)\n",
      "Epoch [17/20] Loss_D: 0.0886 Loss_G: 10.8373 (λL1=20.00)\n",
      "Epoch [18/20] Loss_D: 0.0889 Loss_G: 10.4562 (λL1=20.00)\n",
      "Epoch [19/20] Loss_D: 0.0798 Loss_G: 9.8943 (λL1=20.00)\n",
      "Epoch [20/20] Loss_D: 0.0321 Loss_G: 9.9227 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0476, Corr=0.9519\n",
      "Nejlepší epocha podle MSE: epoch       20.00000\n",
      "mean_MSE     0.04763\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045305    0.952984\n",
      "std     83.282651    0.073742    0.035399\n",
      "min      0.000000    0.000207    0.844275\n",
      "25%     71.750000    0.004269    0.936639\n",
      "50%    143.500000    0.009273    0.951437\n",
      "75%    215.250000    0.028852    0.987801\n",
      "max    287.000000    0.256245    0.992376\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs20_20250926_052917\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=30, výstup: results/lambda20_epochs30_20250926_052954 ===\n",
      "Epoch [1/30] Loss_D: -1.0931 Loss_G: 14.8380 (λL1=20.00)\n",
      "Epoch [2/30] Loss_D: -2.6921 Loss_G: 2.2035 (λL1=20.00)\n",
      "Epoch [3/30] Loss_D: 0.0512 Loss_G: -1.4964 (λL1=20.00)\n",
      "Epoch [4/30] Loss_D: 0.1335 Loss_G: 5.9378 (λL1=20.00)\n",
      "Epoch [5/30] Loss_D: 0.1615 Loss_G: 7.9279 (λL1=20.00)\n",
      "Epoch [6/30] Loss_D: -0.1830 Loss_G: 7.7730 (λL1=20.00)\n",
      "Epoch [7/30] Loss_D: -0.3476 Loss_G: 6.9495 (λL1=20.00)\n",
      "Epoch [8/30] Loss_D: -0.1724 Loss_G: 6.4747 (λL1=20.00)\n",
      "Epoch [9/30] Loss_D: 0.2176 Loss_G: 4.5773 (λL1=20.00)\n",
      "Epoch [10/30] Loss_D: 0.3472 Loss_G: 2.7242 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0546, Corr=0.8559\n",
      "Epoch [11/30] Loss_D: 0.1724 Loss_G: 4.0547 (λL1=20.00)\n",
      "Epoch [12/30] Loss_D: 0.1395 Loss_G: 3.9615 (λL1=20.00)\n",
      "Epoch [13/30] Loss_D: 0.0970 Loss_G: 4.4944 (λL1=20.00)\n",
      "Epoch [14/30] Loss_D: 0.0775 Loss_G: 4.9854 (λL1=20.00)\n",
      "Epoch [15/30] Loss_D: 0.1350 Loss_G: 4.8950 (λL1=20.00)\n",
      "Epoch [16/30] Loss_D: 0.0545 Loss_G: 4.4474 (λL1=20.00)\n",
      "Epoch [17/30] Loss_D: 0.1298 Loss_G: 4.5281 (λL1=20.00)\n",
      "Epoch [18/30] Loss_D: 0.0049 Loss_G: 3.9905 (λL1=20.00)\n",
      "Epoch [19/30] Loss_D: 0.0905 Loss_G: 4.2629 (λL1=20.00)\n",
      "Epoch [20/30] Loss_D: -0.0064 Loss_G: 3.2349 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0501, Corr=0.9474\n",
      "Epoch [21/30] Loss_D: -0.0010 Loss_G: 3.4324 (λL1=20.00)\n",
      "Epoch [22/30] Loss_D: -0.0065 Loss_G: 3.7813 (λL1=20.00)\n",
      "Epoch [23/30] Loss_D: 0.0910 Loss_G: 3.4285 (λL1=20.00)\n",
      "Epoch [24/30] Loss_D: -0.0507 Loss_G: 4.9865 (λL1=20.00)\n",
      "Epoch [25/30] Loss_D: 0.0863 Loss_G: 4.3526 (λL1=20.00)\n",
      "Epoch [26/30] Loss_D: 0.0096 Loss_G: 4.5358 (λL1=20.00)\n",
      "Epoch [27/30] Loss_D: 0.0752 Loss_G: 4.4139 (λL1=20.00)\n",
      "Epoch [28/30] Loss_D: 0.0135 Loss_G: 4.6540 (λL1=20.00)\n",
      "Epoch [29/30] Loss_D: 0.0283 Loss_G: 4.9914 (λL1=20.00)\n",
      "Epoch [30/30] Loss_D: 0.0410 Loss_G: 5.3090 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0444, Corr=0.9684\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.044441\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043992    0.967754\n",
      "std     83.282651    0.073651    0.024952\n",
      "min      0.000000    0.000204    0.854475\n",
      "25%     71.750000    0.003871    0.956347\n",
      "50%    143.500000    0.008898    0.968454\n",
      "75%    215.250000    0.022376    0.991069\n",
      "max    287.000000    0.263532    0.994816\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs30_20250926_052954\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=40, výstup: results/lambda20_epochs40_20250926_053053 ===\n",
      "Epoch [1/40] Loss_D: -0.9415 Loss_G: 14.4302 (λL1=20.00)\n",
      "Epoch [2/40] Loss_D: -2.2429 Loss_G: -0.1967 (λL1=20.00)\n",
      "Epoch [3/40] Loss_D: 0.1070 Loss_G: -6.6326 (λL1=20.00)\n",
      "Epoch [4/40] Loss_D: 0.1774 Loss_G: 0.5751 (λL1=20.00)\n",
      "Epoch [5/40] Loss_D: 0.2958 Loss_G: 2.9168 (λL1=20.00)\n",
      "Epoch [6/40] Loss_D: -0.4044 Loss_G: 2.8277 (λL1=20.00)\n",
      "Epoch [7/40] Loss_D: -0.4762 Loss_G: 0.9554 (λL1=20.00)\n",
      "Epoch [8/40] Loss_D: 0.0582 Loss_G: -2.6425 (λL1=20.00)\n",
      "Epoch [9/40] Loss_D: 0.2276 Loss_G: -3.0489 (λL1=20.00)\n",
      "Epoch [10/40] Loss_D: 0.4806 Loss_G: -0.3436 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0547, Corr=0.6197\n",
      "Epoch [11/40] Loss_D: 0.2514 Loss_G: 1.4638 (λL1=20.00)\n",
      "Epoch [12/40] Loss_D: 0.1501 Loss_G: 3.3130 (λL1=20.00)\n",
      "Epoch [13/40] Loss_D: 0.0487 Loss_G: 2.8373 (λL1=20.00)\n",
      "Epoch [14/40] Loss_D: 0.1064 Loss_G: 3.6258 (λL1=20.00)\n",
      "Epoch [15/40] Loss_D: 0.1743 Loss_G: 3.1385 (λL1=20.00)\n",
      "Epoch [16/40] Loss_D: 0.0753 Loss_G: 3.5567 (λL1=20.00)\n",
      "Epoch [17/40] Loss_D: -0.1012 Loss_G: 3.9396 (λL1=20.00)\n",
      "Epoch [18/40] Loss_D: 0.0589 Loss_G: 4.5632 (λL1=20.00)\n",
      "Epoch [19/40] Loss_D: 0.0728 Loss_G: 4.8540 (λL1=20.00)\n",
      "Epoch [20/40] Loss_D: 0.0916 Loss_G: 5.6244 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0453, Corr=0.9573\n",
      "Epoch [21/40] Loss_D: -0.1180 Loss_G: 6.7701 (λL1=20.00)\n",
      "Epoch [22/40] Loss_D: 0.0103 Loss_G: 6.5565 (λL1=20.00)\n",
      "Epoch [23/40] Loss_D: -0.1020 Loss_G: 7.6142 (λL1=20.00)\n",
      "Epoch [24/40] Loss_D: 0.0432 Loss_G: 7.5582 (λL1=20.00)\n",
      "Epoch [25/40] Loss_D: -0.0201 Loss_G: 8.4224 (λL1=20.00)\n",
      "Epoch [26/40] Loss_D: -0.0355 Loss_G: 9.1798 (λL1=20.00)\n",
      "Epoch [27/40] Loss_D: -0.0379 Loss_G: 8.2367 (λL1=20.00)\n",
      "Epoch [28/40] Loss_D: 0.0010 Loss_G: 8.0356 (λL1=20.00)\n",
      "Epoch [29/40] Loss_D: -0.0230 Loss_G: 7.4179 (λL1=20.00)\n",
      "Epoch [30/40] Loss_D: 0.0498 Loss_G: 7.4411 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0459, Corr=0.9689\n",
      "Epoch [31/40] Loss_D: -0.1193 Loss_G: 7.7175 (λL1=20.00)\n",
      "Epoch [32/40] Loss_D: -0.0514 Loss_G: 8.2227 (λL1=20.00)\n",
      "Epoch [33/40] Loss_D: 0.1191 Loss_G: 8.0923 (λL1=20.00)\n",
      "Epoch [34/40] Loss_D: -0.0534 Loss_G: 7.6938 (λL1=20.00)\n",
      "Epoch [35/40] Loss_D: -0.1646 Loss_G: 8.9141 (λL1=20.00)\n",
      "Epoch [36/40] Loss_D: -0.1083 Loss_G: 9.1025 (λL1=20.00)\n",
      "Epoch [37/40] Loss_D: 0.0334 Loss_G: 9.0058 (λL1=20.00)\n",
      "Epoch [38/40] Loss_D: -0.0706 Loss_G: 8.6510 (λL1=20.00)\n",
      "Epoch [39/40] Loss_D: -0.0588 Loss_G: 9.8482 (λL1=20.00)\n",
      "Epoch [40/40] Loss_D: -0.0332 Loss_G: 9.8503 (λL1=20.00)\n",
      "[Epoch 40] Val mean MSE=0.0453, Corr=0.9730\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.045258\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045673    0.973181\n",
      "std     83.282651    0.074777    0.013718\n",
      "min      0.000000    0.000359    0.901774\n",
      "25%     71.750000    0.004768    0.968732\n",
      "50%    143.500000    0.008703    0.977014\n",
      "75%    215.250000    0.026201    0.982389\n",
      "max    287.000000    0.256991    0.989372\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs40_20250926_053053\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=50, výstup: results/lambda20_epochs50_20250926_054852 ===\n",
      "Epoch [1/50] Loss_D: -1.4959 Loss_G: 14.5310 (λL1=20.00)\n",
      "Epoch [2/50] Loss_D: -3.2150 Loss_G: -0.4385 (λL1=20.00)\n",
      "Epoch [3/50] Loss_D: -0.0842 Loss_G: -3.5238 (λL1=20.00)\n",
      "Epoch [4/50] Loss_D: -0.0721 Loss_G: 5.4206 (λL1=20.00)\n",
      "Epoch [5/50] Loss_D: -0.0370 Loss_G: 4.3162 (λL1=20.00)\n",
      "Epoch [6/50] Loss_D: -0.5608 Loss_G: 7.4079 (λL1=20.00)\n",
      "Epoch [7/50] Loss_D: -1.0331 Loss_G: 8.0113 (λL1=20.00)\n",
      "Epoch [8/50] Loss_D: -0.6271 Loss_G: 6.1798 (λL1=20.00)\n",
      "Epoch [9/50] Loss_D: 0.1532 Loss_G: 5.4932 (λL1=20.00)\n",
      "Epoch [10/50] Loss_D: 0.5346 Loss_G: 6.2520 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0506, Corr=0.7205\n",
      "Epoch [11/50] Loss_D: 0.4792 Loss_G: 7.5478 (λL1=20.00)\n",
      "Epoch [12/50] Loss_D: 0.2063 Loss_G: 8.5804 (λL1=20.00)\n",
      "Epoch [13/50] Loss_D: 0.0568 Loss_G: 8.3149 (λL1=20.00)\n",
      "Epoch [14/50] Loss_D: 0.0778 Loss_G: 9.0457 (λL1=20.00)\n",
      "Epoch [15/50] Loss_D: 0.1230 Loss_G: 8.7558 (λL1=20.00)\n",
      "Epoch [16/50] Loss_D: -0.0180 Loss_G: 8.1933 (λL1=20.00)\n",
      "Epoch [17/50] Loss_D: 0.0760 Loss_G: 7.5113 (λL1=20.00)\n",
      "Epoch [18/50] Loss_D: 0.0717 Loss_G: 7.3044 (λL1=20.00)\n",
      "Epoch [19/50] Loss_D: 0.0462 Loss_G: 6.9347 (λL1=20.00)\n",
      "Epoch [20/50] Loss_D: -0.0051 Loss_G: 7.6005 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0459, Corr=0.9557\n",
      "Epoch [21/50] Loss_D: 0.1651 Loss_G: 7.6937 (λL1=20.00)\n",
      "Epoch [22/50] Loss_D: 0.0953 Loss_G: 7.3358 (λL1=20.00)\n",
      "Epoch [23/50] Loss_D: 0.0119 Loss_G: 6.9066 (λL1=20.00)\n",
      "Epoch [24/50] Loss_D: -0.0885 Loss_G: 7.9363 (λL1=20.00)\n",
      "Epoch [25/50] Loss_D: 0.0372 Loss_G: 8.2131 (λL1=20.00)\n",
      "Epoch [26/50] Loss_D: 0.0057 Loss_G: 7.9768 (λL1=20.00)\n",
      "Epoch [27/50] Loss_D: 0.0508 Loss_G: 7.5618 (λL1=20.00)\n",
      "Epoch [28/50] Loss_D: 0.0590 Loss_G: 6.8157 (λL1=20.00)\n",
      "Epoch [29/50] Loss_D: -0.0098 Loss_G: 7.2773 (λL1=20.00)\n",
      "Epoch [30/50] Loss_D: -0.1036 Loss_G: 7.3862 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0452, Corr=0.9609\n",
      "Epoch [31/50] Loss_D: -0.0686 Loss_G: 7.6664 (λL1=20.00)\n",
      "Epoch [32/50] Loss_D: 0.0343 Loss_G: 7.5555 (λL1=20.00)\n",
      "Epoch [33/50] Loss_D: 0.0019 Loss_G: 7.3691 (λL1=20.00)\n",
      "Epoch [34/50] Loss_D: 0.0215 Loss_G: 7.7136 (λL1=20.00)\n",
      "Epoch [35/50] Loss_D: -0.0312 Loss_G: 7.9234 (λL1=20.00)\n",
      "Epoch [36/50] Loss_D: 0.0093 Loss_G: 7.9874 (λL1=20.00)\n",
      "Epoch [37/50] Loss_D: 0.0711 Loss_G: 8.2858 (λL1=20.00)\n",
      "Epoch [38/50] Loss_D: 0.0394 Loss_G: 9.0331 (λL1=20.00)\n",
      "Epoch [39/50] Loss_D: -0.0277 Loss_G: 8.5254 (λL1=20.00)\n",
      "Epoch [40/50] Loss_D: 0.0272 Loss_G: 8.6337 (λL1=20.00)\n",
      "[Epoch 40] Val mean MSE=0.0443, Corr=0.9651\n",
      "Epoch [41/50] Loss_D: -0.0645 Loss_G: 7.3895 (λL1=20.00)\n",
      "Epoch [42/50] Loss_D: -0.0830 Loss_G: 7.4214 (λL1=20.00)\n",
      "Epoch [43/50] Loss_D: -0.0763 Loss_G: 7.8058 (λL1=20.00)\n",
      "Epoch [44/50] Loss_D: -0.2021 Loss_G: 7.5000 (λL1=20.00)\n",
      "Epoch [45/50] Loss_D: -0.1261 Loss_G: 7.0763 (λL1=20.00)\n",
      "Epoch [46/50] Loss_D: -0.1726 Loss_G: 7.5838 (λL1=20.00)\n",
      "Epoch [47/50] Loss_D: -0.1223 Loss_G: 8.8385 (λL1=20.00)\n",
      "Epoch [48/50] Loss_D: 0.0135 Loss_G: 8.2762 (λL1=20.00)\n",
      "Epoch [49/50] Loss_D: -0.2646 Loss_G: 8.6141 (λL1=20.00)\n",
      "Epoch [50/50] Loss_D: 0.1036 Loss_G: 8.2349 (λL1=20.00)\n",
      "[Epoch 50] Val mean MSE=0.0444, Corr=0.9443\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.044278\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.044693    0.944466\n",
      "std     83.282651    0.075680    0.054678\n",
      "min      0.000000    0.001351    0.759106\n",
      "25%     71.750000    0.003735    0.928741\n",
      "50%    143.500000    0.008206    0.948324\n",
      "75%    215.250000    0.023279    0.991686\n",
      "max    287.000000    0.267420    0.994952\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs50_20250926_054852\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=60, výstup: results/lambda20_epochs60_20250926_055204 ===\n",
      "Epoch [1/60] Loss_D: -1.3107 Loss_G: 14.9299 (λL1=20.00)\n",
      "Epoch [2/60] Loss_D: -2.9730 Loss_G: 3.4172 (λL1=20.00)\n",
      "Epoch [3/60] Loss_D: -0.0098 Loss_G: 0.2485 (λL1=20.00)\n",
      "Epoch [4/60] Loss_D: -0.0696 Loss_G: 7.6860 (λL1=20.00)\n",
      "Epoch [5/60] Loss_D: 0.1155 Loss_G: 8.3575 (λL1=20.00)\n",
      "Epoch [6/60] Loss_D: -0.7638 Loss_G: 7.7127 (λL1=20.00)\n",
      "Epoch [7/60] Loss_D: -0.9198 Loss_G: 7.5896 (λL1=20.00)\n",
      "Epoch [8/60] Loss_D: -0.1160 Loss_G: 5.6546 (λL1=20.00)\n",
      "Epoch [9/60] Loss_D: 0.3899 Loss_G: 6.9048 (λL1=20.00)\n",
      "Epoch [10/60] Loss_D: 0.5409 Loss_G: 11.0691 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0511, Corr=0.5917\n",
      "Epoch [11/60] Loss_D: 0.4978 Loss_G: 13.5767 (λL1=20.00)\n",
      "Epoch [12/60] Loss_D: 0.3217 Loss_G: 12.7445 (λL1=20.00)\n",
      "Epoch [13/60] Loss_D: 0.2230 Loss_G: 11.5975 (λL1=20.00)\n",
      "Epoch [14/60] Loss_D: 0.1276 Loss_G: 11.6280 (λL1=20.00)\n",
      "Epoch [15/60] Loss_D: 0.1392 Loss_G: 12.0136 (λL1=20.00)\n",
      "Epoch [16/60] Loss_D: 0.0359 Loss_G: 12.0542 (λL1=20.00)\n",
      "Epoch [17/60] Loss_D: 0.0358 Loss_G: 12.6699 (λL1=20.00)\n",
      "Epoch [18/60] Loss_D: 0.0602 Loss_G: 12.0208 (λL1=20.00)\n",
      "Epoch [19/60] Loss_D: 0.0376 Loss_G: 12.2555 (λL1=20.00)\n",
      "Epoch [20/60] Loss_D: -0.0345 Loss_G: 13.0144 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0460, Corr=0.9422\n",
      "Epoch [21/60] Loss_D: 0.0374 Loss_G: 13.0625 (λL1=20.00)\n",
      "Epoch [22/60] Loss_D: 0.0838 Loss_G: 13.1737 (λL1=20.00)\n",
      "Epoch [23/60] Loss_D: 0.0883 Loss_G: 13.0282 (λL1=20.00)\n",
      "Epoch [24/60] Loss_D: 0.0140 Loss_G: 14.4885 (λL1=20.00)\n",
      "Epoch [25/60] Loss_D: 0.0677 Loss_G: 14.2483 (λL1=20.00)\n",
      "Epoch [26/60] Loss_D: -0.0202 Loss_G: 15.1831 (λL1=20.00)\n",
      "Epoch [27/60] Loss_D: -0.0897 Loss_G: 16.4393 (λL1=20.00)\n",
      "Epoch [28/60] Loss_D: 0.0542 Loss_G: 15.7806 (λL1=20.00)\n",
      "Epoch [29/60] Loss_D: 0.0233 Loss_G: 15.8035 (λL1=20.00)\n",
      "Epoch [30/60] Loss_D: -0.0177 Loss_G: 16.5958 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0444, Corr=0.9584\n",
      "Epoch [31/60] Loss_D: -0.0760 Loss_G: 17.7159 (λL1=20.00)\n",
      "Epoch [32/60] Loss_D: -0.0852 Loss_G: 18.1742 (λL1=20.00)\n",
      "Epoch [33/60] Loss_D: 0.1778 Loss_G: 17.6964 (λL1=20.00)\n",
      "Epoch [34/60] Loss_D: -0.0712 Loss_G: 16.9858 (λL1=20.00)\n",
      "Epoch [35/60] Loss_D: 0.0332 Loss_G: 18.0857 (λL1=20.00)\n",
      "Epoch [36/60] Loss_D: 0.1295 Loss_G: 17.0324 (λL1=20.00)\n",
      "Epoch [37/60] Loss_D: 0.0409 Loss_G: 16.3560 (λL1=20.00)\n",
      "Epoch [38/60] Loss_D: 0.0201 Loss_G: 15.0894 (λL1=20.00)\n",
      "Epoch [39/60] Loss_D: 0.0327 Loss_G: 14.9213 (λL1=20.00)\n",
      "Epoch [40/60] Loss_D: 0.0583 Loss_G: 14.0135 (λL1=20.00)\n",
      "[Epoch 40] Val mean MSE=0.0428, Corr=0.9684\n",
      "Epoch [41/60] Loss_D: -0.0193 Loss_G: 13.9996 (λL1=20.00)\n",
      "Epoch [42/60] Loss_D: 0.0366 Loss_G: 14.2000 (λL1=20.00)\n",
      "Epoch [43/60] Loss_D: -0.0958 Loss_G: 15.3008 (λL1=20.00)\n",
      "Epoch [44/60] Loss_D: 0.0515 Loss_G: 14.8581 (λL1=20.00)\n",
      "Epoch [45/60] Loss_D: 0.0769 Loss_G: 13.8259 (λL1=20.00)\n",
      "Epoch [46/60] Loss_D: -0.0701 Loss_G: 14.1753 (λL1=20.00)\n",
      "Epoch [47/60] Loss_D: -0.1649 Loss_G: 14.5622 (λL1=20.00)\n",
      "Epoch [48/60] Loss_D: -0.0474 Loss_G: 15.7633 (λL1=20.00)\n",
      "Epoch [49/60] Loss_D: -0.0582 Loss_G: 15.7721 (λL1=20.00)\n",
      "Epoch [50/60] Loss_D: 0.0264 Loss_G: 15.8247 (λL1=20.00)\n",
      "[Epoch 50] Val mean MSE=0.0436, Corr=0.9712\n",
      "Epoch [51/60] Loss_D: 0.1329 Loss_G: 15.0438 (λL1=20.00)\n",
      "Epoch [52/60] Loss_D: -0.1272 Loss_G: 14.9586 (λL1=20.00)\n",
      "Epoch [53/60] Loss_D: 0.0005 Loss_G: 15.4433 (λL1=20.00)\n",
      "Epoch [54/60] Loss_D: 0.0107 Loss_G: 14.8204 (λL1=20.00)\n",
      "Epoch [55/60] Loss_D: -0.1238 Loss_G: 15.4339 (λL1=20.00)\n",
      "Epoch [56/60] Loss_D: -0.0060 Loss_G: 16.2888 (λL1=20.00)\n",
      "Epoch [57/60] Loss_D: -0.1142 Loss_G: 15.8808 (λL1=20.00)\n",
      "Epoch [58/60] Loss_D: 0.0267 Loss_G: 15.2059 (λL1=20.00)\n",
      "Epoch [59/60] Loss_D: 0.0307 Loss_G: 15.0007 (λL1=20.00)\n",
      "Epoch [60/60] Loss_D: 0.1556 Loss_G: 15.8594 (λL1=20.00)\n",
      "[Epoch 60] Val mean MSE=0.0476, Corr=0.9340\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.042775\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.047350    0.934941\n",
      "std     83.282651    0.073317    0.028994\n",
      "min      0.000000    0.001176    0.823160\n",
      "25%     71.750000    0.007397    0.930848\n",
      "50%    143.500000    0.013196    0.945551\n",
      "75%    215.250000    0.027835    0.952056\n",
      "max    287.000000    0.268409    0.980737\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs60_20250926_055204\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=70, výstup: results/lambda20_epochs70_20250926_055553 ===\n",
      "Epoch [1/70] Loss_D: -1.0843 Loss_G: 14.3805 (λL1=20.00)\n",
      "Epoch [2/70] Loss_D: -2.6752 Loss_G: 0.1212 (λL1=20.00)\n",
      "Epoch [3/70] Loss_D: 0.0689 Loss_G: -5.1620 (λL1=20.00)\n",
      "Epoch [4/70] Loss_D: 0.1057 Loss_G: 3.1990 (λL1=20.00)\n",
      "Epoch [5/70] Loss_D: 0.0760 Loss_G: 4.9537 (λL1=20.00)\n",
      "Epoch [6/70] Loss_D: -0.3952 Loss_G: 5.0346 (λL1=20.00)\n",
      "Epoch [7/70] Loss_D: -0.6641 Loss_G: 5.2478 (λL1=20.00)\n",
      "Epoch [8/70] Loss_D: -0.3553 Loss_G: 2.3280 (λL1=20.00)\n",
      "Epoch [9/70] Loss_D: 0.1601 Loss_G: 1.8818 (λL1=20.00)\n",
      "Epoch [10/70] Loss_D: 0.3384 Loss_G: 4.4877 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0520, Corr=0.7402\n",
      "Epoch [11/70] Loss_D: 0.2885 Loss_G: 5.9317 (λL1=20.00)\n",
      "Epoch [12/70] Loss_D: 0.3022 Loss_G: 5.9990 (λL1=20.00)\n",
      "Epoch [13/70] Loss_D: 0.0834 Loss_G: 6.6761 (λL1=20.00)\n",
      "Epoch [14/70] Loss_D: 0.1481 Loss_G: 6.6485 (λL1=20.00)\n",
      "Epoch [15/70] Loss_D: 0.0636 Loss_G: 6.1382 (λL1=20.00)\n",
      "Epoch [16/70] Loss_D: 0.0100 Loss_G: 6.4395 (λL1=20.00)\n",
      "Epoch [17/70] Loss_D: 0.0135 Loss_G: 7.1295 (λL1=20.00)\n",
      "Epoch [18/70] Loss_D: 0.0526 Loss_G: 6.8321 (λL1=20.00)\n",
      "Epoch [19/70] Loss_D: 0.0659 Loss_G: 5.7658 (λL1=20.00)\n",
      "Epoch [20/70] Loss_D: 0.0943 Loss_G: 5.5264 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0460, Corr=0.9559\n",
      "Epoch [21/70] Loss_D: 0.0312 Loss_G: 4.9044 (λL1=20.00)\n",
      "Epoch [22/70] Loss_D: 0.0121 Loss_G: 5.2603 (λL1=20.00)\n",
      "Epoch [23/70] Loss_D: 0.0939 Loss_G: 5.4178 (λL1=20.00)\n",
      "Epoch [24/70] Loss_D: 0.1085 Loss_G: 5.9822 (λL1=20.00)\n",
      "Epoch [25/70] Loss_D: -0.0019 Loss_G: 5.1121 (λL1=20.00)\n",
      "Epoch [26/70] Loss_D: -0.0381 Loss_G: 5.2507 (λL1=20.00)\n",
      "Epoch [27/70] Loss_D: 0.0025 Loss_G: 5.4201 (λL1=20.00)\n",
      "Epoch [28/70] Loss_D: 0.0597 Loss_G: 5.9713 (λL1=20.00)\n",
      "Epoch [29/70] Loss_D: 0.1148 Loss_G: 5.8321 (λL1=20.00)\n",
      "Epoch [30/70] Loss_D: 0.1210 Loss_G: 5.6672 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0450, Corr=0.9647\n",
      "Epoch [31/70] Loss_D: -0.0029 Loss_G: 5.8742 (λL1=20.00)\n",
      "Epoch [32/70] Loss_D: -0.0104 Loss_G: 5.7187 (λL1=20.00)\n",
      "Epoch [33/70] Loss_D: 0.0452 Loss_G: 4.8576 (λL1=20.00)\n",
      "Epoch [34/70] Loss_D: 0.0259 Loss_G: 4.8010 (λL1=20.00)\n",
      "Epoch [35/70] Loss_D: -0.0295 Loss_G: 4.7214 (λL1=20.00)\n",
      "Epoch [36/70] Loss_D: -0.0078 Loss_G: 5.3707 (λL1=20.00)\n",
      "Epoch [37/70] Loss_D: 0.0472 Loss_G: 5.2766 (λL1=20.00)\n",
      "Epoch [38/70] Loss_D: -0.0019 Loss_G: 4.8996 (λL1=20.00)\n",
      "Epoch [39/70] Loss_D: -0.0133 Loss_G: 4.7689 (λL1=20.00)\n",
      "Epoch [40/70] Loss_D: -0.0877 Loss_G: 4.9238 (λL1=20.00)\n",
      "[Epoch 40] Val mean MSE=0.0437, Corr=0.9705\n",
      "Epoch [41/70] Loss_D: 0.0388 Loss_G: 5.0397 (λL1=20.00)\n",
      "Epoch [42/70] Loss_D: -0.0300 Loss_G: 4.1646 (λL1=20.00)\n",
      "Epoch [43/70] Loss_D: -0.0627 Loss_G: 4.5152 (λL1=20.00)\n",
      "Epoch [44/70] Loss_D: -0.0949 Loss_G: 4.3550 (λL1=20.00)\n",
      "Epoch [45/70] Loss_D: -0.0802 Loss_G: 4.0750 (λL1=20.00)\n",
      "Epoch [46/70] Loss_D: -0.1209 Loss_G: 4.5223 (λL1=20.00)\n",
      "Epoch [47/70] Loss_D: -0.1473 Loss_G: 4.5971 (λL1=20.00)\n",
      "Epoch [48/70] Loss_D: -0.1037 Loss_G: 4.4523 (λL1=20.00)\n",
      "Epoch [49/70] Loss_D: -0.0009 Loss_G: 5.2674 (λL1=20.00)\n",
      "Epoch [50/70] Loss_D: -0.0208 Loss_G: 4.2735 (λL1=20.00)\n",
      "[Epoch 50] Val mean MSE=0.0444, Corr=0.9373\n",
      "Epoch [51/70] Loss_D: 0.0059 Loss_G: 3.7931 (λL1=20.00)\n",
      "Epoch [52/70] Loss_D: -0.0057 Loss_G: 4.1995 (λL1=20.00)\n",
      "Epoch [53/70] Loss_D: -0.0203 Loss_G: 3.7769 (λL1=20.00)\n",
      "Epoch [54/70] Loss_D: -0.1437 Loss_G: 4.4290 (λL1=20.00)\n",
      "Epoch [55/70] Loss_D: -0.1192 Loss_G: 4.0440 (λL1=20.00)\n",
      "Epoch [56/70] Loss_D: -0.0687 Loss_G: 3.5630 (λL1=20.00)\n",
      "Epoch [57/70] Loss_D: -0.0089 Loss_G: 4.0832 (λL1=20.00)\n",
      "Epoch [58/70] Loss_D: -0.0201 Loss_G: 2.2171 (λL1=20.00)\n",
      "Epoch [59/70] Loss_D: -0.0231 Loss_G: 4.5868 (λL1=20.00)\n",
      "Epoch [60/70] Loss_D: -0.0073 Loss_G: 2.1920 (λL1=20.00)\n",
      "[Epoch 60] Val mean MSE=0.0461, Corr=0.9544\n",
      "Epoch [61/70] Loss_D: 0.0709 Loss_G: 3.6250 (λL1=20.00)\n",
      "Epoch [62/70] Loss_D: 0.0953 Loss_G: 3.4134 (λL1=20.00)\n",
      "Epoch [63/70] Loss_D: 0.0341 Loss_G: 2.4346 (λL1=20.00)\n",
      "Epoch [64/70] Loss_D: -0.1449 Loss_G: 1.9640 (λL1=20.00)\n",
      "Epoch [65/70] Loss_D: -0.0631 Loss_G: 2.9208 (λL1=20.00)\n",
      "Epoch [66/70] Loss_D: -0.0481 Loss_G: 2.2600 (λL1=20.00)\n",
      "Epoch [67/70] Loss_D: 0.0002 Loss_G: 2.6225 (λL1=20.00)\n",
      "Epoch [68/70] Loss_D: -0.0726 Loss_G: 2.9592 (λL1=20.00)\n",
      "Epoch [69/70] Loss_D: -0.0140 Loss_G: 1.2121 (λL1=20.00)\n",
      "Epoch [70/70] Loss_D: -0.0673 Loss_G: 4.0778 (λL1=20.00)\n",
      "[Epoch 70] Val mean MSE=0.0431, Corr=0.9673\n",
      "Nejlepší epocha podle MSE: epoch       70.000000\n",
      "mean_MSE     0.043052\n",
      "Name: 6, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043308    0.967478\n",
      "std     83.282651    0.073066    0.023776\n",
      "min      0.000000    0.000891    0.898774\n",
      "25%     71.750000    0.004115    0.951129\n",
      "50%    143.500000    0.009684    0.972493\n",
      "75%    215.250000    0.023961    0.989987\n",
      "max    287.000000    0.253149    0.994368\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs70_20250926_055553\n",
      "\n",
      "=== Spouštím běh: λ=20, epochs=80, výstup: results/lambda20_epochs80_20250926_060026 ===\n",
      "Epoch [1/80] Loss_D: -1.0419 Loss_G: 14.4829 (λL1=20.00)\n",
      "Epoch [2/80] Loss_D: -2.3055 Loss_G: 0.3135 (λL1=20.00)\n",
      "Epoch [3/80] Loss_D: 0.1350 Loss_G: -5.5474 (λL1=20.00)\n",
      "Epoch [4/80] Loss_D: -0.0186 Loss_G: 1.5128 (λL1=20.00)\n",
      "Epoch [5/80] Loss_D: 0.0110 Loss_G: 5.6516 (λL1=20.00)\n",
      "Epoch [6/80] Loss_D: -0.6081 Loss_G: 3.6107 (λL1=20.00)\n",
      "Epoch [7/80] Loss_D: -1.4246 Loss_G: 1.1766 (λL1=20.00)\n",
      "Epoch [8/80] Loss_D: -0.3960 Loss_G: 1.8835 (λL1=20.00)\n",
      "Epoch [9/80] Loss_D: -0.3511 Loss_G: 3.2708 (λL1=20.00)\n",
      "Epoch [10/80] Loss_D: 0.1115 Loss_G: 3.7921 (λL1=20.00)\n",
      "[Epoch 10] Val mean MSE=0.0610, Corr=0.7169\n",
      "Epoch [11/80] Loss_D: 0.5082 Loss_G: 6.3772 (λL1=20.00)\n",
      "Epoch [12/80] Loss_D: 0.5895 Loss_G: 7.9398 (λL1=20.00)\n",
      "Epoch [13/80] Loss_D: 0.2787 Loss_G: 8.0871 (λL1=20.00)\n",
      "Epoch [14/80] Loss_D: 0.1135 Loss_G: 8.4787 (λL1=20.00)\n",
      "Epoch [15/80] Loss_D: -0.0811 Loss_G: 8.7055 (λL1=20.00)\n",
      "Epoch [16/80] Loss_D: 0.0821 Loss_G: 9.2426 (λL1=20.00)\n",
      "Epoch [17/80] Loss_D: 0.0128 Loss_G: 7.7383 (λL1=20.00)\n",
      "Epoch [18/80] Loss_D: -0.0150 Loss_G: 8.5584 (λL1=20.00)\n",
      "Epoch [19/80] Loss_D: 0.0722 Loss_G: 8.3330 (λL1=20.00)\n",
      "Epoch [20/80] Loss_D: 0.0910 Loss_G: 8.1099 (λL1=20.00)\n",
      "[Epoch 20] Val mean MSE=0.0464, Corr=0.9503\n",
      "Epoch [21/80] Loss_D: 0.0391 Loss_G: 7.4030 (λL1=20.00)\n",
      "Epoch [22/80] Loss_D: -0.0342 Loss_G: 7.2251 (λL1=20.00)\n",
      "Epoch [23/80] Loss_D: -0.0366 Loss_G: 8.6581 (λL1=20.00)\n",
      "Epoch [24/80] Loss_D: -0.0157 Loss_G: 8.8148 (λL1=20.00)\n",
      "Epoch [25/80] Loss_D: -0.0521 Loss_G: 9.0686 (λL1=20.00)\n",
      "Epoch [26/80] Loss_D: 0.1011 Loss_G: 9.3314 (λL1=20.00)\n",
      "Epoch [27/80] Loss_D: 0.1140 Loss_G: 9.0323 (λL1=20.00)\n",
      "Epoch [28/80] Loss_D: -0.0164 Loss_G: 8.8440 (λL1=20.00)\n",
      "Epoch [29/80] Loss_D: -0.1303 Loss_G: 9.7211 (λL1=20.00)\n",
      "Epoch [30/80] Loss_D: -0.0301 Loss_G: 10.1583 (λL1=20.00)\n",
      "[Epoch 30] Val mean MSE=0.0440, Corr=0.9462\n",
      "Epoch [31/80] Loss_D: -0.0511 Loss_G: 10.1316 (λL1=20.00)\n",
      "Epoch [32/80] Loss_D: 0.1467 Loss_G: 9.0589 (λL1=20.00)\n",
      "Epoch [33/80] Loss_D: -0.1765 Loss_G: 8.8807 (λL1=20.00)\n",
      "Epoch [34/80] Loss_D: -0.1202 Loss_G: 9.0647 (λL1=20.00)\n",
      "Epoch [35/80] Loss_D: -0.2452 Loss_G: 9.8405 (λL1=20.00)\n",
      "Epoch [36/80] Loss_D: -0.2791 Loss_G: 10.4924 (λL1=20.00)\n",
      "Epoch [37/80] Loss_D: 0.0039 Loss_G: 10.3683 (λL1=20.00)\n",
      "Epoch [38/80] Loss_D: 0.0071 Loss_G: 9.7151 (λL1=20.00)\n",
      "Epoch [39/80] Loss_D: 0.0942 Loss_G: 10.0732 (λL1=20.00)\n",
      "Epoch [40/80] Loss_D: -0.0833 Loss_G: 9.9607 (λL1=20.00)\n",
      "[Epoch 40] Val mean MSE=0.0433, Corr=0.9536\n",
      "Epoch [41/80] Loss_D: -0.0582 Loss_G: 10.3276 (λL1=20.00)\n",
      "Epoch [42/80] Loss_D: -0.0251 Loss_G: 9.7250 (λL1=20.00)\n",
      "Epoch [43/80] Loss_D: -0.2136 Loss_G: 10.2771 (λL1=20.00)\n",
      "Epoch [44/80] Loss_D: -0.2743 Loss_G: 9.8366 (λL1=20.00)\n",
      "Epoch [45/80] Loss_D: -0.2344 Loss_G: 9.6881 (λL1=20.00)\n",
      "Epoch [46/80] Loss_D: 0.1055 Loss_G: 7.7463 (λL1=20.00)\n",
      "Epoch [47/80] Loss_D: -0.2570 Loss_G: 7.4161 (λL1=20.00)\n",
      "Epoch [48/80] Loss_D: 0.0069 Loss_G: 8.0807 (λL1=20.00)\n",
      "Epoch [49/80] Loss_D: -0.1996 Loss_G: 7.2567 (λL1=20.00)\n",
      "Epoch [50/80] Loss_D: -0.2916 Loss_G: 8.4011 (λL1=20.00)\n",
      "[Epoch 50] Val mean MSE=0.0433, Corr=0.9451\n",
      "Epoch [51/80] Loss_D: -0.1266 Loss_G: 7.6901 (λL1=20.00)\n",
      "Epoch [52/80] Loss_D: 0.1033 Loss_G: 5.9147 (λL1=20.00)\n",
      "Epoch [53/80] Loss_D: -0.0775 Loss_G: 5.7095 (λL1=20.00)\n",
      "Epoch [54/80] Loss_D: -0.1750 Loss_G: 7.5223 (λL1=20.00)\n",
      "Epoch [55/80] Loss_D: -0.0762 Loss_G: 7.1713 (λL1=20.00)\n",
      "Epoch [56/80] Loss_D: -0.1942 Loss_G: 6.5489 (λL1=20.00)\n",
      "Epoch [57/80] Loss_D: -0.1953 Loss_G: 7.6853 (λL1=20.00)\n",
      "Epoch [58/80] Loss_D: -0.0130 Loss_G: 6.5688 (λL1=20.00)\n",
      "Epoch [59/80] Loss_D: -0.0474 Loss_G: 6.9439 (λL1=20.00)\n",
      "Epoch [60/80] Loss_D: -0.2906 Loss_G: 5.7783 (λL1=20.00)\n",
      "[Epoch 60] Val mean MSE=0.0445, Corr=0.9573\n",
      "Epoch [61/80] Loss_D: -0.2186 Loss_G: 6.4662 (λL1=20.00)\n",
      "Epoch [62/80] Loss_D: -0.4214 Loss_G: 6.7843 (λL1=20.00)\n",
      "Epoch [63/80] Loss_D: -0.3942 Loss_G: 8.9602 (λL1=20.00)\n",
      "Epoch [64/80] Loss_D: -0.4049 Loss_G: 9.9970 (λL1=20.00)\n",
      "Epoch [65/80] Loss_D: -0.2279 Loss_G: 10.1890 (λL1=20.00)\n",
      "Epoch [66/80] Loss_D: 0.2214 Loss_G: 8.9450 (λL1=20.00)\n",
      "Epoch [67/80] Loss_D: 0.0747 Loss_G: 11.1948 (λL1=20.00)\n",
      "Epoch [68/80] Loss_D: 0.1046 Loss_G: 6.8791 (λL1=20.00)\n",
      "Epoch [69/80] Loss_D: -0.4442 Loss_G: 8.9947 (λL1=20.00)\n",
      "Epoch [70/80] Loss_D: -0.2466 Loss_G: 9.6709 (λL1=20.00)\n",
      "[Epoch 70] Val mean MSE=0.0498, Corr=0.9562\n",
      "Epoch [71/80] Loss_D: -0.1333 Loss_G: 12.0043 (λL1=20.00)\n",
      "Epoch [72/80] Loss_D: -0.3702 Loss_G: 8.1516 (λL1=20.00)\n",
      "Epoch [73/80] Loss_D: -0.1810 Loss_G: 11.5556 (λL1=20.00)\n",
      "Epoch [74/80] Loss_D: -0.0254 Loss_G: 7.8431 (λL1=20.00)\n",
      "Epoch [75/80] Loss_D: -0.1275 Loss_G: 12.0858 (λL1=20.00)\n",
      "Epoch [76/80] Loss_D: 0.0403 Loss_G: 8.5538 (λL1=20.00)\n",
      "Epoch [77/80] Loss_D: -0.3816 Loss_G: 10.6360 (λL1=20.00)\n",
      "Epoch [78/80] Loss_D: -0.5233 Loss_G: 7.8848 (λL1=20.00)\n",
      "Epoch [79/80] Loss_D: -0.0114 Loss_G: 11.6745 (λL1=20.00)\n",
      "Epoch [80/80] Loss_D: -0.0989 Loss_G: 10.4160 (λL1=20.00)\n",
      "[Epoch 80] Val mean MSE=0.0493, Corr=0.9752\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.043259\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.048560    0.974467\n",
      "std     83.282651    0.073849    0.017214\n",
      "min      0.000000    0.001007    0.895104\n",
      "25%     71.750000    0.005147    0.965326\n",
      "50%    143.500000    0.011674    0.976013\n",
      "75%    215.250000    0.035453    0.990118\n",
      "max    287.000000    0.248209    0.994956\n",
      "Běh dokončen. Výsledky ve složce: results/lambda20_epochs80_20250926_060026\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=10, výstup: results/lambda25_epochs10_20250926_062235 ===\n",
      "Epoch [1/10] Loss_D: -0.1705 Loss_G: 18.2643 (λL1=25.00)\n",
      "Epoch [2/10] Loss_D: -1.4237 Loss_G: 5.9147 (λL1=25.00)\n",
      "Epoch [3/10] Loss_D: 0.2571 Loss_G: -0.1620 (λL1=25.00)\n",
      "Epoch [4/10] Loss_D: 0.2007 Loss_G: 3.5141 (λL1=25.00)\n",
      "Epoch [5/10] Loss_D: 0.0671 Loss_G: 5.5284 (λL1=25.00)\n",
      "Epoch [6/10] Loss_D: -0.1313 Loss_G: 6.2350 (λL1=25.00)\n",
      "Epoch [7/10] Loss_D: -0.1105 Loss_G: 7.0698 (λL1=25.00)\n",
      "Epoch [8/10] Loss_D: 0.2280 Loss_G: 5.8802 (λL1=25.00)\n",
      "Epoch [9/10] Loss_D: 0.2904 Loss_G: 5.6578 (λL1=25.00)\n",
      "Epoch [10/10] Loss_D: 0.3434 Loss_G: 5.9061 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0500, Corr=0.8567\n",
      "Nejlepší epocha podle MSE: epoch       10.000000\n",
      "mean_MSE     0.049964\n",
      "Name: 0, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.050708    0.856998\n",
      "std     83.282651    0.073497    0.110663\n",
      "min      0.000000    0.000462    0.462148\n",
      "25%     71.750000    0.006278    0.774900\n",
      "50%    143.500000    0.014503    0.853295\n",
      "75%    215.250000    0.046239    0.971918\n",
      "max    287.000000    0.255809    0.985959\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs10_20250926_062235\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=20, výstup: results/lambda25_epochs20_20250926_062302 ===\n",
      "Epoch [1/20] Loss_D: -1.7501 Loss_G: 17.7910 (λL1=25.00)\n",
      "Epoch [2/20] Loss_D: -3.5732 Loss_G: -2.9741 (λL1=25.00)\n",
      "Epoch [3/20] Loss_D: 0.4578 Loss_G: -7.8640 (λL1=25.00)\n",
      "Epoch [4/20] Loss_D: 0.0780 Loss_G: 2.6511 (λL1=25.00)\n",
      "Epoch [5/20] Loss_D: 0.3019 Loss_G: 6.0340 (λL1=25.00)\n",
      "Epoch [6/20] Loss_D: 0.0136 Loss_G: 5.8513 (λL1=25.00)\n",
      "Epoch [7/20] Loss_D: -0.2104 Loss_G: 3.9496 (λL1=25.00)\n",
      "Epoch [8/20] Loss_D: -0.1273 Loss_G: 1.6278 (λL1=25.00)\n",
      "Epoch [9/20] Loss_D: 0.0531 Loss_G: 0.5278 (λL1=25.00)\n",
      "Epoch [10/20] Loss_D: 0.3424 Loss_G: 0.5731 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0536, Corr=0.8682\n",
      "Epoch [11/20] Loss_D: 0.2685 Loss_G: 1.9433 (λL1=25.00)\n",
      "Epoch [12/20] Loss_D: 0.1099 Loss_G: 2.4059 (λL1=25.00)\n",
      "Epoch [13/20] Loss_D: 0.1140 Loss_G: 2.5238 (λL1=25.00)\n",
      "Epoch [14/20] Loss_D: 0.0867 Loss_G: 3.5767 (λL1=25.00)\n",
      "Epoch [15/20] Loss_D: 0.0481 Loss_G: 2.2759 (λL1=25.00)\n",
      "Epoch [16/20] Loss_D: 0.1689 Loss_G: 2.2048 (λL1=25.00)\n",
      "Epoch [17/20] Loss_D: 0.0492 Loss_G: 4.1227 (λL1=25.00)\n",
      "Epoch [18/20] Loss_D: 0.1030 Loss_G: 2.8599 (λL1=25.00)\n",
      "Epoch [19/20] Loss_D: 0.0299 Loss_G: 3.6933 (λL1=25.00)\n",
      "Epoch [20/20] Loss_D: 0.0038 Loss_G: 4.9884 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0486, Corr=0.9574\n",
      "Nejlepší epocha podle MSE: epoch       20.000000\n",
      "mean_MSE     0.048583\n",
      "Name: 1, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.048756    0.958085\n",
      "std     83.282651    0.074496    0.029795\n",
      "min      0.000000    0.000447    0.852163\n",
      "25%     71.750000    0.004693    0.942386\n",
      "50%    143.500000    0.011063    0.956502\n",
      "75%    215.250000    0.042029    0.987872\n",
      "max    287.000000    0.259345    0.993665\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs20_20250926_062302\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=30, výstup: results/lambda25_epochs30_20250926_064000 ===\n",
      "Epoch [1/30] Loss_D: -1.2334 Loss_G: 17.9951 (λL1=25.00)\n",
      "Epoch [2/30] Loss_D: -2.6196 Loss_G: -0.8402 (λL1=25.00)\n",
      "Epoch [3/30] Loss_D: 0.1744 Loss_G: -9.2044 (λL1=25.00)\n",
      "Epoch [4/30] Loss_D: 0.1452 Loss_G: -1.2958 (λL1=25.00)\n",
      "Epoch [5/30] Loss_D: 0.0376 Loss_G: 5.0375 (λL1=25.00)\n",
      "Epoch [6/30] Loss_D: -0.3009 Loss_G: 5.7658 (λL1=25.00)\n",
      "Epoch [7/30] Loss_D: -0.2016 Loss_G: 5.3508 (λL1=25.00)\n",
      "Epoch [8/30] Loss_D: -0.0413 Loss_G: 1.9533 (λL1=25.00)\n",
      "Epoch [9/30] Loss_D: 0.3140 Loss_G: -0.3990 (λL1=25.00)\n",
      "Epoch [10/30] Loss_D: 0.3327 Loss_G: -0.8961 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0504, Corr=0.6807\n",
      "Epoch [11/30] Loss_D: 0.2602 Loss_G: -0.6908 (λL1=25.00)\n",
      "Epoch [12/30] Loss_D: 0.1765 Loss_G: -0.1480 (λL1=25.00)\n",
      "Epoch [13/30] Loss_D: 0.1631 Loss_G: 1.2555 (λL1=25.00)\n",
      "Epoch [14/30] Loss_D: 0.1285 Loss_G: 1.0770 (λL1=25.00)\n",
      "Epoch [15/30] Loss_D: 0.0954 Loss_G: 0.9285 (λL1=25.00)\n",
      "Epoch [16/30] Loss_D: 0.1703 Loss_G: 1.0514 (λL1=25.00)\n",
      "Epoch [17/30] Loss_D: -0.0325 Loss_G: 1.5684 (λL1=25.00)\n",
      "Epoch [18/30] Loss_D: 0.0318 Loss_G: 2.0187 (λL1=25.00)\n",
      "Epoch [19/30] Loss_D: 0.0001 Loss_G: 2.1142 (λL1=25.00)\n",
      "Epoch [20/30] Loss_D: 0.0953 Loss_G: 2.1256 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0468, Corr=0.9504\n",
      "Epoch [21/30] Loss_D: -0.0146 Loss_G: 2.1764 (λL1=25.00)\n",
      "Epoch [22/30] Loss_D: 0.0577 Loss_G: 2.9941 (λL1=25.00)\n",
      "Epoch [23/30] Loss_D: 0.1142 Loss_G: 4.5094 (λL1=25.00)\n",
      "Epoch [24/30] Loss_D: 0.0730 Loss_G: 5.1234 (λL1=25.00)\n",
      "Epoch [25/30] Loss_D: 0.0476 Loss_G: 5.5773 (λL1=25.00)\n",
      "Epoch [26/30] Loss_D: 0.0204 Loss_G: 5.2274 (λL1=25.00)\n",
      "Epoch [27/30] Loss_D: 0.0110 Loss_G: 4.6341 (λL1=25.00)\n",
      "Epoch [28/30] Loss_D: -0.0083 Loss_G: 4.5067 (λL1=25.00)\n",
      "Epoch [29/30] Loss_D: 0.0489 Loss_G: 4.5645 (λL1=25.00)\n",
      "Epoch [30/30] Loss_D: 0.1152 Loss_G: 3.8453 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0455, Corr=0.9630\n",
      "Nejlepší epocha podle MSE: epoch       30.000000\n",
      "mean_MSE     0.045509\n",
      "Name: 2, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045743    0.962605\n",
      "std     83.282651    0.074150    0.028127\n",
      "min      0.000000    0.000172    0.851047\n",
      "25%     71.750000    0.004373    0.948102\n",
      "50%    143.500000    0.009576    0.963069\n",
      "75%    215.250000    0.029334    0.989563\n",
      "max    287.000000    0.250921    0.994021\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs30_20250926_064000\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=40, výstup: results/lambda25_epochs40_20250926_071136 ===\n",
      "Epoch [1/40] Loss_D: -0.6576 Loss_G: 18.4355 (λL1=25.00)\n",
      "Epoch [2/40] Loss_D: -2.0922 Loss_G: 4.5417 (λL1=25.00)\n",
      "Epoch [3/40] Loss_D: 0.0148 Loss_G: -3.1772 (λL1=25.00)\n",
      "Epoch [4/40] Loss_D: -0.0994 Loss_G: 3.9283 (λL1=25.00)\n",
      "Epoch [5/40] Loss_D: -0.1719 Loss_G: 7.5664 (λL1=25.00)\n",
      "Epoch [6/40] Loss_D: -0.5288 Loss_G: 6.7213 (λL1=25.00)\n",
      "Epoch [7/40] Loss_D: -0.6827 Loss_G: 4.7333 (λL1=25.00)\n",
      "Epoch [8/40] Loss_D: -0.0144 Loss_G: -0.2717 (λL1=25.00)\n",
      "Epoch [9/40] Loss_D: 0.3463 Loss_G: -0.9286 (λL1=25.00)\n",
      "Epoch [10/40] Loss_D: 0.4553 Loss_G: -1.2825 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0539, Corr=0.5847\n",
      "Epoch [11/40] Loss_D: 0.4159 Loss_G: -0.8721 (λL1=25.00)\n",
      "Epoch [12/40] Loss_D: 0.2417 Loss_G: -0.6909 (λL1=25.00)\n",
      "Epoch [13/40] Loss_D: 0.2960 Loss_G: 0.7296 (λL1=25.00)\n",
      "Epoch [14/40] Loss_D: 0.0897 Loss_G: 2.5297 (λL1=25.00)\n",
      "Epoch [15/40] Loss_D: 0.1489 Loss_G: 3.1157 (λL1=25.00)\n",
      "Epoch [16/40] Loss_D: 0.0439 Loss_G: 4.6807 (λL1=25.00)\n",
      "Epoch [17/40] Loss_D: -0.0293 Loss_G: 5.6203 (λL1=25.00)\n",
      "Epoch [18/40] Loss_D: 0.0705 Loss_G: 6.8472 (λL1=25.00)\n",
      "Epoch [19/40] Loss_D: -0.0441 Loss_G: 6.2901 (λL1=25.00)\n",
      "Epoch [20/40] Loss_D: 0.0470 Loss_G: 7.8038 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0461, Corr=0.9549\n",
      "Epoch [21/40] Loss_D: 0.0061 Loss_G: 6.8801 (λL1=25.00)\n",
      "Epoch [22/40] Loss_D: -0.0309 Loss_G: 7.5008 (λL1=25.00)\n",
      "Epoch [23/40] Loss_D: 0.0237 Loss_G: 7.6927 (λL1=25.00)\n",
      "Epoch [24/40] Loss_D: -0.0100 Loss_G: 8.7197 (λL1=25.00)\n",
      "Epoch [25/40] Loss_D: 0.0058 Loss_G: 8.8637 (λL1=25.00)\n",
      "Epoch [26/40] Loss_D: -0.0036 Loss_G: 9.2041 (λL1=25.00)\n",
      "Epoch [27/40] Loss_D: -0.0153 Loss_G: 8.9290 (λL1=25.00)\n",
      "Epoch [28/40] Loss_D: 0.0352 Loss_G: 8.4452 (λL1=25.00)\n",
      "Epoch [29/40] Loss_D: -0.0523 Loss_G: 8.1992 (λL1=25.00)\n",
      "Epoch [30/40] Loss_D: -0.0120 Loss_G: 8.2316 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0464, Corr=0.9711\n",
      "Epoch [31/40] Loss_D: -0.0483 Loss_G: 8.3808 (λL1=25.00)\n",
      "Epoch [32/40] Loss_D: -0.0658 Loss_G: 9.4395 (λL1=25.00)\n",
      "Epoch [33/40] Loss_D: -0.0164 Loss_G: 9.4716 (λL1=25.00)\n",
      "Epoch [34/40] Loss_D: -0.0998 Loss_G: 8.7585 (λL1=25.00)\n",
      "Epoch [35/40] Loss_D: -0.0284 Loss_G: 8.1876 (λL1=25.00)\n",
      "Epoch [36/40] Loss_D: -0.0631 Loss_G: 7.9467 (λL1=25.00)\n",
      "Epoch [37/40] Loss_D: -0.1880 Loss_G: 9.1455 (λL1=25.00)\n",
      "Epoch [38/40] Loss_D: 0.0250 Loss_G: 9.4658 (λL1=25.00)\n",
      "Epoch [39/40] Loss_D: -0.1317 Loss_G: 7.9340 (λL1=25.00)\n",
      "Epoch [40/40] Loss_D: -0.1605 Loss_G: 7.9662 (λL1=25.00)\n",
      "[Epoch 40] Val mean MSE=0.0437, Corr=0.9782\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.043715\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043219    0.978306\n",
      "std     83.282651    0.074149    0.017066\n",
      "min      0.000000    0.000291    0.909858\n",
      "25%     71.750000    0.003013    0.970385\n",
      "50%    143.500000    0.008237    0.979072\n",
      "75%    215.250000    0.021315    0.993976\n",
      "max    287.000000    0.255213    0.996859\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs40_20250926_071136\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=50, výstup: results/lambda25_epochs50_20250926_074714 ===\n",
      "Epoch [1/50] Loss_D: -1.4016 Loss_G: 18.2529 (λL1=25.00)\n",
      "Epoch [2/50] Loss_D: -3.8979 Loss_G: -0.5314 (λL1=25.00)\n",
      "Epoch [3/50] Loss_D: -0.0319 Loss_G: -5.3744 (λL1=25.00)\n",
      "Epoch [4/50] Loss_D: 0.1237 Loss_G: 5.9516 (λL1=25.00)\n",
      "Epoch [5/50] Loss_D: 0.2178 Loss_G: 7.1740 (λL1=25.00)\n",
      "Epoch [6/50] Loss_D: -0.1847 Loss_G: 7.5166 (λL1=25.00)\n",
      "Epoch [7/50] Loss_D: -0.2653 Loss_G: 7.6220 (λL1=25.00)\n",
      "Epoch [8/50] Loss_D: -0.1140 Loss_G: 7.7600 (λL1=25.00)\n",
      "Epoch [9/50] Loss_D: 0.2968 Loss_G: 7.2860 (λL1=25.00)\n",
      "Epoch [10/50] Loss_D: 0.4480 Loss_G: 7.7295 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0497, Corr=0.8816\n",
      "Epoch [11/50] Loss_D: 0.3747 Loss_G: 7.3824 (λL1=25.00)\n",
      "Epoch [12/50] Loss_D: 0.2938 Loss_G: 6.2475 (λL1=25.00)\n",
      "Epoch [13/50] Loss_D: 0.2783 Loss_G: 5.0738 (λL1=25.00)\n",
      "Epoch [14/50] Loss_D: 0.1229 Loss_G: 5.4165 (λL1=25.00)\n",
      "Epoch [15/50] Loss_D: 0.0058 Loss_G: 5.0230 (λL1=25.00)\n",
      "Epoch [16/50] Loss_D: 0.1033 Loss_G: 4.3030 (λL1=25.00)\n",
      "Epoch [17/50] Loss_D: 0.1330 Loss_G: 4.7613 (λL1=25.00)\n",
      "Epoch [18/50] Loss_D: 0.0508 Loss_G: 3.9711 (λL1=25.00)\n",
      "Epoch [19/50] Loss_D: 0.1217 Loss_G: 4.6351 (λL1=25.00)\n",
      "Epoch [20/50] Loss_D: 0.0666 Loss_G: 4.1166 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0452, Corr=0.9589\n",
      "Epoch [21/50] Loss_D: 0.0347 Loss_G: 4.0943 (λL1=25.00)\n",
      "Epoch [22/50] Loss_D: 0.0023 Loss_G: 3.8890 (λL1=25.00)\n",
      "Epoch [23/50] Loss_D: -0.0402 Loss_G: 3.0777 (λL1=25.00)\n",
      "Epoch [24/50] Loss_D: 0.1288 Loss_G: 3.2519 (λL1=25.00)\n",
      "Epoch [25/50] Loss_D: 0.0983 Loss_G: 2.7623 (λL1=25.00)\n",
      "Epoch [26/50] Loss_D: 0.0865 Loss_G: 3.2511 (λL1=25.00)\n",
      "Epoch [27/50] Loss_D: -0.0108 Loss_G: 2.9955 (λL1=25.00)\n",
      "Epoch [28/50] Loss_D: 0.1056 Loss_G: 2.3614 (λL1=25.00)\n",
      "Epoch [29/50] Loss_D: 0.0715 Loss_G: 2.4035 (λL1=25.00)\n",
      "Epoch [30/50] Loss_D: 0.1215 Loss_G: 2.4714 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0468, Corr=0.9608\n",
      "Epoch [31/50] Loss_D: 0.0756 Loss_G: 2.4732 (λL1=25.00)\n",
      "Epoch [32/50] Loss_D: -0.0374 Loss_G: 2.7906 (λL1=25.00)\n",
      "Epoch [33/50] Loss_D: 0.0391 Loss_G: 2.0887 (λL1=25.00)\n",
      "Epoch [34/50] Loss_D: -0.0539 Loss_G: 2.5251 (λL1=25.00)\n",
      "Epoch [35/50] Loss_D: 0.0291 Loss_G: 2.0520 (λL1=25.00)\n",
      "Epoch [36/50] Loss_D: -0.0007 Loss_G: 2.2069 (λL1=25.00)\n",
      "Epoch [37/50] Loss_D: 0.0382 Loss_G: 3.7441 (λL1=25.00)\n",
      "Epoch [38/50] Loss_D: 0.0465 Loss_G: 4.2097 (λL1=25.00)\n",
      "Epoch [39/50] Loss_D: -0.0047 Loss_G: 2.9166 (λL1=25.00)\n",
      "Epoch [40/50] Loss_D: -0.0022 Loss_G: 2.6473 (λL1=25.00)\n",
      "[Epoch 40] Val mean MSE=0.0432, Corr=0.9718\n",
      "Epoch [41/50] Loss_D: 0.0081 Loss_G: 1.3042 (λL1=25.00)\n",
      "Epoch [42/50] Loss_D: -0.0537 Loss_G: 1.9812 (λL1=25.00)\n",
      "Epoch [43/50] Loss_D: -0.0590 Loss_G: 1.6291 (λL1=25.00)\n",
      "Epoch [44/50] Loss_D: -0.0134 Loss_G: 2.5162 (λL1=25.00)\n",
      "Epoch [45/50] Loss_D: 0.0991 Loss_G: 2.1364 (λL1=25.00)\n",
      "Epoch [46/50] Loss_D: 0.0634 Loss_G: 0.7490 (λL1=25.00)\n",
      "Epoch [47/50] Loss_D: 0.0217 Loss_G: 1.2051 (λL1=25.00)\n",
      "Epoch [48/50] Loss_D: -0.0390 Loss_G: 1.2728 (λL1=25.00)\n",
      "Epoch [49/50] Loss_D: 0.1645 Loss_G: 2.1573 (λL1=25.00)\n",
      "Epoch [50/50] Loss_D: 0.1042 Loss_G: 3.5030 (λL1=25.00)\n",
      "[Epoch 50] Val mean MSE=0.0459, Corr=0.9562\n",
      "Nejlepší epocha podle MSE: epoch       40.000000\n",
      "mean_MSE     0.043244\n",
      "Name: 3, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045317    0.956942\n",
      "std     83.282651    0.072937    0.022013\n",
      "min      0.000000    0.000915    0.863835\n",
      "25%     71.750000    0.006102    0.950661\n",
      "50%    143.500000    0.010585    0.964540\n",
      "75%    215.250000    0.029038    0.972093\n",
      "max    287.000000    0.253662    0.981234\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs50_20250926_074714\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=60, výstup: results/lambda25_epochs60_20250926_082021 ===\n",
      "Epoch [1/60] Loss_D: -1.4670 Loss_G: 18.1173 (λL1=25.00)\n",
      "Epoch [2/60] Loss_D: -2.9317 Loss_G: -0.4963 (λL1=25.00)\n",
      "Epoch [3/60] Loss_D: 0.3004 Loss_G: -9.0429 (λL1=25.00)\n",
      "Epoch [4/60] Loss_D: 0.1200 Loss_G: -2.3216 (λL1=25.00)\n",
      "Epoch [5/60] Loss_D: 0.2022 Loss_G: 1.9089 (λL1=25.00)\n",
      "Epoch [6/60] Loss_D: -0.2443 Loss_G: 1.7732 (λL1=25.00)\n",
      "Epoch [7/60] Loss_D: -0.2871 Loss_G: -0.0548 (λL1=25.00)\n",
      "Epoch [8/60] Loss_D: -0.0276 Loss_G: -3.3026 (λL1=25.00)\n",
      "Epoch [9/60] Loss_D: 0.2765 Loss_G: -3.9287 (λL1=25.00)\n",
      "Epoch [10/60] Loss_D: 0.4483 Loss_G: -3.5853 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0506, Corr=0.7834\n",
      "Epoch [11/60] Loss_D: 0.2769 Loss_G: -2.5856 (λL1=25.00)\n",
      "Epoch [12/60] Loss_D: 0.1905 Loss_G: -2.2024 (λL1=25.00)\n",
      "Epoch [13/60] Loss_D: 0.1353 Loss_G: -1.1755 (λL1=25.00)\n",
      "Epoch [14/60] Loss_D: 0.1117 Loss_G: -0.1828 (λL1=25.00)\n",
      "Epoch [15/60] Loss_D: 0.0451 Loss_G: -0.9857 (λL1=25.00)\n",
      "Epoch [16/60] Loss_D: 0.1059 Loss_G: 0.0404 (λL1=25.00)\n",
      "Epoch [17/60] Loss_D: 0.0329 Loss_G: -0.6929 (λL1=25.00)\n",
      "Epoch [18/60] Loss_D: 0.1072 Loss_G: -1.0349 (λL1=25.00)\n",
      "Epoch [19/60] Loss_D: 0.0281 Loss_G: 0.2109 (λL1=25.00)\n",
      "Epoch [20/60] Loss_D: 0.1077 Loss_G: 0.0389 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0476, Corr=0.9557\n",
      "Epoch [21/60] Loss_D: 0.2866 Loss_G: 0.8749 (λL1=25.00)\n",
      "Epoch [22/60] Loss_D: -0.1047 Loss_G: 0.6589 (λL1=25.00)\n",
      "Epoch [23/60] Loss_D: 0.1022 Loss_G: 0.6571 (λL1=25.00)\n",
      "Epoch [24/60] Loss_D: 0.0859 Loss_G: 1.0260 (λL1=25.00)\n",
      "Epoch [25/60] Loss_D: 0.0818 Loss_G: 1.3145 (λL1=25.00)\n",
      "Epoch [26/60] Loss_D: 0.0484 Loss_G: 2.3732 (λL1=25.00)\n",
      "Epoch [27/60] Loss_D: -0.0738 Loss_G: 2.5128 (λL1=25.00)\n",
      "Epoch [28/60] Loss_D: -0.0333 Loss_G: 3.0270 (λL1=25.00)\n",
      "Epoch [29/60] Loss_D: -0.0476 Loss_G: 3.1394 (λL1=25.00)\n",
      "Epoch [30/60] Loss_D: 0.0660 Loss_G: 2.1183 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0463, Corr=0.9510\n",
      "Epoch [31/60] Loss_D: 0.0374 Loss_G: 1.8673 (λL1=25.00)\n",
      "Epoch [32/60] Loss_D: 0.0150 Loss_G: 3.0947 (λL1=25.00)\n",
      "Epoch [33/60] Loss_D: 0.0821 Loss_G: 4.2740 (λL1=25.00)\n",
      "Epoch [34/60] Loss_D: -0.0280 Loss_G: 4.4752 (λL1=25.00)\n",
      "Epoch [35/60] Loss_D: -0.0116 Loss_G: 4.3806 (λL1=25.00)\n",
      "Epoch [36/60] Loss_D: 0.0784 Loss_G: 5.3215 (λL1=25.00)\n",
      "Epoch [37/60] Loss_D: -0.0356 Loss_G: 4.9877 (λL1=25.00)\n",
      "Epoch [38/60] Loss_D: 0.0062 Loss_G: 3.9392 (λL1=25.00)\n",
      "Epoch [39/60] Loss_D: 0.0107 Loss_G: 3.4037 (λL1=25.00)\n",
      "Epoch [40/60] Loss_D: -0.0396 Loss_G: 3.7324 (λL1=25.00)\n",
      "[Epoch 40] Val mean MSE=0.0460, Corr=0.9700\n",
      "Epoch [41/60] Loss_D: -0.0450 Loss_G: 4.4761 (λL1=25.00)\n",
      "Epoch [42/60] Loss_D: -0.0471 Loss_G: 4.2373 (λL1=25.00)\n",
      "Epoch [43/60] Loss_D: 0.0446 Loss_G: 3.2316 (λL1=25.00)\n",
      "Epoch [44/60] Loss_D: -0.0097 Loss_G: 3.1909 (λL1=25.00)\n",
      "Epoch [45/60] Loss_D: -0.0486 Loss_G: 4.0680 (λL1=25.00)\n",
      "Epoch [46/60] Loss_D: -0.0318 Loss_G: 5.3985 (λL1=25.00)\n",
      "Epoch [47/60] Loss_D: -0.1612 Loss_G: 6.1811 (λL1=25.00)\n",
      "Epoch [48/60] Loss_D: 0.0740 Loss_G: 5.4878 (λL1=25.00)\n",
      "Epoch [49/60] Loss_D: -0.0596 Loss_G: 3.1005 (λL1=25.00)\n",
      "Epoch [50/60] Loss_D: -0.1962 Loss_G: 3.8490 (λL1=25.00)\n",
      "[Epoch 50] Val mean MSE=0.0447, Corr=0.9689\n",
      "Epoch [51/60] Loss_D: -0.0284 Loss_G: 5.6533 (λL1=25.00)\n",
      "Epoch [52/60] Loss_D: -0.1557 Loss_G: 5.9086 (λL1=25.00)\n",
      "Epoch [53/60] Loss_D: 0.0451 Loss_G: 4.3511 (λL1=25.00)\n",
      "Epoch [54/60] Loss_D: -0.0862 Loss_G: 4.1410 (λL1=25.00)\n",
      "Epoch [55/60] Loss_D: -0.0772 Loss_G: 4.8815 (λL1=25.00)\n",
      "Epoch [56/60] Loss_D: 0.0462 Loss_G: 6.4781 (λL1=25.00)\n",
      "Epoch [57/60] Loss_D: -0.0909 Loss_G: 6.2013 (λL1=25.00)\n",
      "Epoch [58/60] Loss_D: -0.0997 Loss_G: 3.7996 (λL1=25.00)\n",
      "Epoch [59/60] Loss_D: -0.0671 Loss_G: 2.9653 (λL1=25.00)\n",
      "Epoch [60/60] Loss_D: 0.1497 Loss_G: 4.0020 (λL1=25.00)\n",
      "[Epoch 60] Val mean MSE=0.0457, Corr=0.9678\n",
      "Nejlepší epocha podle MSE: epoch       50.000000\n",
      "mean_MSE     0.044733\n",
      "Name: 4, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.045855    0.967206\n",
      "std     83.282651    0.074371    0.021390\n",
      "min      0.000000    0.000894    0.886065\n",
      "25%     71.750000    0.004878    0.957105\n",
      "50%    143.500000    0.010070    0.972561\n",
      "75%    215.250000    0.027423    0.984532\n",
      "max    287.000000    0.259742    0.991751\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs60_20250926_082021\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=70, výstup: results/lambda25_epochs70_20250926_082247 ===\n",
      "Epoch [1/70] Loss_D: -0.8588 Loss_G: 18.3206 (λL1=25.00)\n",
      "Epoch [2/70] Loss_D: -2.4238 Loss_G: 3.5340 (λL1=25.00)\n",
      "Epoch [3/70] Loss_D: -0.0249 Loss_G: -2.8617 (λL1=25.00)\n",
      "Epoch [4/70] Loss_D: 0.1306 Loss_G: 2.6093 (λL1=25.00)\n",
      "Epoch [5/70] Loss_D: -0.0581 Loss_G: 5.7725 (λL1=25.00)\n",
      "Epoch [6/70] Loss_D: -0.4468 Loss_G: 5.5952 (λL1=25.00)\n",
      "Epoch [7/70] Loss_D: -0.3270 Loss_G: 3.8649 (λL1=25.00)\n",
      "Epoch [8/70] Loss_D: 0.1890 Loss_G: 1.2986 (λL1=25.00)\n",
      "Epoch [9/70] Loss_D: 0.4342 Loss_G: 3.0849 (λL1=25.00)\n",
      "Epoch [10/70] Loss_D: 0.3591 Loss_G: 4.9289 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0510, Corr=0.7676\n",
      "Epoch [11/70] Loss_D: 0.3312 Loss_G: 6.8317 (λL1=25.00)\n",
      "Epoch [12/70] Loss_D: 0.1729 Loss_G: 7.6008 (λL1=25.00)\n",
      "Epoch [13/70] Loss_D: 0.0707 Loss_G: 7.9050 (λL1=25.00)\n",
      "Epoch [14/70] Loss_D: 0.0262 Loss_G: 7.5554 (λL1=25.00)\n",
      "Epoch [15/70] Loss_D: 0.1377 Loss_G: 8.6971 (λL1=25.00)\n",
      "Epoch [16/70] Loss_D: 0.2179 Loss_G: 9.2450 (λL1=25.00)\n",
      "Epoch [17/70] Loss_D: 0.1269 Loss_G: 8.2709 (λL1=25.00)\n",
      "Epoch [18/70] Loss_D: 0.0296 Loss_G: 7.5652 (λL1=25.00)\n",
      "Epoch [19/70] Loss_D: 0.0847 Loss_G: 8.1119 (λL1=25.00)\n",
      "Epoch [20/70] Loss_D: 0.0550 Loss_G: 7.9293 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0454, Corr=0.9515\n",
      "Epoch [21/70] Loss_D: 0.0859 Loss_G: 7.6394 (λL1=25.00)\n",
      "Epoch [22/70] Loss_D: 0.0814 Loss_G: 7.8102 (λL1=25.00)\n",
      "Epoch [23/70] Loss_D: -0.0527 Loss_G: 8.0024 (λL1=25.00)\n",
      "Epoch [24/70] Loss_D: 0.0436 Loss_G: 7.9436 (λL1=25.00)\n",
      "Epoch [25/70] Loss_D: -0.0266 Loss_G: 8.7984 (λL1=25.00)\n",
      "Epoch [26/70] Loss_D: 0.0659 Loss_G: 9.0206 (λL1=25.00)\n",
      "Epoch [27/70] Loss_D: 0.0176 Loss_G: 7.4865 (λL1=25.00)\n",
      "Epoch [28/70] Loss_D: 0.0574 Loss_G: 6.3816 (λL1=25.00)\n",
      "Epoch [29/70] Loss_D: -0.0431 Loss_G: 6.6532 (λL1=25.00)\n",
      "Epoch [30/70] Loss_D: -0.0131 Loss_G: 6.3834 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0450, Corr=0.9621\n",
      "Epoch [31/70] Loss_D: -0.0047 Loss_G: 6.6717 (λL1=25.00)\n",
      "Epoch [32/70] Loss_D: 0.0225 Loss_G: 7.0278 (λL1=25.00)\n",
      "Epoch [33/70] Loss_D: -0.0361 Loss_G: 6.8604 (λL1=25.00)\n",
      "Epoch [34/70] Loss_D: -0.0708 Loss_G: 7.3803 (λL1=25.00)\n",
      "Epoch [35/70] Loss_D: 0.0464 Loss_G: 6.4181 (λL1=25.00)\n",
      "Epoch [36/70] Loss_D: -0.0032 Loss_G: 6.0240 (λL1=25.00)\n",
      "Epoch [37/70] Loss_D: -0.0658 Loss_G: 7.8974 (λL1=25.00)\n",
      "Epoch [38/70] Loss_D: -0.0155 Loss_G: 7.5703 (λL1=25.00)\n",
      "Epoch [39/70] Loss_D: 0.0480 Loss_G: 5.7118 (λL1=25.00)\n",
      "Epoch [40/70] Loss_D: -0.1373 Loss_G: 5.8365 (λL1=25.00)\n",
      "[Epoch 40] Val mean MSE=0.0456, Corr=0.9466\n",
      "Epoch [41/70] Loss_D: -0.0702 Loss_G: 7.6409 (λL1=25.00)\n",
      "Epoch [42/70] Loss_D: -0.0787 Loss_G: 6.7979 (λL1=25.00)\n",
      "Epoch [43/70] Loss_D: -0.0730 Loss_G: 5.6898 (λL1=25.00)\n",
      "Epoch [44/70] Loss_D: -0.0573 Loss_G: 6.7792 (λL1=25.00)\n",
      "Epoch [45/70] Loss_D: -0.1372 Loss_G: 7.9378 (λL1=25.00)\n",
      "Epoch [46/70] Loss_D: -0.0447 Loss_G: 6.3895 (λL1=25.00)\n",
      "Epoch [47/70] Loss_D: 0.0057 Loss_G: 5.4824 (λL1=25.00)\n",
      "Epoch [48/70] Loss_D: -0.0051 Loss_G: 6.8266 (λL1=25.00)\n",
      "Epoch [49/70] Loss_D: -0.1527 Loss_G: 7.1119 (λL1=25.00)\n",
      "Epoch [50/70] Loss_D: 0.1286 Loss_G: 5.6658 (λL1=25.00)\n",
      "[Epoch 50] Val mean MSE=0.0453, Corr=0.9523\n",
      "Epoch [51/70] Loss_D: -0.0244 Loss_G: 4.4572 (λL1=25.00)\n",
      "Epoch [52/70] Loss_D: -0.1139 Loss_G: 6.4073 (λL1=25.00)\n",
      "Epoch [53/70] Loss_D: -0.1108 Loss_G: 5.5209 (λL1=25.00)\n",
      "Epoch [54/70] Loss_D: -0.0932 Loss_G: 3.9583 (λL1=25.00)\n",
      "Epoch [55/70] Loss_D: -0.0928 Loss_G: 5.3147 (λL1=25.00)\n",
      "Epoch [56/70] Loss_D: -0.1295 Loss_G: 4.1985 (λL1=25.00)\n",
      "Epoch [57/70] Loss_D: -0.1344 Loss_G: 4.1947 (λL1=25.00)\n",
      "Epoch [58/70] Loss_D: -0.1404 Loss_G: 4.3610 (λL1=25.00)\n",
      "Epoch [59/70] Loss_D: -0.0059 Loss_G: 4.1043 (λL1=25.00)\n",
      "Epoch [60/70] Loss_D: -0.1672 Loss_G: 4.9202 (λL1=25.00)\n",
      "[Epoch 60] Val mean MSE=0.0437, Corr=0.9677\n",
      "Epoch [61/70] Loss_D: -0.1236 Loss_G: 2.4479 (λL1=25.00)\n",
      "Epoch [62/70] Loss_D: -0.0722 Loss_G: 4.9725 (λL1=25.00)\n",
      "Epoch [63/70] Loss_D: -0.3247 Loss_G: 6.1295 (λL1=25.00)\n",
      "Epoch [64/70] Loss_D: 0.2158 Loss_G: 2.3493 (λL1=25.00)\n",
      "Epoch [65/70] Loss_D: -0.1201 Loss_G: 3.2431 (λL1=25.00)\n",
      "Epoch [66/70] Loss_D: -0.0656 Loss_G: 5.0390 (λL1=25.00)\n",
      "Epoch [67/70] Loss_D: -0.0782 Loss_G: 4.3805 (λL1=25.00)\n",
      "Epoch [68/70] Loss_D: -0.1529 Loss_G: 3.9343 (λL1=25.00)\n",
      "Epoch [69/70] Loss_D: -0.1662 Loss_G: 6.0594 (λL1=25.00)\n",
      "Epoch [70/70] Loss_D: -0.0467 Loss_G: 3.7855 (λL1=25.00)\n",
      "[Epoch 70] Val mean MSE=0.0484, Corr=0.9612\n",
      "Nejlepší epocha podle MSE: epoch       60.000000\n",
      "mean_MSE     0.043673\n",
      "Name: 5, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.048256    0.961334\n",
      "std     83.282651    0.073895    0.019757\n",
      "min      0.000000    0.000969    0.878138\n",
      "25%     71.750000    0.005551    0.954890\n",
      "50%    143.500000    0.011904    0.965785\n",
      "75%    215.250000    0.035156    0.975263\n",
      "max    287.000000    0.256765    0.988041\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs70_20250926_082247\n",
      "\n",
      "=== Spouštím běh: λ=25, epochs=80, výstup: results/lambda25_epochs80_20250926_082542 ===\n",
      "Epoch [1/80] Loss_D: -1.0021 Loss_G: 18.5848 (λL1=25.00)\n",
      "Epoch [2/80] Loss_D: -2.3976 Loss_G: 3.8405 (λL1=25.00)\n",
      "Epoch [3/80] Loss_D: 0.0005 Loss_G: -2.8948 (λL1=25.00)\n",
      "Epoch [4/80] Loss_D: 0.0846 Loss_G: 5.1749 (λL1=25.00)\n",
      "Epoch [5/80] Loss_D: 0.0264 Loss_G: 8.8345 (λL1=25.00)\n",
      "Epoch [6/80] Loss_D: -0.4224 Loss_G: 8.6081 (λL1=25.00)\n",
      "Epoch [7/80] Loss_D: -0.6238 Loss_G: 6.9372 (λL1=25.00)\n",
      "Epoch [8/80] Loss_D: -0.1855 Loss_G: 3.8061 (λL1=25.00)\n",
      "Epoch [9/80] Loss_D: 0.3586 Loss_G: 2.2089 (λL1=25.00)\n",
      "Epoch [10/80] Loss_D: 0.4767 Loss_G: 3.4088 (λL1=25.00)\n",
      "[Epoch 10] Val mean MSE=0.0494, Corr=0.6772\n",
      "Epoch [11/80] Loss_D: 0.3361 Loss_G: 6.7637 (λL1=25.00)\n",
      "Epoch [12/80] Loss_D: 0.2230 Loss_G: 8.5926 (λL1=25.00)\n",
      "Epoch [13/80] Loss_D: 0.1277 Loss_G: 9.3208 (λL1=25.00)\n",
      "Epoch [14/80] Loss_D: 0.0455 Loss_G: 9.3141 (λL1=25.00)\n",
      "Epoch [15/80] Loss_D: 0.0571 Loss_G: 9.0412 (λL1=25.00)\n",
      "Epoch [16/80] Loss_D: 0.1346 Loss_G: 8.1198 (λL1=25.00)\n",
      "Epoch [17/80] Loss_D: 0.1497 Loss_G: 6.8800 (λL1=25.00)\n",
      "Epoch [18/80] Loss_D: -0.0607 Loss_G: 6.0609 (λL1=25.00)\n",
      "Epoch [19/80] Loss_D: 0.0845 Loss_G: 5.7669 (λL1=25.00)\n",
      "Epoch [20/80] Loss_D: 0.1679 Loss_G: 5.2233 (λL1=25.00)\n",
      "[Epoch 20] Val mean MSE=0.0474, Corr=0.9523\n",
      "Epoch [21/80] Loss_D: 0.0816 Loss_G: 5.9072 (λL1=25.00)\n",
      "Epoch [22/80] Loss_D: 0.0982 Loss_G: 5.8894 (λL1=25.00)\n",
      "Epoch [23/80] Loss_D: 0.0072 Loss_G: 5.6392 (λL1=25.00)\n",
      "Epoch [24/80] Loss_D: 0.1448 Loss_G: 5.2393 (λL1=25.00)\n",
      "Epoch [25/80] Loss_D: -0.0864 Loss_G: 6.0887 (λL1=25.00)\n",
      "Epoch [26/80] Loss_D: -0.0280 Loss_G: 6.3505 (λL1=25.00)\n",
      "Epoch [27/80] Loss_D: -0.0393 Loss_G: 6.6954 (λL1=25.00)\n",
      "Epoch [28/80] Loss_D: 0.0721 Loss_G: 7.6778 (λL1=25.00)\n",
      "Epoch [29/80] Loss_D: -0.0080 Loss_G: 7.9583 (λL1=25.00)\n",
      "Epoch [30/80] Loss_D: 0.0351 Loss_G: 8.1134 (λL1=25.00)\n",
      "[Epoch 30] Val mean MSE=0.0436, Corr=0.9645\n",
      "Epoch [31/80] Loss_D: 0.0451 Loss_G: 6.3882 (λL1=25.00)\n",
      "Epoch [32/80] Loss_D: 0.0532 Loss_G: 6.8113 (λL1=25.00)\n",
      "Epoch [33/80] Loss_D: -0.0149 Loss_G: 6.6235 (λL1=25.00)\n",
      "Epoch [34/80] Loss_D: -0.0908 Loss_G: 7.4483 (λL1=25.00)\n",
      "Epoch [35/80] Loss_D: -0.0470 Loss_G: 8.3544 (λL1=25.00)\n",
      "Epoch [36/80] Loss_D: -0.0692 Loss_G: 8.3893 (λL1=25.00)\n",
      "Epoch [37/80] Loss_D: 0.0571 Loss_G: 8.2647 (λL1=25.00)\n",
      "Epoch [38/80] Loss_D: 0.0243 Loss_G: 8.1375 (λL1=25.00)\n",
      "Epoch [39/80] Loss_D: -0.0960 Loss_G: 8.6438 (λL1=25.00)\n",
      "Epoch [40/80] Loss_D: -0.0609 Loss_G: 9.4602 (λL1=25.00)\n",
      "[Epoch 40] Val mean MSE=0.0434, Corr=0.9718\n",
      "Epoch [41/80] Loss_D: 0.0233 Loss_G: 8.7905 (λL1=25.00)\n",
      "Epoch [42/80] Loss_D: -0.0734 Loss_G: 8.1565 (λL1=25.00)\n",
      "Epoch [43/80] Loss_D: -0.1687 Loss_G: 8.7580 (λL1=25.00)\n",
      "Epoch [44/80] Loss_D: 0.0767 Loss_G: 8.8743 (λL1=25.00)\n",
      "Epoch [45/80] Loss_D: -0.0778 Loss_G: 9.2872 (λL1=25.00)\n",
      "Epoch [46/80] Loss_D: -0.0592 Loss_G: 9.2190 (λL1=25.00)\n",
      "Epoch [47/80] Loss_D: 0.0084 Loss_G: 9.3144 (λL1=25.00)\n",
      "Epoch [48/80] Loss_D: -0.0620 Loss_G: 9.5222 (λL1=25.00)\n",
      "Epoch [49/80] Loss_D: 0.0712 Loss_G: 9.7124 (λL1=25.00)\n",
      "Epoch [50/80] Loss_D: -0.2319 Loss_G: 8.6884 (λL1=25.00)\n",
      "[Epoch 50] Val mean MSE=0.0448, Corr=0.9588\n",
      "Epoch [51/80] Loss_D: 0.0320 Loss_G: 10.7153 (λL1=25.00)\n",
      "Epoch [52/80] Loss_D: -0.0775 Loss_G: 11.5741 (λL1=25.00)\n",
      "Epoch [53/80] Loss_D: -0.0121 Loss_G: 8.8613 (λL1=25.00)\n",
      "Epoch [54/80] Loss_D: 0.0797 Loss_G: 7.1061 (λL1=25.00)\n",
      "Epoch [55/80] Loss_D: 0.0134 Loss_G: 7.5814 (λL1=25.00)\n",
      "Epoch [56/80] Loss_D: 0.1187 Loss_G: 8.3081 (λL1=25.00)\n",
      "Epoch [57/80] Loss_D: -0.0623 Loss_G: 8.8415 (λL1=25.00)\n",
      "Epoch [58/80] Loss_D: -0.0711 Loss_G: 8.0305 (λL1=25.00)\n",
      "Epoch [59/80] Loss_D: -0.2842 Loss_G: 8.3193 (λL1=25.00)\n",
      "Epoch [60/80] Loss_D: -0.0166 Loss_G: 9.8583 (λL1=25.00)\n",
      "[Epoch 60] Val mean MSE=0.0427, Corr=0.9743\n",
      "Epoch [61/80] Loss_D: -0.0054 Loss_G: 8.2225 (λL1=25.00)\n",
      "Epoch [62/80] Loss_D: 0.0406 Loss_G: 10.1608 (λL1=25.00)\n",
      "Epoch [63/80] Loss_D: -0.0554 Loss_G: 11.7572 (λL1=25.00)\n",
      "Epoch [64/80] Loss_D: -0.1943 Loss_G: 10.0056 (λL1=25.00)\n",
      "Epoch [65/80] Loss_D: 0.1514 Loss_G: 8.0136 (λL1=25.00)\n",
      "Epoch [66/80] Loss_D: -0.1924 Loss_G: 8.3170 (λL1=25.00)\n",
      "Epoch [67/80] Loss_D: -0.0839 Loss_G: 10.4977 (λL1=25.00)\n",
      "Epoch [68/80] Loss_D: 0.0635 Loss_G: 10.9922 (λL1=25.00)\n",
      "Epoch [69/80] Loss_D: 0.1171 Loss_G: 9.0635 (λL1=25.00)\n",
      "Epoch [70/80] Loss_D: -0.1872 Loss_G: 9.0676 (λL1=25.00)\n",
      "[Epoch 70] Val mean MSE=0.0441, Corr=0.9662\n",
      "Epoch [71/80] Loss_D: 0.0192 Loss_G: 9.8055 (λL1=25.00)\n",
      "Epoch [72/80] Loss_D: -0.0811 Loss_G: 7.9997 (λL1=25.00)\n",
      "Epoch [73/80] Loss_D: -0.0560 Loss_G: 9.5918 (λL1=25.00)\n",
      "Epoch [74/80] Loss_D: -0.1870 Loss_G: 11.4075 (λL1=25.00)\n",
      "Epoch [75/80] Loss_D: -0.3485 Loss_G: 10.1259 (λL1=25.00)\n",
      "Epoch [76/80] Loss_D: -0.0605 Loss_G: 9.8529 (λL1=25.00)\n",
      "Epoch [77/80] Loss_D: -0.0259 Loss_G: 11.1608 (λL1=25.00)\n",
      "Epoch [78/80] Loss_D: -0.2505 Loss_G: 13.8796 (λL1=25.00)\n",
      "Epoch [79/80] Loss_D: 0.0162 Loss_G: 13.2027 (λL1=25.00)\n",
      "Epoch [80/80] Loss_D: -0.1250 Loss_G: 11.4761 (λL1=25.00)\n",
      "[Epoch 80] Val mean MSE=0.0432, Corr=0.9618\n",
      "Nejlepší epocha podle MSE: epoch       60.000000\n",
      "mean_MSE     0.042662\n",
      "Name: 5, dtype: float64\n",
      "              idx         MSE        Corr\n",
      "count  288.000000  288.000000  288.000000\n",
      "mean   143.500000    0.043200    0.962605\n",
      "std     83.282651    0.074769    0.030789\n",
      "min      0.000000    0.001112    0.851438\n",
      "25%     71.750000    0.003912    0.948706\n",
      "50%    143.500000    0.007871    0.965683\n",
      "75%    215.250000    0.021828    0.991066\n",
      "max    287.000000    0.262013    0.995631\n",
      "Běh dokončen. Výsledky ve složce: results/lambda25_epochs80_20250926_082542\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T06:28:57.858833Z",
     "start_time": "2025-09-26T06:28:56.900327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "def collect_runs(parent_dir=\"results\"):\n",
    "\n",
    "    runs = []\n",
    "    for run in os.listdir(parent_dir):\n",
    "        run_dir = os.path.join(parent_dir, run)\n",
    "        files = sorted(glob.glob(os.path.join(run_dir, \"validation_metrics_epoch*.csv\")))\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        last_file = files[-1]  # poslední epocha\n",
    "        if os.path.getsize(last_file) == 0:\n",
    "            print(f\"Soubor {last_file} je prázdný – přeskočeno.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(last_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Chyba při čtení {last_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Soubor {last_file} neobsahuje data – přeskočeno.\")\n",
    "            continue\n",
    "\n",
    "        mean_mse = df[\"MSE\"].mean()\n",
    "        mean_corr = df[\"Corr\"].mean()\n",
    "        runs.append({\n",
    "            \"run\": run,\n",
    "            \"mean_MSE\": mean_mse,\n",
    "            \"mean_Corr\": mean_corr,\n",
    "            \"epoch\": int(last_file.split(\"epoch\")[-1].split(\".\")[0])\n",
    "        })\n",
    "\n",
    "    if not runs:\n",
    "        print(\"Nebyl nalezen žádný platný výsledek.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(runs)\n",
    "\n",
    "\n",
    "\n",
    "def compare_runs(parent_dir=\"results\", save_name=\"comparison.png\"):\n",
    "    all_dfs = []\n",
    "    for run in os.listdir(parent_dir):\n",
    "        run_dir = os.path.join(parent_dir, run)\n",
    "        files = sorted(glob.glob(os.path.join(run_dir, \"validation_metrics_epoch*.csv\")))\n",
    "        if files:\n",
    "            # vyber nejlepší epochu podle MSE\n",
    "            best, _ = find_best_epoch(run_dir, metric=\"MSE\", mode=\"min\")\n",
    "            best_file = os.path.join(run_dir, f\"validation_metrics_epoch{int(best['epoch'])}.csv\")\n",
    "\n",
    "            # kontrola, zda soubor není prázdný\n",
    "            if os.path.exists(best_file) and os.path.getsize(best_file) > 0:\n",
    "                try:\n",
    "                    df = pd.read_csv(best_file)\n",
    "                    if not df.empty:\n",
    "                        df[\"run\"] = run\n",
    "                        df[\"epoch\"] = int(best[\"epoch\"])\n",
    "                        all_dfs.append(df)\n",
    "                    else:\n",
    "                        print(f\"Soubor {best_file} je prázdný – přeskočeno.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Chyba při čtení {best_file}: {e}\")\n",
    "            else:\n",
    "                print(f\"Soubor {best_file} neexistuje nebo je prázdný – přeskočeno.\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        print(\"Nebyly nalezeny žádné výsledky k porovnání.\")\n",
    "        return None\n",
    "\n",
    "    big_df = pd.concat(all_dfs)\n",
    "\n",
    "    # boxploty\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x=\"run\", y=\"MSE\", data=big_df)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"MSE podle běhů (nejlepší epochy)\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=\"run\", y=\"Corr\", data=big_df)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Korelace podle běhů (nejlepší epochy)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(parent_dir, save_name), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Porovnání uloženo do {os.path.join(parent_dir, save_name)}\")\n",
    "    return big_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parent = \"results\"\n",
    "    summary = collect_runs(parent)\n",
    "    print(\"Souhrn běhů:\")\n",
    "    print(summary)\n",
    "\n",
    "    big_df = compare_runs(parent)\n",
    "    if big_df is not None:\n",
    "        # histogramy všech běhů dohromady\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        sns.histplot(big_df, x=\"MSE\", hue=\"run\", bins=40, kde=True, element=\"step\")\n",
    "        plt.title(\"Distribuce MSE\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.histplot(big_df, x=\"Corr\", hue=\"run\", bins=40, kde=True, element=\"step\")\n",
    "        plt.title(\"Distribuce korelace\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(parent, \"comparison_histograms.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Histogramy uloženy do {os.path.join(parent, 'comparison_histograms.png')}\")\n",
    "\"\"\""
   ],
   "id": "8cc983bedb39347f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souhrn běhů:\n",
      "                                  run  mean_MSE  mean_Corr  epoch\n",
      "0   lambda10_epochs70_20250926_050105  0.052753   0.856714     70\n",
      "1    lambda5_epochs30_20250926_044340  0.044945   0.901697     30\n",
      "2   lambda20_epochs70_20250926_055553  0.043052   0.967255     70\n",
      "3   lambda25_epochs60_20250926_082021  0.045667   0.967781     60\n",
      "4   lambda15_epochs50_20250926_050919  0.042845   0.961768     50\n",
      "5    lambda5_epochs70_20250926_044924  0.056843   0.722515     70\n",
      "6   lambda20_epochs80_20250926_060026  0.049340   0.975182     80\n",
      "7   lambda25_epochs50_20250926_074714  0.045906   0.956209     50\n",
      "8   lambda15_epochs10_20250926_050554  0.055645   0.759857     10\n",
      "9    lambda5_epochs50_20250926_044554  0.052858   0.847549     50\n",
      "10  lambda20_epochs30_20250926_052954  0.044441   0.968381     30\n",
      "11  lambda15_epochs80_20250926_052631  0.043211   0.965560     80\n",
      "12  lambda25_epochs70_20250926_082247  0.048417   0.961242     70\n",
      "13  lambda15_epochs60_20250926_051129  0.040948   0.946157     60\n",
      "14  lambda10_epochs60_20250926_045909  0.045256   0.959836     60\n",
      "15  lambda10_epochs20_20250926_045433  0.044895   0.920952     20\n",
      "16  lambda15_epochs30_20250926_050652  0.046618   0.940622     30\n",
      "17  lambda15_epochs70_20250926_052422  0.046392   0.818182     70\n",
      "18  lambda20_epochs60_20250926_055204  0.047643   0.934022     60\n",
      "19  lambda20_epochs10_20250926_052859  0.056141   0.773088     10\n",
      "20   lambda5_epochs20_20250926_044302  0.085338   0.438418     20\n",
      "21  lambda15_epochs20_20250926_050613  0.046484   0.953831     20\n",
      "22  lambda10_epochs50_20250926_045730  0.044404   0.911103     50\n",
      "23  lambda25_epochs80_20250926_082542  0.043205   0.961824     80\n",
      "24  lambda10_epochs10_20250926_045413  0.052012   0.683174     10\n",
      "25  lambda25_epochs30_20250926_064000  0.045509   0.963045     30\n",
      "26  lambda25_epochs40_20250926_071136  0.043715   0.978236     40\n",
      "27   lambda5_epochs10_20250926_044242  0.150732   0.333210     10\n",
      "28  lambda15_epochs40_20250926_050749  0.047349   0.947069     40\n",
      "29   lambda5_epochs80_20250926_045139  0.043977   0.947319     80\n",
      "30  lambda10_epochs80_20250926_050321  0.045771   0.964163     80\n",
      "31  lambda10_epochs40_20250926_045611  0.047838   0.932599     40\n",
      "32  lambda20_epochs40_20250926_053053  0.045258   0.972979     40\n",
      "33   lambda5_epochs40_20250926_044437  0.044003   0.954344     40\n",
      "34  lambda25_epochs20_20250926_062302  0.048583   0.957355     20\n",
      "35  lambda25_epochs10_20250926_062235  0.049964   0.856662     10\n",
      "36  lambda10_epochs30_20250926_045513  0.045492   0.940329     30\n",
      "37  lambda20_epochs50_20250926_054852  0.044424   0.944275     50\n",
      "38   lambda5_epochs60_20250926_044729  0.053407   0.927566     60\n",
      "39  lambda20_epochs20_20250926_052917  0.047630   0.951869     20\n",
      "Porovnání uloženo do results/comparison.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/vhlpqw8j2b397jbfkxbr0sm40000gn/T/ipykernel_10089/4006337599.py:128: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogramy uloženy do results/comparison_histograms.png\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ATTENTION!\n",
    "\n",
    "## --> find best run/epoch functions\n",
    "this part is still duplicited - it should fixed later"
   ],
   "id": "197456ba8f1a11b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souhrn všech běhů:\n",
      "                                  run  epoch       MSE  \\\n",
      "0   lambda10_epochs70_20250926_050105     30  0.044194   \n",
      "1    lambda5_epochs30_20250926_044340     30  0.044945   \n",
      "2   lambda20_epochs70_20250926_055553     70  0.043052   \n",
      "3   lambda25_epochs60_20250926_082021     50  0.044733   \n",
      "4   lambda15_epochs50_20250926_050919     40  0.042237   \n",
      "5    lambda5_epochs70_20250926_044924     50  0.044944   \n",
      "6   lambda20_epochs80_20250926_060026     40  0.043259   \n",
      "7   lambda25_epochs50_20250926_074714     40  0.043244   \n",
      "8   lambda15_epochs10_20250926_050554     10  0.055645   \n",
      "9    lambda5_epochs50_20250926_044554     40  0.046894   \n",
      "10  lambda20_epochs30_20250926_052954     30  0.044441   \n",
      "11  lambda15_epochs80_20250926_052631     80  0.043211   \n",
      "12  lambda25_epochs70_20250926_082247     60  0.043673   \n",
      "13  lambda15_epochs60_20250926_051129     60  0.040948   \n",
      "14  lambda10_epochs60_20250926_045909     50  0.042933   \n",
      "15  lambda10_epochs20_20250926_045433     20  0.044895   \n",
      "16  lambda15_epochs30_20250926_050652     20  0.046128   \n",
      "17  lambda15_epochs70_20250926_052422     40  0.044718   \n",
      "18  lambda20_epochs60_20250926_055204     40  0.042775   \n",
      "19  lambda20_epochs10_20250926_052859     10  0.056141   \n",
      "20   lambda5_epochs20_20250926_044302     20  0.085338   \n",
      "21  lambda15_epochs20_20250926_050613     20  0.046484   \n",
      "22  lambda10_epochs50_20250926_045730     50  0.044404   \n",
      "23  lambda25_epochs80_20250926_082542     60  0.042662   \n",
      "24  lambda10_epochs10_20250926_045413     10  0.052012   \n",
      "25  lambda25_epochs30_20250926_064000     30  0.045509   \n",
      "26  lambda25_epochs40_20250926_071136     40  0.043715   \n",
      "27   lambda5_epochs10_20250926_044242     10  0.150732   \n",
      "28  lambda15_epochs40_20250926_050749     30  0.044706   \n",
      "29   lambda5_epochs80_20250926_045139     80  0.043977   \n",
      "30  lambda10_epochs80_20250926_050321     40  0.044389   \n",
      "31  lambda10_epochs40_20250926_045611     40  0.047838   \n",
      "32  lambda20_epochs40_20250926_053053     40  0.045258   \n",
      "33   lambda5_epochs40_20250926_044437     40  0.044003   \n",
      "34  lambda25_epochs20_20250926_062302     20  0.048583   \n",
      "35  lambda25_epochs10_20250926_062235     10  0.049964   \n",
      "36  lambda10_epochs30_20250926_045513     20  0.044781   \n",
      "37  lambda20_epochs50_20250926_054852     40  0.044278   \n",
      "38   lambda5_epochs60_20250926_044729     30  0.047237   \n",
      "39  lambda20_epochs20_20250926_052917     20  0.047630   \n",
      "\n",
      "                                                 file  lambda_l1  num_epochs  \n",
      "0   results/lambda10_epochs70_20250926_050105/vali...         10          70  \n",
      "1   results/lambda5_epochs30_20250926_044340/valid...          5          30  \n",
      "2   results/lambda20_epochs70_20250926_055553/vali...         20          70  \n",
      "3   results/lambda25_epochs60_20250926_082021/vali...         25          60  \n",
      "4   results/lambda15_epochs50_20250926_050919/vali...         15          50  \n",
      "5   results/lambda5_epochs70_20250926_044924/valid...          5          70  \n",
      "6   results/lambda20_epochs80_20250926_060026/vali...         20          80  \n",
      "7   results/lambda25_epochs50_20250926_074714/vali...         25          50  \n",
      "8   results/lambda15_epochs10_20250926_050554/vali...         15          10  \n",
      "9   results/lambda5_epochs50_20250926_044554/valid...          5          50  \n",
      "10  results/lambda20_epochs30_20250926_052954/vali...         20          30  \n",
      "11  results/lambda15_epochs80_20250926_052631/vali...         15          80  \n",
      "12  results/lambda25_epochs70_20250926_082247/vali...         25          70  \n",
      "13  results/lambda15_epochs60_20250926_051129/vali...         15          60  \n",
      "14  results/lambda10_epochs60_20250926_045909/vali...         10          60  \n",
      "15  results/lambda10_epochs20_20250926_045433/vali...         10          20  \n",
      "16  results/lambda15_epochs30_20250926_050652/vali...         15          30  \n",
      "17  results/lambda15_epochs70_20250926_052422/vali...         15          70  \n",
      "18  results/lambda20_epochs60_20250926_055204/vali...         20          60  \n",
      "19  results/lambda20_epochs10_20250926_052859/vali...         20          10  \n",
      "20  results/lambda5_epochs20_20250926_044302/valid...          5          20  \n",
      "21  results/lambda15_epochs20_20250926_050613/vali...         15          20  \n",
      "22  results/lambda10_epochs50_20250926_045730/vali...         10          50  \n",
      "23  results/lambda25_epochs80_20250926_082542/vali...         25          80  \n",
      "24  results/lambda10_epochs10_20250926_045413/vali...         10          10  \n",
      "25  results/lambda25_epochs30_20250926_064000/vali...         25          30  \n",
      "26  results/lambda25_epochs40_20250926_071136/vali...         25          40  \n",
      "27  results/lambda5_epochs10_20250926_044242/valid...          5          10  \n",
      "28  results/lambda15_epochs40_20250926_050749/vali...         15          40  \n",
      "29  results/lambda5_epochs80_20250926_045139/valid...          5          80  \n",
      "30  results/lambda10_epochs80_20250926_050321/vali...         10          80  \n",
      "31  results/lambda10_epochs40_20250926_045611/vali...         10          40  \n",
      "32  results/lambda20_epochs40_20250926_053053/vali...         20          40  \n",
      "33  results/lambda5_epochs40_20250926_044437/valid...          5          40  \n",
      "34  results/lambda25_epochs20_20250926_062302/vali...         25          20  \n",
      "35  results/lambda25_epochs10_20250926_062235/vali...         25          10  \n",
      "36  results/lambda10_epochs30_20250926_045513/vali...         10          30  \n",
      "37  results/lambda20_epochs50_20250926_054852/vali...         20          50  \n",
      "38  results/lambda5_epochs60_20250926_044729/valid...          5          60  \n",
      "39  results/lambda20_epochs20_20250926_052917/vali...         20          20  \n",
      "\n",
      "Nejlepší průběh podle MSE:\n",
      "{'run': 'lambda15_epochs60_20250926_051129', 'epoch': 60, 'MSE': 0.04094769284423208, 'file': 'results/lambda15_epochs60_20250926_051129/validation_metrics_epoch60.csv', 'lambda_l1': 15, 'num_epochs': 60}\n"
     ]
    }
   ],
   "execution_count": 90,
   "source": [
    "def find_best_epoch(run_dir, metric=\"MSE\", mode=\"min\"):\n",
    "    \"\"\"Find the best epoch within a single run based on the selected metric criterion.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(run_dir, \"validation_metrics_epoch*.csv\")))\n",
    "    if not files:\n",
    "        return None, None\n",
    "\n",
    "    results = []\n",
    "    for f in files:\n",
    "        epoch = int(os.path.basename(f).replace(\"validation_metrics_epoch\", \"\").replace(\".csv\", \"\"))\n",
    "        df = pd.read_csv(f)\n",
    "        mean_val = df[metric].mean()\n",
    "        results.append({\"epoch\": epoch, metric: mean_val, \"file\": f})\n",
    "\n",
    "    df_all = pd.DataFrame(results)\n",
    "    if mode == \"min\":\n",
    "        best = df_all.loc[df_all[metric].idxmin()]\n",
    "    else:\n",
    "        best = df_all.loc[df_all[metric].idxmax()]\n",
    "\n",
    "    return best, df_all\n",
    "\n",
    "\n",
    "def find_best_run(parent_dir=\"results\", metric=\"MSE\", mode=\"min\"):\n",
    "    \"\"\"Find the globally best run and epoch based on the selected metric.\"\"\"\n",
    "    best_overall = None\n",
    "    all_runs = []\n",
    "\n",
    "    for run in os.listdir(parent_dir):\n",
    "        run_dir = os.path.join(parent_dir, run)\n",
    "        if not os.path.isdir(run_dir):\n",
    "            continue\n",
    "\n",
    "        best, all_vals = find_best_epoch(run_dir, metric=metric, mode=mode)\n",
    "        if best is None:\n",
    "            continue\n",
    "\n",
    "        # load configuration\n",
    "        config_file = os.path.join(run_dir, \"config.json\")\n",
    "        if os.path.exists(config_file):\n",
    "            with open(config_file, \"r\") as f:\n",
    "                config = json.load(f)\n",
    "        else:\n",
    "            config = {}\n",
    "\n",
    "        record = {\n",
    "            \"run\": run,\n",
    "            \"epoch\": int(best[\"epoch\"]),\n",
    "            metric: float(best[metric]),\n",
    "            \"file\": best[\"file\"],\n",
    "            \"lambda_l1\": config.get(\"lambda_l1\"),\n",
    "            \"num_epochs\": config.get(\"num_epochs\")\n",
    "        }\n",
    "        all_runs.append(record)\n",
    "\n",
    "        # update best run\n",
    "        if best_overall is None:\n",
    "            best_overall = record\n",
    "        else:\n",
    "            if (mode == \"min\" and record[metric] < best_overall[metric]) or \\\n",
    "               (mode == \"max\" and record[metric] > best_overall[metric]):\n",
    "                best_overall = record\n",
    "\n",
    "    df_all = pd.DataFrame(all_runs)\n",
    "    return best_overall, df_all\n",
    "\n",
    "\n",
    "\n",
    "best, summary = find_best_run(\"results\", metric=\"MSE\", mode=\"min\")\n",
    "\n",
    "print(f\"Summary of all runs: \\n {summary}\")\n",
    "print(f\"Best run according to MSE: {best}\")\n"
   ],
   "id": "402154cc0b01127c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T06:56:27.836012Z",
     "start_time": "2025-09-26T06:56:27.409311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "def compute_extra_metrics(real, fake):\n",
    "    \"\"\"Compute additional metrics for a single signal.\"\"\"\n",
    "    mae = mean_absolute_error(real, fake)\n",
    "    spear, _ = spearmanr(real, fake)\n",
    "    # DTW (Dynamic Time Warping)\n",
    "    dtw_dist, _ = fastdtw(real, fake, dist=euclidean)\n",
    "    return mae, spear, dtw_dist\n",
    "\n",
    "\n",
    "def evaluate_epoch(file_path):\n",
    "    \"\"\"Load validation CSV for one epoch and compute average metrics.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    metrics = {\n",
    "        \"MSE\": df[\"MSE\"].mean(),\n",
    "        \"Corr\": df[\"Corr\"].mean()\n",
    "    }\n",
    "\n",
    "    maes, spears, dtws = [], [], []\n",
    "    for idx, row in df.iterrows():\n",
    "        # If you have saved real_signals.npy and fake_signals.npy → you could load them here.\n",
    "        # For now, we only use MSE and Corr from the CSV.\n",
    "        # Spearman and DTW could be computed during validation → placeholder here.\n",
    "        pass\n",
    "\n",
    "    # If DTW is too expensive to compute for all samples,\n",
    "    # it’s better to do it during validation and store it in the CSV.\n",
    "    # For simplicity, we only return MSE and Corr here.\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def find_best_epoch(run_dir, metric=\"MSE\", mode=\"min\"):\n",
    "    \"\"\"Find the best epoch within a single run based on the selected metric.\"\"\"\n",
    "    files = sorted(glob.glob(os.path.join(run_dir, \"validation_metrics_epoch*.csv\")))\n",
    "    if not files:\n",
    "        return None, None\n",
    "\n",
    "    results = []\n",
    "    for f in files:\n",
    "        epoch = int(os.path.basename(f).replace(\"validation_metrics_epoch\", \"\").replace(\".csv\", \"\"))\n",
    "        metrics = evaluate_epoch(f)\n",
    "        results.append({\"epoch\": epoch, **metrics, \"file\": f})\n",
    "\n",
    "    df_all = pd.DataFrame(results)\n",
    "    if mode == \"min\":\n",
    "        best = df_all.loc[df_all[metric].idxmin()]\n",
    "    else:\n",
    "        best = df_all.loc[df_all[metric].idxmax()]\n",
    "\n",
    "    return best, df_all\n",
    "\n",
    "\n",
    "def compute_score(row, weights=None):\n",
    "    \"\"\"\n",
    "    Composite score = weighted combination of metrics.\n",
    "    Lower is better.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        # Default: MSE and (1 - Corr) equally weighted\n",
    "        weights = {\"MSE\": 0.5, \"Corr\": 0.5}\n",
    "\n",
    "    score = 0.0\n",
    "    if \"MSE\" in weights:\n",
    "        score += weights[\"MSE\"] * row[\"MSE\"]\n",
    "    if \"Corr\" in weights:\n",
    "        score += weights[\"Corr\"] * (1 - row[\"Corr\"])\n",
    "    return score\n",
    "\n",
    "\n",
    "def find_best_run(parent_dir=\"results\", metric=\"MSE\", mode=\"min\", weights=None):\n",
    "    \"\"\"Find the globally best run based on the composite score.\"\"\"\n",
    "    all_runs = []\n",
    "    best_overall = None\n",
    "\n",
    "    for run in os.listdir(parent_dir):\n",
    "        run_dir = os.path.join(parent_dir, run)\n",
    "        if not os.path.isdir(run_dir):\n",
    "            continue\n",
    "\n",
    "        best, all_vals = find_best_epoch(run_dir, metric=metric, mode=mode)\n",
    "        if best is None:\n",
    "            continue\n",
    "\n",
    "        # load configuration\n",
    "        config_file = os.path.join(run_dir, \"config.json\")\n",
    "        if os.path.exists(config_file):\n",
    "            with open(config_file, \"r\") as f:\n",
    "                config = json.load(f)\n",
    "        else:\n",
    "            config = {}\n",
    "\n",
    "        record = {\n",
    "            \"run\": run,\n",
    "            \"epoch\": int(best[\"epoch\"]),\n",
    "            \"MSE\": float(best[\"MSE\"]),\n",
    "            \"Corr\": float(best[\"Corr\"]),\n",
    "            \"score\": compute_score(best, weights=weights),\n",
    "            \"file\": best[\"file\"],\n",
    "            \"lambda_l1\": config.get(\"lambda_l1\"),\n",
    "            \"num_epochs\": config.get(\"num_epochs\")\n",
    "        }\n",
    "        all_runs.append(record)\n",
    "\n",
    "        if best_overall is None:\n",
    "            best_overall = record\n",
    "        else:\n",
    "            if record[\"score\"] < best_overall[\"score\"]:\n",
    "                best_overall = record\n",
    "\n",
    "    df_all = pd.DataFrame(all_runs)\n",
    "    return best_overall, df_all\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Weights: equal for MSE and Corr\n",
    "    weights = {\"MSE\": 0.5, \"Corr\": 0.5}\n",
    "\n",
    "    best, summary = find_best_run(\"results\", metric=\"MSE\", mode=\"min\", weights=weights)\n",
    "    print(\"Summary of all runs:\")\n",
    "    print(summary)\n",
    "\n",
    "    print(f\"Best run according to composite score (MSE + Corr): {best}\")\n"
   ],
   "id": "a0472e9cf24d4353",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souhrn všech běhů:\n",
      "                                  run  epoch       MSE      Corr     score  \\\n",
      "0   lambda10_epochs70_20250926_050105     30  0.044194  0.939912  0.052141   \n",
      "1    lambda5_epochs30_20250926_044340     30  0.044945  0.901697  0.071624   \n",
      "2   lambda20_epochs70_20250926_055553     70  0.043052  0.967255  0.037899   \n",
      "3   lambda25_epochs60_20250926_082021     50  0.044733  0.968899  0.037917   \n",
      "4   lambda15_epochs50_20250926_050919     40  0.042237  0.945651  0.048293   \n",
      "5    lambda5_epochs70_20250926_044924     50  0.044944  0.950072  0.047436   \n",
      "6   lambda20_epochs80_20250926_060026     40  0.043259  0.953632  0.044813   \n",
      "7   lambda25_epochs50_20250926_074714     40  0.043244  0.971839  0.035703   \n",
      "8   lambda15_epochs10_20250926_050554     10  0.055645  0.759857  0.147894   \n",
      "9    lambda5_epochs50_20250926_044554     40  0.046894  0.896649  0.075122   \n",
      "10  lambda20_epochs30_20250926_052954     30  0.044441  0.968381  0.038030   \n",
      "11  lambda15_epochs80_20250926_052631     80  0.043211  0.965560  0.038825   \n",
      "12  lambda25_epochs70_20250926_082247     60  0.043673  0.967720  0.037976   \n",
      "13  lambda15_epochs60_20250926_051129     60  0.040948  0.946157  0.047395   \n",
      "14  lambda10_epochs60_20250926_045909     50  0.042933  0.968545  0.037194   \n",
      "15  lambda10_epochs20_20250926_045433     20  0.044895  0.920952  0.061971   \n",
      "16  lambda15_epochs30_20250926_050652     20  0.046128  0.947078  0.049525   \n",
      "17  lambda15_epochs70_20250926_052422     40  0.044718  0.953808  0.045455   \n",
      "18  lambda20_epochs60_20250926_055204     40  0.042775  0.968353  0.037211   \n",
      "19  lambda20_epochs10_20250926_052859     10  0.056141  0.773088  0.141527   \n",
      "20   lambda5_epochs20_20250926_044302     20  0.085338  0.438418  0.323460   \n",
      "21  lambda15_epochs20_20250926_050613     20  0.046484  0.953831  0.046326   \n",
      "22  lambda10_epochs50_20250926_045730     50  0.044404  0.911103  0.066650   \n",
      "23  lambda25_epochs80_20250926_082542     60  0.042662  0.974264  0.034199   \n",
      "24  lambda10_epochs10_20250926_045413     10  0.052012  0.683174  0.184419   \n",
      "25  lambda25_epochs30_20250926_064000     30  0.045509  0.963045  0.041232   \n",
      "26  lambda25_epochs40_20250926_071136     40  0.043715  0.978236  0.032740   \n",
      "27   lambda5_epochs10_20250926_044242     10  0.150732  0.333210  0.408761   \n",
      "28  lambda15_epochs40_20250926_050749     30  0.044706  0.952225  0.046241   \n",
      "29   lambda5_epochs80_20250926_045139     80  0.043977  0.947319  0.048329   \n",
      "30  lambda10_epochs80_20250926_050321     40  0.044389  0.919453  0.062468   \n",
      "31  lambda10_epochs40_20250926_045611     40  0.047838  0.932599  0.057620   \n",
      "32  lambda20_epochs40_20250926_053053     40  0.045258  0.972979  0.036139   \n",
      "33   lambda5_epochs40_20250926_044437     40  0.044003  0.954344  0.044830   \n",
      "34  lambda25_epochs20_20250926_062302     20  0.048583  0.957355  0.045614   \n",
      "35  lambda25_epochs10_20250926_062235     10  0.049964  0.856662  0.096651   \n",
      "36  lambda10_epochs30_20250926_045513     20  0.044781  0.949958  0.047411   \n",
      "37  lambda20_epochs50_20250926_054852     40  0.044278  0.965096  0.039591   \n",
      "38   lambda5_epochs60_20250926_044729     30  0.047237  0.928996  0.059121   \n",
      "39  lambda20_epochs20_20250926_052917     20  0.047630  0.951869  0.047881   \n",
      "\n",
      "                                                 file  lambda_l1  num_epochs  \n",
      "0   results/lambda10_epochs70_20250926_050105/vali...         10          70  \n",
      "1   results/lambda5_epochs30_20250926_044340/valid...          5          30  \n",
      "2   results/lambda20_epochs70_20250926_055553/vali...         20          70  \n",
      "3   results/lambda25_epochs60_20250926_082021/vali...         25          60  \n",
      "4   results/lambda15_epochs50_20250926_050919/vali...         15          50  \n",
      "5   results/lambda5_epochs70_20250926_044924/valid...          5          70  \n",
      "6   results/lambda20_epochs80_20250926_060026/vali...         20          80  \n",
      "7   results/lambda25_epochs50_20250926_074714/vali...         25          50  \n",
      "8   results/lambda15_epochs10_20250926_050554/vali...         15          10  \n",
      "9   results/lambda5_epochs50_20250926_044554/valid...          5          50  \n",
      "10  results/lambda20_epochs30_20250926_052954/vali...         20          30  \n",
      "11  results/lambda15_epochs80_20250926_052631/vali...         15          80  \n",
      "12  results/lambda25_epochs70_20250926_082247/vali...         25          70  \n",
      "13  results/lambda15_epochs60_20250926_051129/vali...         15          60  \n",
      "14  results/lambda10_epochs60_20250926_045909/vali...         10          60  \n",
      "15  results/lambda10_epochs20_20250926_045433/vali...         10          20  \n",
      "16  results/lambda15_epochs30_20250926_050652/vali...         15          30  \n",
      "17  results/lambda15_epochs70_20250926_052422/vali...         15          70  \n",
      "18  results/lambda20_epochs60_20250926_055204/vali...         20          60  \n",
      "19  results/lambda20_epochs10_20250926_052859/vali...         20          10  \n",
      "20  results/lambda5_epochs20_20250926_044302/valid...          5          20  \n",
      "21  results/lambda15_epochs20_20250926_050613/vali...         15          20  \n",
      "22  results/lambda10_epochs50_20250926_045730/vali...         10          50  \n",
      "23  results/lambda25_epochs80_20250926_082542/vali...         25          80  \n",
      "24  results/lambda10_epochs10_20250926_045413/vali...         10          10  \n",
      "25  results/lambda25_epochs30_20250926_064000/vali...         25          30  \n",
      "26  results/lambda25_epochs40_20250926_071136/vali...         25          40  \n",
      "27  results/lambda5_epochs10_20250926_044242/valid...          5          10  \n",
      "28  results/lambda15_epochs40_20250926_050749/vali...         15          40  \n",
      "29  results/lambda5_epochs80_20250926_045139/valid...          5          80  \n",
      "30  results/lambda10_epochs80_20250926_050321/vali...         10          80  \n",
      "31  results/lambda10_epochs40_20250926_045611/vali...         10          40  \n",
      "32  results/lambda20_epochs40_20250926_053053/vali...         20          40  \n",
      "33  results/lambda5_epochs40_20250926_044437/valid...          5          40  \n",
      "34  results/lambda25_epochs20_20250926_062302/vali...         25          20  \n",
      "35  results/lambda25_epochs10_20250926_062235/vali...         25          10  \n",
      "36  results/lambda10_epochs30_20250926_045513/vali...         10          30  \n",
      "37  results/lambda20_epochs50_20250926_054852/vali...         20          50  \n",
      "38  results/lambda5_epochs60_20250926_044729/valid...          5          60  \n",
      "39  results/lambda20_epochs20_20250926_052917/vali...         20          20  \n",
      "\n",
      "Nejlepší běh podle složeného skóre (MSE + Corr):\n",
      "{'run': 'lambda25_epochs40_20250926_071136', 'epoch': 40, 'MSE': 0.04371534743331212, 'Corr': 0.9782357494444445, 'score': np.float64(0.03273979899443383), 'file': 'results/lambda25_epochs40_20250926_071136/validation_metrics_epoch40.csv', 'lambda_l1': 25, 'num_epochs': 40}\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "26011642cb74cbda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
